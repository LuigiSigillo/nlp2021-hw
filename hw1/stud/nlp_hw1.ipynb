{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-hw1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOVhIqlds04iU8ARWuD6uGG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "53987915649247188045f5cd86cfa51b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cf33943f98a04af6b9119199030b7e07",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7ed880de548a44b387bbb4eabd7a1e69",
              "IPY_MODEL_fc07cde2992141cebc8f592da2e9d8f2"
            ]
          }
        },
        "cf33943f98a04af6b9119199030b7e07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7ed880de548a44b387bbb4eabd7a1e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_723c4474492949cd9c2a41b7967faa5e",
            "_dom_classes": [],
            "description": " 98%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 100000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 97670,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_950ddf8228394f499d237b11d513dac3"
          }
        },
        "fc07cde2992141cebc8f592da2e9d8f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f04e6406086479fbee43473a662c346",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97670/100000 [00:20&lt;00:00, 26575.41it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ba1fdebc0caa41e8843a6f48bcb005e8"
          }
        },
        "723c4474492949cd9c2a41b7967faa5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "950ddf8228394f499d237b11d513dac3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f04e6406086479fbee43473a662c346": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ba1fdebc0caa41e8843a6f48bcb005e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8df6027b6ad740008892c4a710c1d35a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ff875efd3b6b481790fcb157db4d2693",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6f041e77386443828b5f2c7b5d0d07c2",
              "IPY_MODEL_966555d30a244e67a520fbf2a751310f"
            ]
          }
        },
        "ff875efd3b6b481790fcb157db4d2693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6f041e77386443828b5f2c7b5d0d07c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7069da085164e0d9b4e059ee1512746",
            "_dom_classes": [],
            "description": " 77%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 300,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 232,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4ce12a7489744714a59b2236fbea1a5b"
          }
        },
        "966555d30a244e67a520fbf2a751310f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77949fff5eb84fe9b3f32b4e11d080c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232/300 [00:11&lt;00:03, 20.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c4420460b2e49919a6ab6ecb18b69bc"
          }
        },
        "a7069da085164e0d9b4e059ee1512746": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4ce12a7489744714a59b2236fbea1a5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "77949fff5eb84fe9b3f32b4e11d080c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c4420460b2e49919a6ab6ecb18b69bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuigiSigillo/nlp2021-hw/blob/master/hw1/stud/nlp_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y_g6ETA_lf3"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2n5xn1F5kvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be9d4467-c16d-4620-e239-e3f9096030a0"
      },
      "source": [
        "from google.colab import drive\n",
        "# general\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import *\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "import json\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import SGD\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "root_folder = '/content/drive/My Drive/NLP/nlp2021-hw1'\n",
        "dataset_folder = os.path.join(root_folder,'data')\n",
        "print(dataset_folder)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/NLP/nlp2021-hw1/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbAnAo7pMvbq"
      },
      "source": [
        "#! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
        "#! unzip -d data/glove.6B\n",
        "#! cd '/content/drive/My Drive/NLP/nlp2021-hw1'\n",
        "#!unzip '/content/drive/My Drive/NLP/nlp2021-hw1/glove.6B.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10W7Xq0CPENx"
      },
      "source": [
        "!mv glove.6B.200d.txt '/content/drive/My Drive/NLP/nlp2021-hw1/model'\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anwpXc08XRKf"
      },
      "source": [
        " load the actual word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "53987915649247188045f5cd86cfa51b",
            "cf33943f98a04af6b9119199030b7e07",
            "7ed880de548a44b387bbb4eabd7a1e69",
            "fc07cde2992141cebc8f592da2e9d8f2",
            "723c4474492949cd9c2a41b7967faa5e",
            "950ddf8228394f499d237b11d513dac3",
            "6f04e6406086479fbee43473a662c346",
            "ba1fdebc0caa41e8843a6f48bcb005e8"
          ]
        },
        "id": "Te3_zheKQQDe",
        "outputId": "52954adb-c84f-4857-89c2-668bdce14dca"
      },
      "source": [
        "word_vectors = dict()\n",
        "words_limit = 100_000\n",
        "with open('/content/drive/My Drive/NLP/nlp2021-hw1/model/glove.6B.100d.txt') as f:\n",
        "\n",
        "    next(f)  # skip header\n",
        "\n",
        "    for i, line in tqdm(enumerate(f), total=words_limit):\n",
        "\n",
        "        if i == words_limit:\n",
        "            break\n",
        "\n",
        "        word, *vector = line.strip().split(' ')\n",
        "        vector = torch.tensor([float(c) for c in vector])\n",
        "        \n",
        "        word_vectors[word] = vector\n",
        "\n",
        "## alternatives\n",
        "# for l in f:\n",
        "#     line = l.decode().split()\n",
        "#     word = line[0]\n",
        "#     words.append(word)\n",
        "#     word2idx[word] = idx\n",
        "#     idx += 1\n",
        "#     vect = np.array(line[1:]).astype(np.float)\n",
        "#     vectors.append(vect)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "53987915649247188045f5cd86cfa51b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKwgTMzCWGfU"
      },
      "source": [
        "def cosine_similarity(v1: torch.Tensor, v2: torch.Tensor) -> float:\n",
        "    num = torch.sum(v1 * v2)\n",
        "    den = torch.linalg.norm(v1) * torch.linalg.norm(v2)\n",
        "    return (num / den).item()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf9mpY2fWI58",
        "outputId": "6f9d68e7-cb09-4aa0-8d04-08b63710b931"
      },
      "source": [
        "cosine_similarity(word_vectors['king'], word_vectors['queen'])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7507690787315369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKed-2p_XsMH"
      },
      "source": [
        "word-embedding-powered function $\\phi$.  just converts any review to a vector by **averaging the embeddings corresponding to each word in it**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpsIPHyUV6Lt"
      },
      "source": [
        "def phrase2vector(phrase: str) -> Optional[torch.Tensor]:\n",
        "    phrases_word_vector = [word_vectors[w] for w in phrase.split(' ') if w in word_vectors]\n",
        "    \n",
        "    if len(phrases_word_vector) == 0:\n",
        "        return None\n",
        "\n",
        "    phrases_word_vector = torch.stack(phrases_word_vector)  # tensor shape: (#words X #features)\n",
        "    return torch.mean(phrases_word_vector, dim=0)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti80ryeyXUXT"
      },
      "source": [
        "class SentencesDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, dataset_path: str, phrase2vector):\n",
        "        self.data_store = []\n",
        "        self.init_structures(dataset_path, phrase2vector)\n",
        "\n",
        "    def init_structures(self, dataset_path: str, phrase2vector) -> None:\n",
        "\n",
        "        with open(dataset_path) as f:\n",
        "            for json_string in f:\n",
        "                single_json = json.loads(json_string)\n",
        "                '''s1 = single_json['sentence1']\n",
        "                s2 =  single_json['sentence2']\n",
        "                ground_t = 1 if single_json['label'] =='True' else 0\n",
        "                vector1 = phrase2vector(s1)\n",
        "                vector2 = phrase2vector(s2)\n",
        "                if vector1 is None:\n",
        "                    continue\n",
        "                if vector2 is None:\n",
        "                    continue\n",
        "                self.data_store.append((vector1,vector2,ground_t))'''\n",
        "                sentence =  single_json['sentence1'] + \" <SEP> \" + single_json['sentence2']\n",
        "                ground_t = np.float32(1) if single_json['label'] =='True' else np.float32(0)\n",
        "                vector = phrase2vector(sentence)\n",
        "                if vector is None:\n",
        "                    continue\n",
        "                self.data_store.append((vector,ground_t))\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data_store)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
        "        return self.data_store[idx]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8K2TtSOXY13"
      },
      "source": [
        "class SentencesDataModule(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        data_train_path: str,\n",
        "        data_dev_path: str,\n",
        "        data_test_path: str,\n",
        "        batch_size: int,\n",
        "        collate_fn=None\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.data_train_path = data_train_path\n",
        "        self.data_dev_path = data_dev_path\n",
        "        self.data_test_path = data_test_path\n",
        "        self.batch_size = batch_size\n",
        "        self.collate_fn = collate_fn\n",
        "\n",
        "        self.train_dataset = None\n",
        "        self.validation_dataset = None\n",
        "        self.test_dataset = None\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None) -> None:\n",
        "        if stage == 'fit':\n",
        "            self.train_dataset = SentencesDataset(self.data_train_path, phrase2vector)\n",
        "            self.validation_dataset = SentencesDataset(self.data_dev_path, phrase2vector)\n",
        "        elif stage == 'test':\n",
        "            self.test_dataset = SentencesDataset(self.data_test_path, phrase2vector)\n",
        "\n",
        "    def train_dataloader(self, *args, **kwargs) -> DataLoader:\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
        "        return DataLoader(self.validation_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwuHz1kdXryl"
      },
      "source": [
        "sentences_dm = SentencesDataModule(\n",
        "    data_train_path=dataset_folder+'/train.jsonl',\n",
        "    data_dev_path=dataset_folder+'/dev.jsonl',\n",
        "    data_test_path=dataset_folder+'/dev.jsonl',\n",
        "    batch_size=32,\n",
        ")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVdsB3fBYC_c",
        "outputId": "07107bf6-ce0a-4f8b-8fd4-cb57972ebe6f"
      },
      "source": [
        "sentences_dm.setup('test')\n",
        "test_dataloader = sentences_dm.test_dataloader()\n",
        "# print(word_vectors['test'])\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    X, y = batch\n",
        "    print(batch)\n",
        "    print(f\"batch X shape: {X.shape}\")\n",
        "    print(f\"batch z shape: {y.shape}\")\n",
        "    \n",
        "    \n",
        "    break"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor([[ 0.0720,  0.0442,  0.2484,  ..., -0.4093,  0.4343,  0.0722],\n",
            "        [ 0.0876, -0.2088,  0.2685,  ..., -0.2694,  0.4142,  0.0086],\n",
            "        [-0.1082,  0.1376,  0.2182,  ..., -0.3296,  0.5344,  0.0149],\n",
            "        ...,\n",
            "        [-0.0065,  0.2078,  0.1619,  ..., -0.2311,  0.6040,  0.2938],\n",
            "        [-0.0159, -0.0029,  0.1497,  ..., -0.3368,  0.6026,  0.1131],\n",
            "        [-0.0394,  0.0067,  0.1338,  ..., -0.2512,  0.5939,  0.0027]]), tensor([0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0.,\n",
            "        1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.])]\n",
            "batch X shape: torch.Size([32, 100])\n",
            "batch z shape: torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b45LYx6FZiD"
      },
      "source": [
        "# Non so se training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmfsdUysWYNl"
      },
      "source": [
        "class SentencesClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, n_features: int, n_hidden: int):\n",
        "        super().__init__()\n",
        "        # classification function\n",
        "        self.lin1 = torch.nn.Linear(n_features, n_hidden)\n",
        "        self.output_layer = torch.nn.Linear(n_hidden, 1)\n",
        "        \n",
        "        # criterion\n",
        "        self.loss_fn = torch.nn.BCELoss()\n",
        "        \n",
        "\n",
        "    def forward(self, x: torch.Tensor, y: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:\n",
        "        # actual forward\n",
        "        out = self.lin1(x)\n",
        "        out = torch.relu(out)\n",
        "        # compute logits (which are simply the out variable) and the actual probability distribution (pred, as it is the predicted distribution)\n",
        "    \n",
        "        logits = self.output_layer(out).squeeze(1)\n",
        "\n",
        "        out = torch.sigmoid(logits)\n",
        "\n",
        "        result = {'logits': logits, 'pred': out}\n",
        "\n",
        "        # compute loss\n",
        "        if y is not None:\n",
        "            # torch optimizes its computation internally and takes as input the logits instead\n",
        "            loss = self.loss(out, y)\n",
        "            result['loss'] = loss\n",
        "\n",
        "        return result\n",
        "\n",
        "    def loss(self, pred, y):\n",
        "        return self.loss_fn(pred, y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWqDqb9ibBfo"
      },
      "source": [
        "sent_classifier = SentencesClassifier(\n",
        "    n_features=100, \n",
        "    n_hidden=64\n",
        ")\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-D3B5zgbcKy"
      },
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, optimizer, device):\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        # starts requires_grad for all layers\n",
        "        self.model.train()  # we are using this model for training (some layers have different behaviours in train and eval mode)\n",
        "        self.model.to(self.device)  # move model to GPU if available\n",
        "\n",
        "    def train(self, train_dataset, eval_dataset, epochs=1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            epoch_loss = 0.0\n",
        "            len_train = 0\n",
        "            epoch_val_loss = 0.0\n",
        "            len_val_train = 0\n",
        "            self.model.train()\n",
        "            # each element (sample) in train_dataset is a batch\n",
        "            for step, sample in enumerate(train_dataset):\n",
        "                # inputs in the batch\n",
        "                inputs = sample[0].to(self.device)\n",
        "                # outputs in the batch\n",
        "                targets = sample[1].to(self.device)\n",
        "                output_distribution = self.model(inputs)\n",
        "                loss = self.model.loss(output_distribution['pred'], targets)  # compute loss\n",
        "                # calculates the gradient and accumulates\n",
        "                loss.backward()  # we backpropagate the loss\n",
        "                # updates the parameters\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                len_train += 1\n",
        "            \n",
        "            self.model.eval()\n",
        "            for step, sample in enumerate(eval_dataset):\n",
        "                # inputs in the batch\n",
        "                inputs = sample[0].to(self.device)\n",
        "                # outputs in the batch\n",
        "                targets = sample[1].to(self.device)\n",
        "                output_distribution = self.model(inputs)\n",
        "                loss = self.model.loss(output_distribution['pred'], targets)  # compute loss    \n",
        "                \n",
        "                epoch_val_loss += loss.item()\n",
        "                len_val_train += 1\n",
        "            \n",
        "            avg_epoch_loss = epoch_loss / len_train\n",
        "            avg_eval_loss = epoch_val_loss / len_val_train\n",
        "            print('Epoch: {} avg loss = {:0.4f} eval loss {:0.4f}'.format(epoch, avg_epoch_loss, avg_eval_loss))\n",
        "\n",
        "            train_loss += avg_epoch_loss\n",
        "            # torch.save(self.model.state_dict(),\n",
        "            #            os.path.join(output_folder, 'state_{}.pt'.format(epoch)))  # save the model state\n",
        "\n",
        "        avg_epoch_loss = train_loss / epochs\n",
        "        return avg_epoch_loss"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8df6027b6ad740008892c4a710c1d35a",
            "ff875efd3b6b481790fcb157db4d2693",
            "6f041e77386443828b5f2c7b5d0d07c2",
            "966555d30a244e67a520fbf2a751310f",
            "a7069da085164e0d9b4e059ee1512746",
            "4ce12a7489744714a59b2236fbea1a5b",
            "77949fff5eb84fe9b3f32b4e11d080c7",
            "4c4420460b2e49919a6ab6ecb18b69bc"
          ]
        },
        "id": "VsbMs2tYbxTv",
        "outputId": "feaf167b-425e-4987-8ab4-f334e1a256ad"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "optimizer = torch.optim.SGD(sent_classifier.parameters(), lr=0.02)\n",
        "trainer = Trainer(sent_classifier, optimizer, device)\n",
        "sentences_dm.setup('train')\n",
        "train_dataloader = sentences_dm.test_dataloader()\n",
        "avg_loss = trainer.train(train_dataloader,test_dataloader, epochs=300)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8df6027b6ad740008892c4a710c1d35a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=300.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 avg loss = 0.1599 eval loss 0.1862\n",
            "Epoch: 1 avg loss = 0.1593 eval loss 0.1858\n",
            "Epoch: 2 avg loss = 0.1585 eval loss 0.1857\n",
            "Epoch: 3 avg loss = 0.1583 eval loss 0.1891\n",
            "Epoch: 4 avg loss = 0.1605 eval loss 0.1868\n",
            "Epoch: 5 avg loss = 0.1580 eval loss 0.1851\n",
            "Epoch: 6 avg loss = 0.1573 eval loss 0.1850\n",
            "Epoch: 7 avg loss = 0.1583 eval loss 0.1880\n",
            "Epoch: 8 avg loss = 0.1582 eval loss 0.1846\n",
            "Epoch: 9 avg loss = 0.1574 eval loss 0.1859\n",
            "Epoch: 10 avg loss = 0.1583 eval loss 0.1881\n",
            "Epoch: 11 avg loss = 0.1588 eval loss 0.1854\n",
            "Epoch: 12 avg loss = 0.1564 eval loss 0.1844\n",
            "Epoch: 13 avg loss = 0.1557 eval loss 0.1835\n",
            "Epoch: 14 avg loss = 0.1568 eval loss 0.1843\n",
            "Epoch: 15 avg loss = 0.1551 eval loss 0.1829\n",
            "Epoch: 16 avg loss = 0.1555 eval loss 0.1854\n",
            "Epoch: 17 avg loss = 0.1568 eval loss 0.1840\n",
            "Epoch: 18 avg loss = 0.1545 eval loss 0.1837\n",
            "Epoch: 19 avg loss = 0.1555 eval loss 0.1824\n",
            "Epoch: 20 avg loss = 0.1550 eval loss 0.1816\n",
            "Epoch: 21 avg loss = 0.1546 eval loss 0.1848\n",
            "Epoch: 22 avg loss = 0.1552 eval loss 0.1811\n",
            "Epoch: 23 avg loss = 0.1539 eval loss 0.1811\n",
            "Epoch: 24 avg loss = 0.1536 eval loss 0.1811\n",
            "Epoch: 25 avg loss = 0.1548 eval loss 0.1878\n",
            "Epoch: 26 avg loss = 0.1556 eval loss 0.1828\n",
            "Epoch: 27 avg loss = 0.1527 eval loss 0.1805\n",
            "Epoch: 28 avg loss = 0.1527 eval loss 0.1800\n",
            "Epoch: 29 avg loss = 0.1531 eval loss 0.1819\n",
            "Epoch: 30 avg loss = 0.1533 eval loss 0.1799\n",
            "Epoch: 31 avg loss = 0.1518 eval loss 0.1795\n",
            "Epoch: 32 avg loss = 0.1527 eval loss 0.1798\n",
            "Epoch: 33 avg loss = 0.1521 eval loss 0.1832\n",
            "Epoch: 34 avg loss = 0.1526 eval loss 0.1788\n",
            "Epoch: 35 avg loss = 0.1512 eval loss 0.1791\n",
            "Epoch: 36 avg loss = 0.1514 eval loss 0.1787\n",
            "Epoch: 37 avg loss = 0.1503 eval loss 0.1795\n",
            "Epoch: 38 avg loss = 0.1530 eval loss 0.1819\n",
            "Epoch: 39 avg loss = 0.1502 eval loss 0.1781\n",
            "Epoch: 40 avg loss = 0.1500 eval loss 0.1778\n",
            "Epoch: 41 avg loss = 0.1506 eval loss 0.1785\n",
            "Epoch: 42 avg loss = 0.1510 eval loss 0.1846\n",
            "Epoch: 43 avg loss = 0.1516 eval loss 0.1804\n",
            "Epoch: 44 avg loss = 0.1504 eval loss 0.1770\n",
            "Epoch: 45 avg loss = 0.1500 eval loss 0.1786\n",
            "Epoch: 46 avg loss = 0.1509 eval loss 0.1861\n",
            "Epoch: 47 avg loss = 0.1508 eval loss 0.1768\n",
            "Epoch: 48 avg loss = 0.1486 eval loss 0.1761\n",
            "Epoch: 49 avg loss = 0.1481 eval loss 0.1756\n",
            "Epoch: 50 avg loss = 0.1482 eval loss 0.1778\n",
            "Epoch: 51 avg loss = 0.1486 eval loss 0.1751\n",
            "Epoch: 52 avg loss = 0.1478 eval loss 0.1751\n",
            "Epoch: 53 avg loss = 0.1479 eval loss 0.1755\n",
            "Epoch: 54 avg loss = 0.1473 eval loss 0.1752\n",
            "Epoch: 55 avg loss = 0.1463 eval loss 0.1745\n",
            "Epoch: 56 avg loss = 0.1470 eval loss 0.1769\n",
            "Epoch: 57 avg loss = 0.1502 eval loss 0.1834\n",
            "Epoch: 58 avg loss = 0.1483 eval loss 0.1750\n",
            "Epoch: 59 avg loss = 0.1470 eval loss 0.1767\n",
            "Epoch: 60 avg loss = 0.1479 eval loss 0.1759\n",
            "Epoch: 61 avg loss = 0.1468 eval loss 0.1761\n",
            "Epoch: 62 avg loss = 0.1451 eval loss 0.1733\n",
            "Epoch: 63 avg loss = 0.1449 eval loss 0.1738\n",
            "Epoch: 64 avg loss = 0.1459 eval loss 0.1734\n",
            "Epoch: 65 avg loss = 0.1476 eval loss 0.1780\n",
            "Epoch: 66 avg loss = 0.1441 eval loss 0.1727\n",
            "Epoch: 67 avg loss = 0.1447 eval loss 0.1740\n",
            "Epoch: 68 avg loss = 0.1458 eval loss 0.1736\n",
            "Epoch: 69 avg loss = 0.1449 eval loss 0.1737\n",
            "Epoch: 70 avg loss = 0.1444 eval loss 0.1722\n",
            "Epoch: 71 avg loss = 0.1432 eval loss 0.1713\n",
            "Epoch: 72 avg loss = 0.1440 eval loss 0.1713\n",
            "Epoch: 73 avg loss = 0.1432 eval loss 0.1725\n",
            "Epoch: 74 avg loss = 0.1439 eval loss 0.1702\n",
            "Epoch: 75 avg loss = 0.1441 eval loss 0.1770\n",
            "Epoch: 76 avg loss = 0.1443 eval loss 0.1709\n",
            "Epoch: 77 avg loss = 0.1427 eval loss 0.1702\n",
            "Epoch: 78 avg loss = 0.1426 eval loss 0.1713\n",
            "Epoch: 79 avg loss = 0.1419 eval loss 0.1697\n",
            "Epoch: 80 avg loss = 0.1425 eval loss 0.1742\n",
            "Epoch: 81 avg loss = 0.1452 eval loss 0.1735\n",
            "Epoch: 82 avg loss = 0.1409 eval loss 0.1692\n",
            "Epoch: 83 avg loss = 0.1426 eval loss 0.1720\n",
            "Epoch: 84 avg loss = 0.1418 eval loss 0.1689\n",
            "Epoch: 85 avg loss = 0.1408 eval loss 0.1684\n",
            "Epoch: 86 avg loss = 0.1422 eval loss 0.1721\n",
            "Epoch: 87 avg loss = 0.1398 eval loss 0.1685\n",
            "Epoch: 88 avg loss = 0.1406 eval loss 0.1690\n",
            "Epoch: 89 avg loss = 0.1408 eval loss 0.1682\n",
            "Epoch: 90 avg loss = 0.1406 eval loss 0.1731\n",
            "Epoch: 91 avg loss = 0.1425 eval loss 0.1737\n",
            "Epoch: 92 avg loss = 0.1407 eval loss 0.1668\n",
            "Epoch: 93 avg loss = 0.1404 eval loss 0.1684\n",
            "Epoch: 94 avg loss = 0.1395 eval loss 0.1676\n",
            "Epoch: 95 avg loss = 0.1385 eval loss 0.1664\n",
            "Epoch: 96 avg loss = 0.1396 eval loss 0.1692\n",
            "Epoch: 97 avg loss = 0.1384 eval loss 0.1660\n",
            "Epoch: 98 avg loss = 0.1382 eval loss 0.1669\n",
            "Epoch: 99 avg loss = 0.1374 eval loss 0.1678\n",
            "Epoch: 100 avg loss = 0.1399 eval loss 0.1672\n",
            "Epoch: 101 avg loss = 0.1371 eval loss 0.1655\n",
            "Epoch: 102 avg loss = 0.1373 eval loss 0.1664\n",
            "Epoch: 103 avg loss = 0.1378 eval loss 0.1650\n",
            "Epoch: 104 avg loss = 0.1393 eval loss 0.1744\n",
            "Epoch: 105 avg loss = 0.1387 eval loss 0.1647\n",
            "Epoch: 106 avg loss = 0.1359 eval loss 0.1645\n",
            "Epoch: 107 avg loss = 0.1373 eval loss 0.1688\n",
            "Epoch: 108 avg loss = 0.1370 eval loss 0.1638\n",
            "Epoch: 109 avg loss = 0.1389 eval loss 0.1698\n",
            "Epoch: 110 avg loss = 0.1370 eval loss 0.1720\n",
            "Epoch: 111 avg loss = 0.1387 eval loss 0.1651\n",
            "Epoch: 112 avg loss = 0.1360 eval loss 0.1654\n",
            "Epoch: 113 avg loss = 0.1345 eval loss 0.1625\n",
            "Epoch: 114 avg loss = 0.1353 eval loss 0.1630\n",
            "Epoch: 115 avg loss = 0.1351 eval loss 0.1666\n",
            "Epoch: 116 avg loss = 0.1359 eval loss 0.1632\n",
            "Epoch: 117 avg loss = 0.1341 eval loss 0.1624\n",
            "Epoch: 118 avg loss = 0.1337 eval loss 0.1619\n",
            "Epoch: 119 avg loss = 0.1368 eval loss 0.1682\n",
            "Epoch: 120 avg loss = 0.1332 eval loss 0.1613\n",
            "Epoch: 121 avg loss = 0.1341 eval loss 0.1615\n",
            "Epoch: 122 avg loss = 0.1331 eval loss 0.1611\n",
            "Epoch: 123 avg loss = 0.1329 eval loss 0.1617\n",
            "Epoch: 124 avg loss = 0.1346 eval loss 0.1629\n",
            "Epoch: 125 avg loss = 0.1325 eval loss 0.1604\n",
            "Epoch: 126 avg loss = 0.1327 eval loss 0.1604\n",
            "Epoch: 127 avg loss = 0.1334 eval loss 0.1626\n",
            "Epoch: 128 avg loss = 0.1318 eval loss 0.1604\n",
            "Epoch: 129 avg loss = 0.1316 eval loss 0.1599\n",
            "Epoch: 130 avg loss = 0.1341 eval loss 0.1690\n",
            "Epoch: 131 avg loss = 0.1331 eval loss 0.1595\n",
            "Epoch: 132 avg loss = 0.1329 eval loss 0.1618\n",
            "Epoch: 133 avg loss = 0.1311 eval loss 0.1590\n",
            "Epoch: 134 avg loss = 0.1307 eval loss 0.1588\n",
            "Epoch: 135 avg loss = 0.1304 eval loss 0.1583\n",
            "Epoch: 136 avg loss = 0.1315 eval loss 0.1604\n",
            "Epoch: 137 avg loss = 0.1300 eval loss 0.1584\n",
            "Epoch: 138 avg loss = 0.1307 eval loss 0.1599\n",
            "Epoch: 139 avg loss = 0.1306 eval loss 0.1579\n",
            "Epoch: 140 avg loss = 0.1323 eval loss 0.1619\n",
            "Epoch: 141 avg loss = 0.1297 eval loss 0.1581\n",
            "Epoch: 142 avg loss = 0.1291 eval loss 0.1570\n",
            "Epoch: 143 avg loss = 0.1291 eval loss 0.1580\n",
            "Epoch: 144 avg loss = 0.1293 eval loss 0.1570\n",
            "Epoch: 145 avg loss = 0.1285 eval loss 0.1566\n",
            "Epoch: 146 avg loss = 0.1289 eval loss 0.1569\n",
            "Epoch: 147 avg loss = 0.1291 eval loss 0.1586\n",
            "Epoch: 148 avg loss = 0.1311 eval loss 0.1608\n",
            "Epoch: 149 avg loss = 0.1280 eval loss 0.1561\n",
            "Epoch: 150 avg loss = 0.1278 eval loss 0.1557\n",
            "Epoch: 151 avg loss = 0.1284 eval loss 0.1586\n",
            "Epoch: 152 avg loss = 0.1299 eval loss 0.1582\n",
            "Epoch: 153 avg loss = 0.1268 eval loss 0.1553\n",
            "Epoch: 154 avg loss = 0.1271 eval loss 0.1548\n",
            "Epoch: 155 avg loss = 0.1275 eval loss 0.1551\n",
            "Epoch: 156 avg loss = 0.1274 eval loss 0.1557\n",
            "Epoch: 157 avg loss = 0.1263 eval loss 0.1567\n",
            "Epoch: 158 avg loss = 0.1293 eval loss 0.1581\n",
            "Epoch: 159 avg loss = 0.1265 eval loss 0.1550\n",
            "Epoch: 160 avg loss = 0.1264 eval loss 0.1548\n",
            "Epoch: 161 avg loss = 0.1266 eval loss 0.1595\n",
            "Epoch: 162 avg loss = 0.1269 eval loss 0.1538\n",
            "Epoch: 163 avg loss = 0.1257 eval loss 0.1536\n",
            "Epoch: 164 avg loss = 0.1249 eval loss 0.1539\n",
            "Epoch: 165 avg loss = 0.1249 eval loss 0.1535\n",
            "Epoch: 166 avg loss = 0.1250 eval loss 0.1537\n",
            "Epoch: 167 avg loss = 0.1251 eval loss 0.1525\n",
            "Epoch: 168 avg loss = 0.1255 eval loss 0.1597\n",
            "Epoch: 169 avg loss = 0.1279 eval loss 0.1613\n",
            "Epoch: 170 avg loss = 0.1266 eval loss 0.1531\n",
            "Epoch: 171 avg loss = 0.1245 eval loss 0.1541\n",
            "Epoch: 172 avg loss = 0.1246 eval loss 0.1541\n",
            "Epoch: 173 avg loss = 0.1248 eval loss 0.1538\n",
            "Epoch: 174 avg loss = 0.1230 eval loss 0.1511\n",
            "Epoch: 175 avg loss = 0.1231 eval loss 0.1512\n",
            "Epoch: 176 avg loss = 0.1231 eval loss 0.1509\n",
            "Epoch: 177 avg loss = 0.1259 eval loss 0.1630\n",
            "Epoch: 178 avg loss = 0.1250 eval loss 0.1509\n",
            "Epoch: 179 avg loss = 0.1233 eval loss 0.1507\n",
            "Epoch: 180 avg loss = 0.1222 eval loss 0.1502\n",
            "Epoch: 181 avg loss = 0.1225 eval loss 0.1527\n",
            "Epoch: 182 avg loss = 0.1242 eval loss 0.1538\n",
            "Epoch: 183 avg loss = 0.1223 eval loss 0.1518\n",
            "Epoch: 184 avg loss = 0.1239 eval loss 0.1557\n",
            "Epoch: 185 avg loss = 0.1212 eval loss 0.1492\n",
            "Epoch: 186 avg loss = 0.1220 eval loss 0.1497\n",
            "Epoch: 187 avg loss = 0.1227 eval loss 0.1579\n",
            "Epoch: 188 avg loss = 0.1241 eval loss 0.1511\n",
            "Epoch: 189 avg loss = 0.1205 eval loss 0.1490\n",
            "Epoch: 190 avg loss = 0.1206 eval loss 0.1490\n",
            "Epoch: 191 avg loss = 0.1212 eval loss 0.1497\n",
            "Epoch: 192 avg loss = 0.1214 eval loss 0.1512\n",
            "Epoch: 193 avg loss = 0.1223 eval loss 0.1508\n",
            "Epoch: 194 avg loss = 0.1201 eval loss 0.1486\n",
            "Epoch: 195 avg loss = 0.1194 eval loss 0.1478\n",
            "Epoch: 196 avg loss = 0.1202 eval loss 0.1480\n",
            "Epoch: 197 avg loss = 0.1192 eval loss 0.1493\n",
            "Epoch: 198 avg loss = 0.1201 eval loss 0.1472\n",
            "Epoch: 199 avg loss = 0.1187 eval loss 0.1473\n",
            "Epoch: 200 avg loss = 0.1189 eval loss 0.1469\n",
            "Epoch: 201 avg loss = 0.1209 eval loss 0.1527\n",
            "Epoch: 202 avg loss = 0.1190 eval loss 0.1479\n",
            "Epoch: 203 avg loss = 0.1181 eval loss 0.1462\n",
            "Epoch: 204 avg loss = 0.1183 eval loss 0.1465\n",
            "Epoch: 205 avg loss = 0.1186 eval loss 0.1482\n",
            "Epoch: 206 avg loss = 0.1188 eval loss 0.1456\n",
            "Epoch: 207 avg loss = 0.1196 eval loss 0.1512\n",
            "Epoch: 208 avg loss = 0.1174 eval loss 0.1459\n",
            "Epoch: 209 avg loss = 0.1181 eval loss 0.1452\n",
            "Epoch: 210 avg loss = 0.1192 eval loss 0.1533\n",
            "Epoch: 211 avg loss = 0.1209 eval loss 0.1504\n",
            "Epoch: 212 avg loss = 0.1177 eval loss 0.1474\n",
            "Epoch: 213 avg loss = 0.1164 eval loss 0.1446\n",
            "Epoch: 214 avg loss = 0.1166 eval loss 0.1446\n",
            "Epoch: 215 avg loss = 0.1164 eval loss 0.1447\n",
            "Epoch: 216 avg loss = 0.1168 eval loss 0.1453\n",
            "Epoch: 217 avg loss = 0.1166 eval loss 0.1490\n",
            "Epoch: 218 avg loss = 0.1183 eval loss 0.1455\n",
            "Epoch: 219 avg loss = 0.1167 eval loss 0.1463\n",
            "Epoch: 220 avg loss = 0.1156 eval loss 0.1450\n",
            "Epoch: 221 avg loss = 0.1153 eval loss 0.1436\n",
            "Epoch: 222 avg loss = 0.1155 eval loss 0.1439\n",
            "Epoch: 223 avg loss = 0.1150 eval loss 0.1456\n",
            "Epoch: 224 avg loss = 0.1161 eval loss 0.1431\n",
            "Epoch: 225 avg loss = 0.1148 eval loss 0.1449\n",
            "Epoch: 226 avg loss = 0.1164 eval loss 0.1455\n",
            "Epoch: 227 avg loss = 0.1141 eval loss 0.1429\n",
            "Epoch: 228 avg loss = 0.1160 eval loss 0.1500\n",
            "Epoch: 229 avg loss = 0.1162 eval loss 0.1426\n",
            "Epoch: 230 avg loss = 0.1138 eval loss 0.1420\n",
            "Epoch: 231 avg loss = 0.1141 eval loss 0.1418\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-f1c10a23dfdf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msentences_dm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_dataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences_dm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-22bb25fcf63d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, eval_dataset, epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_distribution\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# compute loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mepoch_val_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                 \u001b[0mlen_val_train\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}