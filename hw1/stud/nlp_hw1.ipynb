{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp-hw1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "_ywAFYy1_jzW"
      ],
      "authorship_tag": "ABX9TyNUUxVMCv8knrzbP9hH/dvB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8806a12988b34c4cb0cdfc0c40d19462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f969bc517d7342deaaddf95c22029847",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_de685432a8704cd09064b92368dee12e",
              "IPY_MODEL_dd22ee28e4114ac7ad42ed4bcb577844"
            ]
          }
        },
        "f969bc517d7342deaaddf95c22029847": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "de685432a8704cd09064b92368dee12e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_604c08927fbe4dc09012f9ad26a9a318",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 100000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 99681,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72218425c7194bce9dbcd282a5c39087"
          }
        },
        "dd22ee28e4114ac7ad42ed4bcb577844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0426fc29d3ea4143bc2405e8e6bbe744",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 99681/100000 [00:15&lt;00:00, 21543.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b58b752673974819be1009ce68f594f9"
          }
        },
        "604c08927fbe4dc09012f9ad26a9a318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72218425c7194bce9dbcd282a5c39087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0426fc29d3ea4143bc2405e8e6bbe744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b58b752673974819be1009ce68f594f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a410a6a6bac24a77a7b7514d23783df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_630c80276fdb4865a9c9d690c919c15f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ebeb604d19af4b2fac389070f87a87e5",
              "IPY_MODEL_3657c94e515d47f99141521ce3bd3cc9"
            ]
          }
        },
        "630c80276fdb4865a9c9d690c919c15f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ebeb604d19af4b2fac389070f87a87e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d5afeeb5a4b340d3a459f20e0883c560",
            "_dom_classes": [],
            "description": "Batch: ",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55d9613e160c42f0b003714a84e93e86"
          }
        },
        "3657c94e515d47f99141521ce3bd3cc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c51bbbd40ff646d8b4c0b367c36bbd81",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/? [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45db296d8a804949bf683e54b40b2fc7"
          }
        },
        "d5afeeb5a4b340d3a459f20e0883c560": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55d9613e160c42f0b003714a84e93e86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c51bbbd40ff646d8b4c0b367c36bbd81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45db296d8a804949bf683e54b40b2fc7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuigiSigillo/nlp2021-hw/blob/master/hw1/stud/nlp_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y_g6ETA_lf3"
      },
      "source": [
        "# imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2n5xn1F5kvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77c04c3f-1043-47b1-9d79-b178afb7000c"
      },
      "source": [
        "from google.colab import drive\n",
        "# general\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import *\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "import json\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import SGD\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "root_folder = '/content/drive/My Drive/NLP/nlp2021-hw1'\n",
        "dataset_folder = os.path.join(root_folder,'data')\n",
        "print(dataset_folder)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/My Drive/NLP/nlp2021-hw1/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nbAnAo7pMvbq"
      },
      "source": [
        "#! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
        "#! unzip -d data/glove.6B\n",
        "#! cd '/content/drive/My Drive/NLP/nlp2021-hw1'\n",
        "#!unzip '/content/drive/My Drive/NLP/nlp2021-hw1/glove.6B.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10W7Xq0CPENx",
        "outputId": "3c54c258-65ba-413e-ddf2-377f1e6f75b8"
      },
      "source": [
        "!mv glove.6B.200d.txt '/content/drive/My Drive/NLP/nlp2021-hw1/model'\n",
        "!ls"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "8806a12988b34c4cb0cdfc0c40d19462",
            "f969bc517d7342deaaddf95c22029847",
            "de685432a8704cd09064b92368dee12e",
            "dd22ee28e4114ac7ad42ed4bcb577844",
            "604c08927fbe4dc09012f9ad26a9a318",
            "72218425c7194bce9dbcd282a5c39087",
            "0426fc29d3ea4143bc2405e8e6bbe744",
            "b58b752673974819be1009ce68f594f9"
          ]
        },
        "id": "Te3_zheKQQDe",
        "outputId": "5b4a00a5-28e6-40ea-ae5b-28d6006148a5"
      },
      "source": [
        "word_vectors = dict()\n",
        "words_limit = 100_000\n",
        "with open('/content/drive/My Drive/NLP/nlp2021-hw1/model/glove.6B.100d.txt') as f:\n",
        "\n",
        "    next(f)  # skip header\n",
        "\n",
        "    for i, line in tqdm(enumerate(f), total=words_limit):\n",
        "\n",
        "        if i == words_limit:\n",
        "            break\n",
        "\n",
        "        word, *vector = line.strip().split(' ')\n",
        "        vector = torch.tensor([float(c) for c in vector])\n",
        "        \n",
        "        word_vectors[word] = vector\n",
        "\n",
        "## alternatives\n",
        "# for l in f:\n",
        "#     line = l.decode().split()\n",
        "#     word = line[0]\n",
        "#     words.append(word)\n",
        "#     word2idx[word] = idx\n",
        "#     idx += 1\n",
        "#     vect = np.array(line[1:]).astype(np.float)\n",
        "#     vectors.append(vect)\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8806a12988b34c4cb0cdfc0c40d19462",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKwgTMzCWGfU"
      },
      "source": [
        "def cosine_similarity(v1: torch.Tensor, v2: torch.Tensor) -> float:\n",
        "    num = torch.sum(v1 * v2)\n",
        "    den = torch.linalg.norm(v1) * torch.linalg.norm(v2)\n",
        "    return (num / den).item()"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wf9mpY2fWI58",
        "outputId": "561be936-6c2c-4bea-f13a-c6a0a73839e8"
      },
      "source": [
        "cosine_similarity(word_vectors['king'], word_vectors['queen'])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7507690787315369"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpsIPHyUV6Lt"
      },
      "source": [
        "def phrase2vector(phrase: str) -> Optional[torch.Tensor]:\n",
        "    phrases_word_vector = [word_vectors[w] for w in phrase.split(' ') if w in word_vectors]\n",
        "    \n",
        "    if len(phrases_word_vector) == 0:\n",
        "        return None\n",
        "\n",
        "    phrases_word_vector = torch.stack(phrases_word_vector)  # tensor shape: (#words X #features)\n",
        "    return torch.mean(phrases_word_vector, dim=0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti80ryeyXUXT"
      },
      "source": [
        "# same class as Notebook 4\n",
        "class AmazonReviewsDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, dataset_path: str, phrase2vector):\n",
        "        self.data_store = []\n",
        "        self.init_structures(dataset_path, phrase2vector)\n",
        "\n",
        "    def init_structures(self, dataset_path: str, phrase2vector) -> None:\n",
        "\n",
        "        with open(dataset_path) as f:\n",
        "            for json_string in f:\n",
        "                single_json = json.loads(json_string)\n",
        "                s1 = single_json['sentence1']\n",
        "                s2 =  single_json['sentence2']\n",
        "                ground_t = 1 if single_json['label'] =='True' else 0\n",
        "                vector1 = phrase2vector(s1)\n",
        "                vector2 = phrase2vector(s2)\n",
        "                if vector is None:\n",
        "                    continue\n",
        "                if vector2 is None:\n",
        "                    continue\n",
        "                self.data_store.append((vector1,vector2,ground_t))\n",
        "    \n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data_store)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
        "        return self.data_store[idx]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8K2TtSOXY13"
      },
      "source": [
        "# same class as Notebook 4\n",
        "class AmazonReviewsDataModule(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        data_train_path: str,\n",
        "        data_dev_path: str,\n",
        "        data_test_path: str,\n",
        "        batch_size: int,\n",
        "        collate_fn=None\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.data_train_path = data_train_path\n",
        "        self.data_dev_path = data_dev_path\n",
        "        self.data_test_path = data_test_path\n",
        "        self.batch_size = batch_size\n",
        "        self.collate_fn = collate_fn\n",
        "\n",
        "        self.train_dataset = None\n",
        "        self.validation_dataset = None\n",
        "        self.test_dataset = None\n",
        "\n",
        "    def setup(self, stage: Optional[str] = None) -> None:\n",
        "        if stage == 'fit':\n",
        "            self.train_dataset = AmazonReviewsDataset(self.data_train_path, phrase2vector)\n",
        "            self.validation_dataset = AmazonReviewsDataset(self.data_dev_path, phrase2vector)\n",
        "        elif stage == 'test':\n",
        "            self.test_dataset = AmazonReviewsDataset(self.data_test_path, phrase2vector)\n",
        "\n",
        "    def train_dataloader(self, *args, **kwargs) -> DataLoader:\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
        "        return DataLoader(self.validation_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
        "        return DataLoader(self.test_dataset, batch_size=self.batch_size)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwuHz1kdXryl"
      },
      "source": [
        "amazon_review_dm = AmazonReviewsDataModule(\n",
        "    data_train_path=dataset_folder+'/train.jsonl',\n",
        "    data_dev_path=dataset_folder+'/dev.jsonl',\n",
        "    data_test_path=dataset_folder+'/dev.jsonl',\n",
        "    batch_size=32,\n",
        ")"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RVdsB3fBYC_c",
        "outputId": "fac9f622-b986-4a2a-c69c-595500612693"
      },
      "source": [
        "amazon_review_dm.setup('test')\n",
        "test_dataloader = amazon_review_dm.test_dataloader()\n",
        "# print(word_vectors['test'])\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    X, y,z = batch\n",
        "    print(f\"batch X shape: {X.shape}\")\n",
        "    print(f\"batch y shape: {z.shape}\")\n",
        "    #print(f\"batch y shape: {z[0]}\")\n",
        "    \n",
        "    break"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "batch X shape: torch.Size([32, 100])\n",
            "batch y shape: torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvJMxf0lABoK"
      },
      "source": [
        "import sklearn\n",
        "\n",
        "# same class as Notebook 4\n",
        "class AmazonReviewClassifier(nn.Module):\n",
        "\n",
        "    REVIEWS_CLASSES = 2\n",
        "\n",
        "    def __init__(self, n_features: int, n_hidden: int):\n",
        "        super().__init__()\n",
        "        # classification function\n",
        "        self.lin1 = torch.nn.Linear(n_features, n_hidden)\n",
        "        self.lin2 = torch.nn.Linear(n_hidden, self.REVIEWS_CLASSES)\n",
        "        \n",
        "        # criterion\n",
        "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
        "        \n",
        "        # metrics\n",
        "        self.val_f1 = sklearn.metrics.f1_score\n",
        "        self.test_f1 = sklearn.metrics.f1_score\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x: torch.Tensor, y: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:\n",
        "        # actual forward\n",
        "        out = self.lin1(x)\n",
        "        out = torch.relu(out)\n",
        "        out = self.lin2(out).squeeze(1)\n",
        "\n",
        "        # compute logits (which are simply the out variable) and the actual probability distribution (pred, as it is the predicted distribution)\n",
        "        logits = out\n",
        "        pred = torch.softmax(logits, dim=-1)\n",
        "\n",
        "        result = {'logits': logits, 'pred': pred}\n",
        "\n",
        "        # compute loss\n",
        "        if y is not None:\n",
        "            # while mathematically the CrossEntropyLoss takes as input the probability distributions,\n",
        "            # torch optimizes its computation internally and takes as input the logits instead\n",
        "            loss = self.loss(logits, y)\n",
        "            result['loss'] = loss\n",
        "\n",
        "        return result\n",
        "\n",
        "    def training_step(\n",
        "        self, \n",
        "        batch: Tuple[torch.Tensor], \n",
        "        batch_idx: int\n",
        "    ) -> torch.Tensor:\n",
        "        forward_output = self.forward(*batch)\n",
        "        return forward_output['loss']\n",
        "\n",
        "    def validation_step(\n",
        "        self, \n",
        "        batch: Tuple[torch.Tensor], \n",
        "        batch_idx: int\n",
        "    ):\n",
        "        forward_output = self.forward(*batch)\n",
        "        \n",
        "        self.val_f1(forward_output['pred'], batch[1])\n",
        "\n",
        "        self.log('val_f1', self.val_f1, prog_bar=True)\n",
        "        self.log('val_loss', forward_output['loss'], prog_bar=True)\n",
        "\n",
        "    def test_step(\n",
        "        self,\n",
        "        batch: Tuple[torch.Tensor],\n",
        "        batch_idx: int\n",
        "    ):\n",
        "        forward_output = self.forward(*batch)\n",
        "        self.test_f1(forward_output['pred'], batch[1])\n",
        "        self.log('test_f1', self.test_f1, prog_bar=True)\n",
        "\n",
        "    def loss(self, pred, y):\n",
        "        return self.loss_fn(pred, y)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.SGD(self.parameters(), lr=0.1, momentum=0.0)\n",
        "        return optimizer"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-pn8_jXA3wj"
      },
      "source": [
        "amazon_review_classifier = AmazonReviewClassifier(\n",
        "    n_features=300, \n",
        "    n_hidden=128\n",
        ")"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENRsBYhCVeBM"
      },
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, optimizer, device):\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        # starts requires_grad for all layers\n",
        "        self.model.train()  # we are using this model for training (some layers have different behaviours in train and eval mode)\n",
        "        self.model.to(self.device)  # move model to GPU if available\n",
        "\n",
        "    def train(self, train_dataset, output_folder, epochs=1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        for epoch in range(epochs):\n",
        "            epoch_loss = 0.0\n",
        "            len_train = 0\n",
        "\n",
        "            # each element (sample) in train_dataset is a batch\n",
        "            for step, sample in tqdm(enumerate(train_dataset), desc=\"Batch\", leave=False):\n",
        "                # inputs in the batch\n",
        "                print(sample)\n",
        "                inputs = sample['inputs']\n",
        "                # outputs in the batch\n",
        "                targets = sample['targets'].to(self.device)\n",
        "\n",
        "                # one_hot_input : batch size X vocab_size\n",
        "                one_hot_input = torch.zeros((inputs.shape[0], VOCAB_SIZE), device=self.device)\n",
        "                # sets the ones corresponding to the input word\n",
        "                for i, x in enumerate(inputs):\n",
        "                    one_hot_input[i, x] = 1\n",
        "\n",
        "                output_distribution = self.model(one_hot_input)\n",
        "                loss = self.model.loss_function(output_distribution, targets)  # compute loss\n",
        "                # calculates the gradient and accumulates\n",
        "                loss.backward()  # we backpropagate the loss\n",
        "                # updates the parameters\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                len_train += 1\n",
        "            avg_epoch_loss = epoch_loss / len_train\n",
        "\n",
        "            print('Epoch: {} avg loss = {:0.4f}'.format(epoch, avg_epoch_loss))\n",
        "\n",
        "            train_loss += avg_epoch_loss\n",
        "            torch.save(self.model.state_dict(),\n",
        "                       os.path.join(output_folder, 'state_{}.pt'.format(epoch)))  # save the model state\n",
        "\n",
        "        avg_epoch_loss = train_loss / epochs\n",
        "        return avg_epoch_loss"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tz_I_YyeVBx0"
      },
      "source": [
        "def get_trainer():\n",
        "\n",
        "    # the PyTorch Lightning Trainer\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    model = amazon_review_classifier\n",
        "\n",
        "    # define an optimizer (stochastic gradient descent) to update the parameters\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=0.02)\n",
        "    trainer = Trainer(model, optimizer, device)\n",
        "\n",
        "\n",
        "    return trainer"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617,
          "referenced_widgets": [
            "a410a6a6bac24a77a7b7514d23783df1",
            "630c80276fdb4865a9c9d690c919c15f",
            "ebeb604d19af4b2fac389070f87a87e5",
            "3657c94e515d47f99141521ce3bd3cc9",
            "d5afeeb5a4b340d3a459f20e0883c560",
            "55d9613e160c42f0b003714a84e93e86",
            "c51bbbd40ff646d8b4c0b367c36bbd81",
            "45db296d8a804949bf683e54b40b2fc7"
          ]
        },
        "id": "5Kazs3MWVF0K",
        "outputId": "1d931b5f-f14e-4fba-f231-aea0bffb2d9c"
      },
      "source": [
        "# and finally we can let the \"trainer\" fit the amazon reviews classifier.\n",
        "trainer = get_trainer()\n",
        "avg_loss = trainer.train(test_dataloader, \"output\", epochs=100)\n",
        "#trainer.fit(model=amazon_review_classifier, datamodule=amazon_review_dm)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a410a6a6bac24a77a7b7514d23783df1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Batch', max=1.0, style=ProgressStyle(deâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "[tensor([[ 0.0777, -0.1355,  0.2992,  ..., -0.2303,  0.3809,  0.0008],\n",
            "        [ 0.0777, -0.1355,  0.2992,  ..., -0.2303,  0.3809,  0.0008],\n",
            "        [-0.1202,  0.0973,  0.3522,  ..., -0.4849,  0.4850,  0.1797],\n",
            "        ...,\n",
            "        [-0.0030,  0.2531,  0.1949,  ..., -0.1160,  0.6354,  0.3582],\n",
            "        [-0.0095,  0.0145,  0.0887,  ..., -0.3209,  0.5519,  0.0739],\n",
            "        [-0.0095,  0.0145,  0.0887,  ..., -0.3209,  0.5519,  0.0739]]), tensor([[ 0.0699,  0.1105,  0.2296,  ..., -0.4752,  0.4540,  0.0984],\n",
            "        [ 0.0975, -0.2821,  0.2379,  ..., -0.3085,  0.4475,  0.0163],\n",
            "        [-0.0973,  0.1742,  0.0963,  ..., -0.1884,  0.5794, -0.1349],\n",
            "        ...,\n",
            "        [-0.0116,  0.1431,  0.1148,  ..., -0.3956,  0.5592,  0.2019],\n",
            "        [-0.0281, -0.0365,  0.2674,  ..., -0.3676,  0.7004,  0.1887],\n",
            "        [-0.0818, -0.0044,  0.1980,  ..., -0.1523,  0.6536, -0.0984]]), tensor([0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 0, 0])]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-103-ac17855c073b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# and finally we can let the \"trainer\" fit the amazon reviews classifier.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_trainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#trainer.fit(model=amazon_review_classifier, datamodule=amazon_review_dm)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-8bc0e29a8629>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_dataset, output_folder, epochs)\u001b[0m\n\u001b[1;32m     22\u001b[0m                 \u001b[0;31m# inputs in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'inputs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                 \u001b[0;31m# outputs in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ywAFYy1_jzW"
      },
      "source": [
        "# load dats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10VWDX4f_i3J"
      },
      "source": [
        "class Word2VecDataset(torch.utils.data.IterableDataset):\n",
        "\n",
        "    def __init__(self, txt_path, vocab_size, unk_token, window_size):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "          txt_file (str): Path to the raw-text file.\n",
        "          vocab_size (int): Maximum amount of words that we want to embed.\n",
        "          unk_token (str): How will unknown words represented (e.g. 'UNK').\n",
        "          window_size (int): Number of words to consider as context.\n",
        "        \"\"\"\n",
        "        self.window_size = window_size\n",
        "        # [[w1,s1, w2,s1, ..., w|s1|,s1], [w1,s2, w2,s2, ..., w|s2|,s2], ..., [w1,sn, ..., w|sn|,sn]]\n",
        "        self.data_words = self.read_data(txt_path)\n",
        "        self.build_vocabulary(vocab_size, unk_token)\n",
        "\n",
        "    def __iter__(self):\n",
        "        sentences = self.data_words\n",
        "        for sentence in sentences:\n",
        "            len_sentence = len(sentence)\n",
        "\n",
        "            for input_idx in range(len_sentence):\n",
        "                current_word = sentence[input_idx]\n",
        "                # must be a word in the vocabulary\n",
        "                if current_word in self.word2id and self.keep_word(current_word):\n",
        "                    # left and right window indices\n",
        "                    min_idx = max(0, input_idx - self.window_size)\n",
        "                    max_idx = min(len_sentence, input_idx + self.window_size)\n",
        "\n",
        "                    window_idxs = [x for x in range(min_idx, max_idx) if x != input_idx]\n",
        "                    for target_idx in window_idxs:\n",
        "                        # must be a word in the vocabulary\n",
        "                        if sentence[target_idx] in self.word2id:\n",
        "                            # index of target word in vocab\n",
        "                            target = self.word2id[sentence[target_idx]]\n",
        "                            # index of input word\n",
        "                            current_word_id = self.word2id[current_word]\n",
        "                            output_dict = {'targets':target, 'inputs':current_word_id}\n",
        "\n",
        "                            yield output_dict\n",
        "\n",
        "    def keep_word(self, word):\n",
        "        '''Implements negative sampling and returns true if we can keep the occurrence as training instance.'''\n",
        "        z = self.frequency[word] / self.tot_occurrences\n",
        "        p_keep = np.sqrt(z / 10e-3) + 1\n",
        "        p_keep *= 10e-3 / z # higher for less frequent instances\n",
        "        return np.random.rand() < p_keep # toss a coin and compare it to p_keep to keep the word\n",
        "\n",
        "    def read_data(self,jsonl_path):\n",
        "        \"\"\"Converts each line in the input file into a list of lists of tokenized words.\"\"\"\n",
        "        data = []\n",
        "        total_words = 0\n",
        "        # tot_lines = self.count_lines(txt_path)\n",
        "        with open(jsonl_path) as f:\n",
        "            for json_string in f:\n",
        "                single_json = json.loads(json_string)\n",
        "                split = self.tokenize_line(single_json['sentence1'])\n",
        "                split2 = self.tokenize_line(single_json['sentence2'])\n",
        "                if split:\n",
        "                    data.append(split)\n",
        "                    total_words += len(split)\n",
        "                if split2:\n",
        "                    data.append(split2)\n",
        "                    total_words += len(split2)\n",
        "        return data\n",
        "\n",
        "\n",
        "    # \"The pen is on the table\" -> [\"the, \"pen\", \"is\", \"on\", \"the\", \"table\"]\n",
        "    def tokenize_line(self, line, pattern='\\W'):\n",
        "        \"\"\"Tokenizes a single line.\"\"\"\n",
        "        return [word.lower() for word in re.split(pattern, line.lower()) if word]\n",
        "\n",
        "    def build_vocabulary(self, vocab_size, unk_token):\n",
        "        \"\"\"Defines the vocabulary to be used. Builds a mapping (word, index) for\n",
        "        each word in the vocabulary.\n",
        "\n",
        "        Args:\n",
        "          vocab_size (int): size of the vocabolary\n",
        "          unk_token (str): token to associate with unknown words\n",
        "        \"\"\"\n",
        "        counter_list = []\n",
        "        # context is a list of tokens within a single sentence\n",
        "        for context in self.data_words:\n",
        "            counter_list.extend(context)\n",
        "        counter = collections.Counter(counter_list)\n",
        "        counter_len = len(counter)\n",
        "        print(\"Number of distinct words: {}\".format(counter_len))\n",
        "\n",
        "        # consider only the (vocab size -1) most common words to build the vocab\n",
        "        dictionary = {key: index for index, (key, _) in enumerate(counter.most_common(vocab_size - 1))}\n",
        "        assert unk_token not in dictionary\n",
        "        # all the other words are mapped to UNK\n",
        "        dictionary[unk_token] = vocab_size - 1\n",
        "        self.word2id = dictionary\n",
        "\n",
        "        # dictionary with (word, frequency) pairs -- including only words that are in the vocabulary\n",
        "        dict_counts = {x: counter[x] for x in dictionary if x is not unk_token}\n",
        "        self.frequency = dict_counts\n",
        "        self.tot_occurrences = sum(dict_counts[x] for x in dict_counts)\n",
        "\n",
        "        print(\"Total occurrences of words in dictionary: {}\".format(self.tot_occurrences))\n",
        "\n",
        "        less_freq_word = min(dict_counts, key=counter.get)\n",
        "        print(\"Less frequent word in dictionary appears {} times ({})\".format(dict_counts[less_freq_word],\n",
        "                                                                              less_freq_word))\n",
        "\n",
        "        # index to word\n",
        "        self.id2word = {value: key for key, value in dictionary.items()}\n",
        "\n",
        "        # data is the text converted to indexes, as list of lists\n",
        "        data = []\n",
        "        # for each sentence\n",
        "        for sentence in self.data_words:\n",
        "            paragraph = []\n",
        "            # for each word in the sentence\n",
        "            for i in sentence:\n",
        "                id_ = dictionary[i] if i in dictionary else dictionary[unk_token]\n",
        "                if id_ == dictionary[unk_token]:\n",
        "                    continue\n",
        "                paragraph.append(id_)\n",
        "            data.append(paragraph)\n",
        "        # list of lists of indices, where each sentence is a list of indices, ignoring UNK\n",
        "        self.data_idx = data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hn_Re8-BUBG"
      },
      "source": [
        "def read_data(jsonl_path):\n",
        "    \"\"\"Converts each line in the input file into a list of lists of tokenized words.\"\"\"\n",
        "    data = []\n",
        "    total_words = 0\n",
        "    # tot_lines = self.count_lines(txt_path)\n",
        "    with open(jsonl_path) as f:\n",
        "        for json_string in f:\n",
        "            single_json = json.loads(json_string)\n",
        "            split = tokenize_line(single_json['sentence1'])\n",
        "            split2 = tokenize_line(single_json['sentence2'])\n",
        "            if split:\n",
        "                data.append(split)\n",
        "                total_words += len(split)\n",
        "            if split2:\n",
        "                data.append(split2)\n",
        "                total_words += len(split2)\n",
        "    return data\n",
        "\n",
        "# \"The pen is on the table\" -> [\"the, \"pen\", \"is\", \"on\", \"the\", \"table\"]\n",
        "def tokenize_line(line, pattern='\\W'):\n",
        "    \"\"\"Tokenizes a single line.\"\"\"\n",
        "    return [word.lower() for word in re.split(pattern, line.lower()) if word]\n",
        "\n",
        "\n",
        "train_data_path = os.path.join(dataset_folder,'train.jsonl')\n",
        "read_data(train_data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBbb2mjjA8GY",
        "outputId": "c40dcb79-ae6d-4088-91ae-36c9fd7c98ec"
      },
      "source": [
        "VOCAB_SIZE = 10_000\n",
        "UNK = 'UNK'\n",
        "train_data_path = os.path.join(dataset_folder,'train.jsonl')\n",
        "dataset = Word2VecDataset(train_data_path, VOCAB_SIZE, UNK, window_size=5)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of distinct words: 27007\n",
            "Total occurrences of words in dictionary: 361796\n",
            "Less frequent word in dictionary appears 4 times (bolivia)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyGtqsT4EivE"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGvrDbbOEwYT"
      },
      "source": [
        ""
      ]
    }
  ]
}