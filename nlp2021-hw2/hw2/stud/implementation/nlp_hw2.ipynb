{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nlp_hw2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "vyY3M7Un0VXu",
        "EnJuu3tbUgvn",
        "L8vzinmvb4x2",
        "xCL-D3DKd1Sj"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0c4bf23057ad473ab513f9bc67d4c06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7695cd1122d647179166cf7d770d33ba",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_51228f8176ef44aba0ecc73ad460d971",
              "IPY_MODEL_855dd996a1084ba3b0395f06f9df8986"
            ]
          }
        },
        "7695cd1122d647179166cf7d770d33ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "51228f8176ef44aba0ecc73ad460d971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_53ee621c5ed8414794226944a67738ff",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ee46b8741402406a8c671f973c94bf26"
          }
        },
        "855dd996a1084ba3b0395f06f9df8986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_53286cfb6620430a8f106f5264b1a918",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:02&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_804742c5a6b34ba6bf3a49c73827c7bf"
          }
        },
        "53ee621c5ed8414794226944a67738ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ee46b8741402406a8c671f973c94bf26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "53286cfb6620430a8f106f5264b1a918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "804742c5a6b34ba6bf3a49c73827c7bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f519da44fee64436896f636be792e378": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a227f1ab5724e20a4944558c48b37d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ba8d4d7cbdd4e5f9549d20164635b6f",
              "IPY_MODEL_c8a96d114a954133b0f21e055873d842"
            ]
          }
        },
        "0a227f1ab5724e20a4944558c48b37d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "8ba8d4d7cbdd4e5f9549d20164635b6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a050022fb6f445e8ad4bd29490b94b6b",
            "_dom_classes": [],
            "description": "Epoch 14: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 25,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 25,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_259fee6a551946c4866c0661a8d2a2c0"
          }
        },
        "c8a96d114a954133b0f21e055873d842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b2a017bef4ac47a99ff41cacb455709d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 25/25 [00:00&lt;00:00, 33.14it/s, loss=0.217, v_num=13, valid_loss=0.298, train_loss=0.157]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c526908e95664bc6a14353020c1dfcf0"
          }
        },
        "a050022fb6f445e8ad4bd29490b94b6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "259fee6a551946c4866c0661a8d2a2c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b2a017bef4ac47a99ff41cacb455709d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c526908e95664bc6a14353020c1dfcf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6cae1b17cdce42748e138ea55fe0fb0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a24b79816a5e42adb07961877700f73e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc713dbb4f9e4f2194ea331b92b1cb8e",
              "IPY_MODEL_d9918212c34b43609cbd1852affb12a5"
            ]
          }
        },
        "a24b79816a5e42adb07961877700f73e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "dc713dbb4f9e4f2194ea331b92b1cb8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_adc4a76f848446afa41e9b5df329b7aa",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4db07fca272f42709f96d0cb3746a7dd"
          }
        },
        "d9918212c34b43609cbd1852affb12a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5ddd1e2f4c8d403baacd0f86af6d5ebf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 69.28it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_93d49f4bea9641e8be5a15731ed75edb"
          }
        },
        "adc4a76f848446afa41e9b5df329b7aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4db07fca272f42709f96d0cb3746a7dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5ddd1e2f4c8d403baacd0f86af6d5ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "93d49f4bea9641e8be5a15731ed75edb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0f5750bf236b41faa911919cd4a25431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_63b86f1ccae94e9580443bf874acac0e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_aac8486269344931a856aea6eb20c84c",
              "IPY_MODEL_23c245ccb0f94774a78c51bae01c3e25"
            ]
          }
        },
        "63b86f1ccae94e9580443bf874acac0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "aac8486269344931a856aea6eb20c84c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_de59041788a84587a134ad67107560ec",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8f318ec75bd144c399c6b373723bd482"
          }
        },
        "23c245ccb0f94774a78c51bae01c3e25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0d12e8b9ef9c4f6eb4afc102ec016d84",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 68.51it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcfdab36321445a086d93ecb51be4598"
          }
        },
        "de59041788a84587a134ad67107560ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8f318ec75bd144c399c6b373723bd482": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0d12e8b9ef9c4f6eb4afc102ec016d84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcfdab36321445a086d93ecb51be4598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c1c842eee22b413d89bc3ccc0053ee44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c4a265f4bb4414caa7441ff831e7ecb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_15121694dd384373bc7d4e91632f8c4a",
              "IPY_MODEL_56e52cd286f14d94a2f92e97c2a42411"
            ]
          }
        },
        "6c4a265f4bb4414caa7441ff831e7ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "15121694dd384373bc7d4e91632f8c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_40027d83a11f449180e4fb1a22256781",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d323420e97d44eac97750215eebce5cd"
          }
        },
        "56e52cd286f14d94a2f92e97c2a42411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58fea9252c2746a186bb8eb0a6f0e45f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 66.80it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22720204b6ff4563bb0506642bd59158"
          }
        },
        "40027d83a11f449180e4fb1a22256781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d323420e97d44eac97750215eebce5cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58fea9252c2746a186bb8eb0a6f0e45f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22720204b6ff4563bb0506642bd59158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad3eba9005ac4566b4c0e198f0754012": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_03977f63588b4e619f9effd308b8a333",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b3f3f55086b4ed2baa27a5b13f8f057",
              "IPY_MODEL_148868898ca648c387ef128e6c252f18"
            ]
          }
        },
        "03977f63588b4e619f9effd308b8a333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "5b3f3f55086b4ed2baa27a5b13f8f057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b94cc7f3118c4108b828388728c79249",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_df643593f2a94d9ebb8f5c9a46fe4e26"
          }
        },
        "148868898ca648c387ef128e6c252f18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_122c5665787a4bb3878615f150aa30a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 75.11it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b84e5903d06d4d01998849a55319592a"
          }
        },
        "b94cc7f3118c4108b828388728c79249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "df643593f2a94d9ebb8f5c9a46fe4e26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "122c5665787a4bb3878615f150aa30a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b84e5903d06d4d01998849a55319592a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ec12ba2017f40c58e3e33a37516dc83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6314d6e64f6242d797903f61410cd788",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f3abf8ee1e2a468abdb47f4db0770388",
              "IPY_MODEL_5510b00235c14f56a619bb86874be7c9"
            ]
          }
        },
        "6314d6e64f6242d797903f61410cd788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "f3abf8ee1e2a468abdb47f4db0770388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0bce419e0a5440738bb14c7323fe55d8",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8bcc48ee2104b15b4f3aeba50e445ca"
          }
        },
        "5510b00235c14f56a619bb86874be7c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d98a9e07c4d14b36ab9977bf5cac74dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 72.40it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_132c75c981164d8bbe233e18ccc5bbbe"
          }
        },
        "0bce419e0a5440738bb14c7323fe55d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8bcc48ee2104b15b4f3aeba50e445ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d98a9e07c4d14b36ab9977bf5cac74dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "132c75c981164d8bbe233e18ccc5bbbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48b9874749ff4526a14d54418ac7b0ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ae0290c2b2e04a3d9550ddcf212d09f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8641917c17404eac9d98a5ebbab99d82",
              "IPY_MODEL_3237c45d09d44de5a7f762b923c188c2"
            ]
          }
        },
        "ae0290c2b2e04a3d9550ddcf212d09f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "8641917c17404eac9d98a5ebbab99d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6c90e4cc1b64479c8648e0842f359621",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_381e5e1f66304c8ca472b4da973a77a8"
          }
        },
        "3237c45d09d44de5a7f762b923c188c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_448d2335aa7942be887927f4e9f2225c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 64.96it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a268972dffea43df8eb62ff6f01bd050"
          }
        },
        "6c90e4cc1b64479c8648e0842f359621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "381e5e1f66304c8ca472b4da973a77a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "448d2335aa7942be887927f4e9f2225c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a268972dffea43df8eb62ff6f01bd050": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2f0d813832d2449d88e0e91d8f10324d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3d24578cfd24035b7b7d269835f99a8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fda0662d93b94738869ff7fd035bbe37",
              "IPY_MODEL_8c935faf5e614192933892f5b8572748"
            ]
          }
        },
        "f3d24578cfd24035b7b7d269835f99a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "fda0662d93b94738869ff7fd035bbe37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_911b2c10e4e143e6b17c6584ad6629f2",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2fc5476216f14190ad48879ab17cad8d"
          }
        },
        "8c935faf5e614192933892f5b8572748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1e5cd41b4d9a451da41ddc7bc3f3a6ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 65.30it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eeeaae8dfc604dc883ada2912324ee5f"
          }
        },
        "911b2c10e4e143e6b17c6584ad6629f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2fc5476216f14190ad48879ab17cad8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e5cd41b4d9a451da41ddc7bc3f3a6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eeeaae8dfc604dc883ada2912324ee5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d6f20357f3bd48c8b0fa3fc95b67082a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_80e27c02426b4717a60987598fb6c9b9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4c2b765340dd429cab6dd2ffc7de0bd3",
              "IPY_MODEL_8b45102d4350487a942719fa88b53eaf"
            ]
          }
        },
        "80e27c02426b4717a60987598fb6c9b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "4c2b765340dd429cab6dd2ffc7de0bd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ec168f901fbf463bac9e0301b557b42f",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae448f418d5247fdaca3b5041054454f"
          }
        },
        "8b45102d4350487a942719fa88b53eaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21db503b8aa743b3b79aeeb6dbc54f1b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 71.04it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ddfa9df8fd1148ac99f1613d8b719cbe"
          }
        },
        "ec168f901fbf463bac9e0301b557b42f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae448f418d5247fdaca3b5041054454f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21db503b8aa743b3b79aeeb6dbc54f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ddfa9df8fd1148ac99f1613d8b719cbe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8c41ee7b83244f8489ce7e1212d51b63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1f58d9b2ac29461880e9af4a16e7dd7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5ad4918bf25c40909c5ac391af20d54d",
              "IPY_MODEL_9ca1c3f3e88e4d3f863774c2fb6a9a16"
            ]
          }
        },
        "1f58d9b2ac29461880e9af4a16e7dd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "5ad4918bf25c40909c5ac391af20d54d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ff1ad62fa9dc4c3a9a6fefb8d453124e",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b74f0c6bdbf4d95a1fabff0986f5bf9"
          }
        },
        "9ca1c3f3e88e4d3f863774c2fb6a9a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e89b05cf437a4215b910c9715b434e86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 67.71it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34c8ff4dbe0a4aeaae12ad2bd5af4ad5"
          }
        },
        "ff1ad62fa9dc4c3a9a6fefb8d453124e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b74f0c6bdbf4d95a1fabff0986f5bf9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e89b05cf437a4215b910c9715b434e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34c8ff4dbe0a4aeaae12ad2bd5af4ad5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a2e570e541b94799b52b60865b742e75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ded769bc281042d586586514e20a7f13",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_03ef2c01a5954c3aba324d318257d349",
              "IPY_MODEL_8d1dbed7852642cd888cb8661edcd74b"
            ]
          }
        },
        "ded769bc281042d586586514e20a7f13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "03ef2c01a5954c3aba324d318257d349": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e796e51e65941a097549efd912cdbfb",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6d47e17827564c70a71d93b7364f47f5"
          }
        },
        "8d1dbed7852642cd888cb8661edcd74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c467b5caa12641b090d930c84d6daa40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 70.90it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05c3220e0fa241f8b5e99a2252e424af"
          }
        },
        "3e796e51e65941a097549efd912cdbfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6d47e17827564c70a71d93b7364f47f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c467b5caa12641b090d930c84d6daa40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05c3220e0fa241f8b5e99a2252e424af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e677b5a87f8347b7bda654c38e8e8d05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4052f281c8e34ef7840eb663357b99ab",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be72946ca26a48a5a615aabb33c7c312",
              "IPY_MODEL_c68af7eb97cc40fa8ef11da79116b320"
            ]
          }
        },
        "4052f281c8e34ef7840eb663357b99ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "be72946ca26a48a5a615aabb33c7c312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_86f38478060448aca913855860532574",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1b93b52b28e4fc1bbaf5fdb0cd3cb5b"
          }
        },
        "c68af7eb97cc40fa8ef11da79116b320": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7481780b1ea045a0b4063b362bc200fd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 87.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a23610d2fb134c29be5072486d24a95a"
          }
        },
        "86f38478060448aca913855860532574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1b93b52b28e4fc1bbaf5fdb0cd3cb5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7481780b1ea045a0b4063b362bc200fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a23610d2fb134c29be5072486d24a95a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a18d3b1eca74753828bd2fffd3f1b91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_367b3f070bd243b699724f89524eb8eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bc68a1d07d4a4786887a461ea31681fb",
              "IPY_MODEL_01de6113e7af4e97abacd51dd6308095"
            ]
          }
        },
        "367b3f070bd243b699724f89524eb8eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "bc68a1d07d4a4786887a461ea31681fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_65b20a8e91734494ae114ac318e7a83f",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08b26668b79d475ebcdeea6e8848f1fd"
          }
        },
        "01de6113e7af4e97abacd51dd6308095": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1ab0c6ae0dce4e23b168e6ca7410bcbc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 73.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5b25cf7e40d48058b1a573a182b19ea"
          }
        },
        "65b20a8e91734494ae114ac318e7a83f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08b26668b79d475ebcdeea6e8848f1fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1ab0c6ae0dce4e23b168e6ca7410bcbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5b25cf7e40d48058b1a573a182b19ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "09d3376ad7574cda8f3a88bfd7dfd704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2c72f4859ab5438aa312a866158c46af",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_921d980f967445b49a992e0845ffebf7",
              "IPY_MODEL_d1403025814443879bfedb0823b0579a"
            ]
          }
        },
        "2c72f4859ab5438aa312a866158c46af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "921d980f967445b49a992e0845ffebf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b19ca45847954b9888fe881a5c8cfb02",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ccc0026ab454fa5b1e58d78d799c581"
          }
        },
        "d1403025814443879bfedb0823b0579a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2cf78c7867254befada06275ac839f0b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 70.07it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ac1dcdd1e3ce4db4bc70ce3747380e23"
          }
        },
        "b19ca45847954b9888fe881a5c8cfb02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ccc0026ab454fa5b1e58d78d799c581": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2cf78c7867254befada06275ac839f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ac1dcdd1e3ce4db4bc70ce3747380e23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "171efa233c084ca9b160561955c4ea2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6332d071d196421ebd485b8fda0eb266",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b5a1447ee5874e23ac5e805c5a222c6c",
              "IPY_MODEL_ab931d676d75474b98b6d3b7859b89c1"
            ]
          }
        },
        "6332d071d196421ebd485b8fda0eb266": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "b5a1447ee5874e23ac5e805c5a222c6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9a3c6c6f382045a78545ab7ef0c6a613",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_843c5203e3dd4095b3ca38650182f885"
          }
        },
        "ab931d676d75474b98b6d3b7859b89c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b355897c3e294cf086593598fa4e283b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 61.50it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b9f3c6900d46425cb41a6969829e3f8a"
          }
        },
        "9a3c6c6f382045a78545ab7ef0c6a613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "843c5203e3dd4095b3ca38650182f885": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b355897c3e294cf086593598fa4e283b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b9f3c6900d46425cb41a6969829e3f8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3047922046c448baace8acb02b6c759c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7851c936c30946debc5d215309faa142",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_19a3cc9aa60148619bef053d54584108",
              "IPY_MODEL_834f2d527f37421ca4bb11b586c883cb"
            ]
          }
        },
        "7851c936c30946debc5d215309faa142": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "19a3cc9aa60148619bef053d54584108": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_38c6cb5c482748498b5aa35100f3ccc6",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 5,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f827502737634ef987a5f0b2b7429a36"
          }
        },
        "834f2d527f37421ca4bb11b586c883cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_58eaff872b1a4141acd24f6ecd2379eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 5/5 [00:00&lt;00:00, 74.42it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dc7e9383245048529c35306a6aa9d399"
          }
        },
        "38c6cb5c482748498b5aa35100f3ccc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f827502737634ef987a5f0b2b7429a36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "58eaff872b1a4141acd24f6ecd2379eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dc7e9383245048529c35306a6aa9d399": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "682d231fd2ac457cbd91075bf097cdd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fb98503a1284e0a8e7dc5ba739b0c5f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_561cf0f183714a6a98adfc87f6fe7ad8",
              "IPY_MODEL_6b9d83fb359c4687adf6bf14a7ad4938"
            ]
          }
        },
        "4fb98503a1284e0a8e7dc5ba739b0c5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "561cf0f183714a6a98adfc87f6fe7ad8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5ba0d42dc42a4b868c6c0c050610596c",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8ab4af71149418b9935de1af76d7c2f"
          }
        },
        "6b9d83fb359c4687adf6bf14a7ad4938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8fbf6108dda04800bb7c922552a0c06f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:24&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6e742a4dbbab472296cc3e18c9cb1caa"
          }
        },
        "5ba0d42dc42a4b868c6c0c050610596c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8ab4af71149418b9935de1af76d7c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8fbf6108dda04800bb7c922552a0c06f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6e742a4dbbab472296cc3e18c9cb1caa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6639cf669b91431ba7e65b4e21a7e05d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_630c24c32c8b434a91abf8952c750e38",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_688d29acd1fe4d0fb55162ae0003ae66",
              "IPY_MODEL_1aa4fc94c24d45ff95e393b06cf275e2"
            ]
          }
        },
        "630c24c32c8b434a91abf8952c750e38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "688d29acd1fe4d0fb55162ae0003ae66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f9831b7785da4105ac75673904561cc7",
            "_dom_classes": [],
            "description": "Epoch 2: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 113,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 113,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3659c9aafa834ebc8f4dce423fe05ac0"
          }
        },
        "1aa4fc94c24d45ff95e393b06cf275e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dbe15891353b4ac3a00900c0a40d4d17",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 113/113 [34:21&lt;00:00, 18.24s/it, loss=0.152, v_num=3, val_loss=0.150, train_loss=0.135]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_91c0d02b549649a5914e14f1eadfb831"
          }
        },
        "f9831b7785da4105ac75673904561cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3659c9aafa834ebc8f4dce423fe05ac0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbe15891353b4ac3a00900c0a40d4d17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "91c0d02b549649a5914e14f1eadfb831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "975c81bedb094f2ba91fdb1fa0b59910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f3a96835683944fca8d36fc2a27a241c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b0f2dc7d2f44d0fb1df9a9fce900020",
              "IPY_MODEL_85d821827b094fbbb0136d7473ff0fbc"
            ]
          }
        },
        "f3a96835683944fca8d36fc2a27a241c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "5b0f2dc7d2f44d0fb1df9a9fce900020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_08b486b1d68c4d339a696274dd614a78",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 34,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 34,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_60fed79d68f54041b4a9b54d822fbb31"
          }
        },
        "85d821827b094fbbb0136d7473ff0fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d1730504e3645a088685c8e35f6f34d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 34/34 [00:01&lt;00:00, 25.28it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_54ece2437df546ac85038009c2a63f42"
          }
        },
        "08b486b1d68c4d339a696274dd614a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "60fed79d68f54041b4a9b54d822fbb31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d1730504e3645a088685c8e35f6f34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "54ece2437df546ac85038009c2a63f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9790a66e88a14e83b8a40f59175c9e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97374d53cba44b628ec24fb1d7ac2a4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bcfb1277c63144198533777ecee7efac",
              "IPY_MODEL_4f9a12829b5a48a8ae8eb1f15d64010a"
            ]
          }
        },
        "97374d53cba44b628ec24fb1d7ac2a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "bcfb1277c63144198533777ecee7efac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a71d6ceade7a464481f9318e6ec66477",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 34,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 34,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4732df9c5454e67b07f1c98bb233283"
          }
        },
        "4f9a12829b5a48a8ae8eb1f15d64010a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e918cd0899dc43b9b2be95babe02627e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 34/34 [00:01&lt;00:00, 25.87it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b55de595d324fa6ab7aa0e841ec4b3a"
          }
        },
        "a71d6ceade7a464481f9318e6ec66477": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4732df9c5454e67b07f1c98bb233283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e918cd0899dc43b9b2be95babe02627e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b55de595d324fa6ab7aa0e841ec4b3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0415aed3e61d4644af2266d8bbc3a6a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f1da48a6aec4e468fc1ee436f2820f2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f45eff8183f74537b8e7de052f37ac28",
              "IPY_MODEL_c8d73fa3b8e847d099dc6d3e3c9ea75b"
            ]
          }
        },
        "0f1da48a6aec4e468fc1ee436f2820f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "f45eff8183f74537b8e7de052f37ac28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5fcda640ec724cfca83399605978142c",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 34,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 34,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_22961161f6744ed1803f495773672b96"
          }
        },
        "c8d73fa3b8e847d099dc6d3e3c9ea75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3a7b59ed13104aabb0359273d9af802d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 34/34 [00:01&lt;00:00, 25.78it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_de74826bd170494683392a915a4924f5"
          }
        },
        "5fcda640ec724cfca83399605978142c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "22961161f6744ed1803f495773672b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a7b59ed13104aabb0359273d9af802d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "de74826bd170494683392a915a4924f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuigiSigillo/nlp2021-hw/blob/master/nlp2021-hw2/hw2/stud/implementation/nlp_hw2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyM39Hb89WdF"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2n5xn1F5kvq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "62464dd6-2245-406e-b81c-1322f9f7f6ac"
      },
      "source": [
        "from google.colab import drive\n",
        "# general\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import *\n",
        "import string\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader,SequentialSampler\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# torch text\n",
        "!pip install torchtext --upgrade\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "from pprint import pprint\n",
        "from torchtext.vocab import *\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "!pip install pytorch_lightning\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# SKLEARN\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "from sklearn.metrics import precision_score as sk_precision\n",
        "\n",
        "# transformers\n",
        "!pip install transformers\n",
        "from transformers import DistilBertTokenizerFast, BertTokenizerFast\n",
        "from transformers import DistilBertForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertForTokenClassification\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from transformers import BertModel,get_linear_schedule_with_warmup\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torchtext in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied, skipping upgrade: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchtext) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Collecting pytorch_lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/3d/af3ea8cbd7c3cbb2b50d667062e70980ff56b50b835caf2c80e5da33a1ef/pytorch_lightning-1.3.4-py3-none-any.whl (806kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.41.1)\n",
            "Collecting pyDeprecate==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/14/52/aa227a0884df71ed1957649085adf2b8bc2a1816d037c2f18b3078854516/pyDeprecate-0.3.0-py3-none-any.whl\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 48.2MB/s \n",
            "\u001b[?25hCollecting PyYAML<=5.4.1,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 45.6MB/s \n",
            "\u001b[?25hCollecting tensorboard!=2.5.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/21/eebd23060763fedeefb78bc2b286e00fa1d8abda6f70efa2ee08c28af0d4/tensorboard-2.4.1-py3-none-any.whl (10.6MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6MB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.8.1+cu101)\n",
            "Collecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e8/513cd9d0b1c83dc14cd8f788d05cd6a34758d4fd7e4f9e5ecd5d7d599c95/torchmetrics-0.3.2-py3-none-any.whl (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 53.8MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 56.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch_lightning) (2.4.7)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.3.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.30.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.34.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (57.0.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_lightning) (3.7.4.3)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (2.10)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 47.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]>=2021.4.0->pytorch_lightning) (21.2.0)\n",
            "Collecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 58.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=ccee5267ab8b041d449f8730d21872a73ddff015806292e30425015ea4d5547d\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built future\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorboard~=2.5, but you'll have tensorboard 2.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: pyDeprecate, future, PyYAML, tensorboard, torchmetrics, multidict, yarl, async-timeout, aiohttp, fsspec, pytorch-lightning\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.5.0 future-0.18.2 multidict-5.1.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.4 tensorboard-2.4.1 torchmetrics-0.3.2 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\r\u001b[K     |▏                               | 10kB 25.8MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 25.8MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 18.0MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 15.1MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 8.9MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 9.2MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 10.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 10.4MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 8.7MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 8.7MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 8.7MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 8.7MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 8.7MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 8.7MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 8.7MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▍                            | 235kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 8.7MB/s eta 0:00:01\r\u001b[K     |███▉                            | 266kB 8.7MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 8.7MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▎                           | 296kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 8.7MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 368kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 399kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 430kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 471kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 501kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 532kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 593kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 604kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 665kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 696kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 727kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 737kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 757kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 768kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 798kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819kB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 829kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 839kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 860kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 870kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 890kB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 901kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 931kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 942kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 962kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 972kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 993kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.4MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.4MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.4MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.5MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.5MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.5MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.6MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.6MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.6MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.6MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.7MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.7MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.7MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.8MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.8MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.8MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.9MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.9MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.9MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.9MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.9MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.9MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.0MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.1MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.2MB 8.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 50.4MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 52.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7lIQtGqAoLS"
      },
      "source": [
        "Set up of seeds and  folders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPQc6F08AlBP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00343b38-3eff-4a8d-8b3e-690399536c1d"
      },
      "source": [
        "root_folder = '/content/drive/My Drive/NLP/nlp2021-hw2'\n",
        "dataset_folder = os.path.join(root_folder,'data')\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True  \n",
        "\n",
        "model_b = False\n",
        "\n",
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun  7 11:01:05 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   45C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMcutM72NGcI"
      },
      "source": [
        "# TASK A-B (Bi-LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyY3M7Un0VXu"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un8I8KTkr1zR"
      },
      "source": [
        "class BiLSTMDataset(Dataset):\n",
        "\n",
        "    def __init__(self, \n",
        "                 data_path:str,\n",
        "                 window_size:int, \n",
        "                 window_shift:int=-1,\n",
        "                 model_b:bool=False,\n",
        "                 device=\"cuda\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_path (string): The path containing the data\n",
        "            window_size (integer): The maximum length of a sentence in terms of number of tokens.\n",
        "            window_shift (integer): The number of tokens we shift the window over the sentence. Default value is -1 meaning that the window will be shifted by window_size.\n",
        "            model_b:bool=False,\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        self.window_size = window_size\n",
        "        self.window_shift = window_shift if window_shift > 0 else window_size\n",
        "        self.model_b = model_b\n",
        "\n",
        "        sentences = self.load_data(data_path)\n",
        "        self.device = device\n",
        "        self.data = self.create_windows(sentences)\n",
        "        self.encoded_data = None\n",
        "    \n",
        "\n",
        "    def remove_stopwords(self,sent: str) -> str:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        # remove punkt\n",
        "        others = \"–\" +\"—\" + \"−\" + \"’\" + \"”\" + \"“\" #These chars arent inside the standard punctuation\n",
        "        str_punkt = string.punctuation+ others\n",
        "        translator = str.maketrans(str_punkt, ' '*len(str_punkt)) \n",
        "        word_tokens = word_tokenize(sent.translate(translator)) \n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        return filtered_sentence\n",
        "\n",
        "    def load_data(self,data_path):\n",
        "        \"\"\" \n",
        "        Args:\n",
        "            data_path \n",
        "        \"\"\"\n",
        "        sentences = []\n",
        "        with open(data_path) as json_file:\n",
        "            list_of_sentences = json.load(json_file)\n",
        "            for obj in list_of_sentences:\n",
        "                _sentence = []\n",
        "                #lemmatized = [lemmatizer.lemmatize(w)  for w in obj['text'].split(\" \")]\n",
        "                lemmatized = self.remove_stopwords(obj['text'])\n",
        "                for t in lemmatized:\n",
        "                    ne_label = \"O\"\n",
        "                    sentiment = \"\"\n",
        "                    for i in range(len(obj['targets'])):\n",
        "                        lemmatized_target = lemmatizer.lemmatize(obj['targets'][i][1])\n",
        "                        if t in lemmatized_target:\n",
        "                            ne_label = \"B\" if t == lemmatized_target.split(\" \")[0] else \"I\"\n",
        "                            try:\n",
        "                                if ne_label == \"I\" and _sentence[-1][\"ne_label\"] == \"O\":\n",
        "                                    ne_label = \"O\"\n",
        "                            except:\n",
        "                                ne_label = \"O\"\n",
        "                                \n",
        "                            sentiment = obj['targets'][i][2]\n",
        "                            #embed sentiment directly into the position of word\n",
        "                            if self.model_b and ne_label != \"O\":\n",
        "                                ne_label = ne_label +\"-\"+sentiment\n",
        "                    token = {\"token\": t, \"ne_label\": ne_label , \"sentiment\" :sentiment}\n",
        "                    _sentence.append(token)\n",
        "                sentences.append(_sentence)\n",
        "            return sentences\n",
        "\n",
        "    def create_windows(self, sentences): # to save space in memory ? why we do not load directly all the sentence?\n",
        "        \"\"\" \n",
        "        Args:\n",
        "            sentences (list of lists of dictionaries, where each dictionary represents a word occurrence)\n",
        "        \"\"\"\n",
        "        data = []\n",
        "        for sentence in sentences:\n",
        "            for i in range(0, len(sentence), self.window_shift):\n",
        "                window = sentence[i:i+self.window_size]\n",
        "                if len(window) < self.window_size:\n",
        "                    window = window + [None]*(self.window_size - len(window))  # to match the same length of sentences\n",
        "                assert len(window) == self.window_size\n",
        "                data.append(window)\n",
        "        return data\n",
        "\n",
        "\n",
        "    def index_dataset(self, l_vocabulary, l_label_vocabulary):\n",
        "        self.encoded_data = list()\n",
        "        for i in range(len(self.data)):\n",
        "            # for each window\n",
        "            sentence = self.data[i]\n",
        "            encoded_sentence = torch.LongTensor(self.encode_text(sentence, l_vocabulary)).to(self.device)\n",
        "            \n",
        "            # for each element d in the elem window (d is a dictionary with the various fields from the CoNLL line) \n",
        "            encoded_labels = torch.LongTensor([l_label_vocabulary[d[\"ne_label\"]] if d is not None else l_label_vocabulary[\"<pad>\"] for d in sentence]).to(self.device)\n",
        "            \n",
        "            self.encoded_data.append({\"inputs\":encoded_sentence, \"outputs\":encoded_labels})\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def encode_text(sentence:list, l_vocabulary:Vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (list): list of OrderedDict, each carrying the information about one token.\n",
        "            l_vocabulary (Vocab): vocabulary with mappings from words to indices and viceversa.\n",
        "        Return:\n",
        "            The method returns a list of indices corresponding to the input tokens.\n",
        "        \"\"\"\n",
        "        indices = list()\n",
        "        for w in sentence:\n",
        "            if w is None:\n",
        "                indices.append(l_vocabulary[\"<pad>\"])\n",
        "            elif w[\"token\"] in l_vocabulary.stoi: # vocabulary string to integer (necessary to search faster)\n",
        "                indices.append(l_vocabulary[w[\"token\"]])\n",
        "            else:\n",
        "                indices.append(l_vocabulary[\"<unk>\"])\n",
        "        return indices\n",
        "\n",
        "    \n",
        "    @staticmethod\n",
        "    def decode_output(outputs:torch.Tensor,\n",
        "                    l_label_vocabulary: Vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            outputs (Tensor): a Tensor with shape (batch_size, max_len, label_vocab_size)\n",
        "                containing the logits outputed by the neural network.\n",
        "            l_label_vocabulary (Vocab): is the vocabulary containing the mapping from\n",
        "            a string label to its corresponding index and vice versa\n",
        "        Output:\n",
        "            The method returns a list of batch_size length where each element is a list\n",
        "            of labels, one for each input token.\n",
        "        \"\"\"\n",
        "        max_indices = torch.argmax(outputs, -1).tolist() # shape = (batch_size, max_len)\n",
        "        predictions = list()\n",
        "        for indices in max_indices:\n",
        "            # vocabulary integer to string is used to obtain the corresponding word from the max index\n",
        "            predictions.append([l_label_vocabulary.itos[i] for i in indices])\n",
        "        return predictions\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded_data[idx]\n",
        "    \n",
        "    def get_raw_element(self, idx):\n",
        "        return self.data[idx]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBLYwPsIUNtJ"
      },
      "source": [
        "testing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FiMnels7u3L_",
        "outputId": "feb396a2-6ad4-47f2-9913-b3553a01c356"
      },
      "source": [
        "training_file = dataset_folder+\"/laptops_train.json\"\n",
        "\n",
        "def test_dataset_class(training_file):\n",
        "    \n",
        "    window_size, window_shift = 10, 10\n",
        "\n",
        "    dataset = BiLSTMDataset(training_file, window_size, window_shift, model_b)\n",
        "    \n",
        "    print('Dataset test:')\n",
        "    for i in range(10):\n",
        "        print('  sample {}: {}'.format(i, [t[\"token\"] + \":\" +  t[\"ne_label\"] + \"-\"+ t[\"sentiment\"] for t in dataset.get_raw_element(i) if t is not None]))\n",
        "\n",
        "test_dataset_class(training_file)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset test:\n",
            "  sample 0: ['always:O-', 'use:O-', 'backup:O-', 'hard:B-neutral', 'disk:I-neutral', 'store:O-', 'important:O-', 'files:O-', 'times:O-']\n",
            "  sample 1: ['also:O-', 'love:O-', 'small:O-', 'convenient:O-', 'size:B-positive', 'laptop:O-', 'making:O-', 'perfect:O-', 'tool:O-', 'academic:O-']\n",
            "  sample 2: ['studies:O-']\n",
            "  sample 3: ['thought:O-', 'white:O-', 'Mac:O-', 'computers:O-', 'looked:O-', 'dirty:O-', 'quicly:O-', 'use:O-neutral', 'mousepad:B-neutral', 'place:O-']\n",
            "  sample 4: ['hands:O-', 'typing:O-']\n",
            "  sample 5: ['always:O-', 'reliable:O-', 'never:O-', 'bugged:O-', 'responds:B-positive', 'well:O-']\n",
            "  sample 6: ['real:O-', 'stand:O-', 'computer:O-', 'feel:O-', 'keyboard:B-positive', 'speed:B-positive']\n",
            "  sample 7: ['Called:O-', 'headquarters:O-', 'report:O-', 'TFT:B-negative', 'panel:I-negative', 'broken:O-', 'fixed:O-', 'end:O-', 'week:O-', 'week:O-']\n",
            "  sample 8: ['3:O-']\n",
            "  sample 9: ['computer:O-', 'bought:O-', 'wanted:O-', 'top:O-', 'line:O-', 'fast:O-', 'reliable:O-', 'HA:O-']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXoEzFqdp6E"
      },
      "source": [
        "Data module definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnjG9vx0dpOa"
      },
      "source": [
        "def create_windows(sentences): # to save space in memory ? why we do not load directly all the sentence?\n",
        "        \"\"\" \n",
        "        Args:\n",
        "            sentences (list of lists of dictionaries, where each dictionary represents a word occurrence)\n",
        "        \"\"\"\n",
        "        data = []\n",
        "        window_size = 100\n",
        "        for sentence in sentences:\n",
        "            for i in range(0, len(sentence), window_shift):\n",
        "                window = sentence[i:i+window_size]\n",
        "                if len(window) < window_size:\n",
        "                    window = window + [None]*(window_size - len(window))  # to match the same length of sentences\n",
        "                assert len(window) == window_size\n",
        "                data.append(window)\n",
        "        return data\n",
        "\n",
        "class DataModuleBiLSTM(pl.LightningDataModule):\n",
        "    def __init__(self, training_file, dev_file, window_size, window_shift, vocabulary, label_vocabulary, model_b=None):\n",
        "        super().__init__()\n",
        "        self.training_file = training_file\n",
        "        self.dev_file = dev_file\n",
        "        self.window_size = window_size\n",
        "        self.window_shift = window_shift\n",
        "        self.vocabulary = vocabulary\n",
        "        self.label_vocabulary = label_vocabulary\n",
        "        self.model_b = model_b\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "      self.trainingset = BiLSTMDataset(self.training_file, self.window_size, self.window_shift, self.model_b)\n",
        "      self.devset = BiLSTMDataset(self.dev_file, self.window_size, self.window_shift, self.model_b)\n",
        "\n",
        "      self.trainingset.index_dataset(self.vocabulary, self.label_vocabulary)\n",
        "      self.devset.index_dataset(self.vocabulary, self.label_vocabulary)\n",
        "          \n",
        "    def train_dataloader(self):\n",
        "      return DataLoader(self.trainingset, batch_size=128)\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.devset, batch_size=128)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnJuu3tbUgvn"
      },
      "source": [
        "### Building vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjbrH-mCu8iZ"
      },
      "source": [
        "def build_vocab(dataset, min_freq=1):\n",
        "    counter = Counter()\n",
        "    for i in tqdm(range(len(dataset))):\n",
        "        # for each token in the sentence viewed as a dictionary of items from the line\n",
        "        for token in dataset.get_raw_element(i):\n",
        "            if token is not None:\n",
        "                counter[token[\"token\"]]+=1\n",
        "    #Counter({'the': 1046, 'and': 671, 'to': 604, etc....}\n",
        "    # we add special tokens for handling padding and unknown words at testing time.\n",
        "\n",
        "    return Vocab(counter, specials=['<pad>', '<unk>'], min_freq=min_freq)\n",
        "\n",
        "def build_label_vocab(dataset):\n",
        "    counter = Counter()\n",
        "    for i in tqdm(range(len(dataset))):\n",
        "        for token in dataset.get_raw_element(i):\n",
        "            if token is not None:\n",
        "                counter[token[\"ne_label\"]]+=1\n",
        "    # No <unk> token for labels. Counter({'O': 19179, 'B': 1548, 'I': 718})\n",
        "    print(counter)\n",
        "    return Vocab(counter, specials=['<pad>'])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yyvdW3GtwelF",
        "outputId": "b5286fcb-4555-4904-ee78-9eb43932eabd"
      },
      "source": [
        "training_file = dataset_folder+\"/laptops_train.json\"\n",
        "dev_file = dataset_folder+\"/laptops_dev.json\"\n",
        "window_size, window_shift = 100, 100\n",
        "dataset = BiLSTMDataset(training_file, window_size, window_shift, model_b)\n",
        "vocabulary = build_vocab(dataset)\n",
        "label_vocabulary = build_label_vocab(dataset)\n",
        "dataset.index_dataset(vocabulary, label_vocabulary)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|██████████| 2497/2497 [00:00<00:00, 113784.46it/s]\n",
            "\n",
            "\n",
            "100%|██████████| 2497/2497 [00:00<00:00, 162465.52it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Counter({'O': 15738, 'B': 1705, 'I': 820})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8vzinmvb4x2"
      },
      "source": [
        "## Usage of pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUhw7SOT3a_-"
      },
      "source": [
        "vocabulary.load_vectors(\"glove.6B.50d\")\n",
        "#vocabulary.load_vectors(\"charngram.100d\")\n",
        "#vocabulary.load_vectors(\"fasttext.en.300d\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2BiDElNVaRJ"
      },
      "source": [
        "print(vocabulary.vectors[1165])\n",
        "#print(vocabulary.vectors[0].get_vecs_by_tokens(\"pain\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYjbtu2qVq5W"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaxUAwmSutnW"
      },
      "source": [
        "class ABSAModel(pl.LightningModule):\n",
        "    def __init__(self, hparams, embeddings = None, comments=\"without_pretrained_embeddings\",*args, **kwargs):\n",
        "        super(ABSAModel, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.save_hyperparameters(hparams)\n",
        "        self.loss_function = nn.CrossEntropyLoss(ignore_index=label_vocabulary['<pad>'])\n",
        "        #self.model = ABSATaggerModel(self.hparams, embeddings)\n",
        "        self.word_embedding = nn.Embedding(self.hparams.vocab_size, self.hparams.embedding_dim) # hparams.vocab_size words in vocab, hparams.embedding_dim dimensional embeddings\n",
        "\n",
        "        if embeddings is not None:\n",
        "            print(\"initializing embeddings from pretrained\")\n",
        "            self.word_embedding = nn.Embedding.from_pretrained(embeddings)\n",
        "\n",
        "        self.lstm = nn.LSTM(self.hparams.embedding_dim, self.hparams.hidden_dim, \n",
        "                            bidirectional=self.hparams.bidirectional,\n",
        "                            num_layers=self.hparams.num_layers, \n",
        "                            dropout = self.hparams.dropout if self.hparams.num_layers > 1 else 0)\n",
        "        \n",
        "        lstm_output_dim = self.hparams.hidden_dim if self.hparams.bidirectional is False else self.hparams.hidden_dim * 2\n",
        "\n",
        "        # During training, randomly zeroes some of the elements of the \n",
        "        # input tensor with probability hparams.dropout. \n",
        "        # This has proven to be an effective technique for regularization and \n",
        "        # preventing the co-adaptation of neurons\n",
        "        self.dropout = nn.Dropout(self.hparams.dropout)\n",
        "        self.classifier = nn.Linear(lstm_output_dim, self.hparams.num_classes)\n",
        "\n",
        "        self.writer = SummaryWriter(comment=comments+\"_modelb=\"+str(model_b))\n",
        "        self.epoch_t, self.epoch_ev = -1,-1\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = self.word_embedding(x)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        o, (h, c) = self.lstm(embeddings)\n",
        "        o = self.dropout(o)\n",
        "        logits = self.classifier(o)\n",
        "        \n",
        "        predictions = torch.argmax(logits, -1)\n",
        "        \n",
        "        return logits, predictions\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        '''\n",
        "        {\n",
        "        'inputs': tensor([  5, 121,  34,   6, 834,  68, 307,   4, 370, 684, 663,  40,  42, 748, 0,   0,   0,   0,   0], device='cuda:0'), \n",
        "        'outputs': tensor([1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
        "        }\n",
        "        '''\n",
        "        inputs = batch['inputs']\n",
        "        labels = batch['outputs']\n",
        "        # We receive one batch of data and perform a forward pass:\n",
        "        logits, _ = self.forward(inputs)\n",
        "\n",
        "        # We adapt the logits and labels to fit the format required for the loss function\n",
        "        logits = logits.view(-1, logits.shape[-1])\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        loss = self.loss_function(logits, labels)\n",
        "        # Log it:\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        if self.epoch_t != self.current_epoch:\n",
        "            self.epoch_t = self.current_epoch\n",
        "            self.writer.add_scalar(\"train/loss\", loss, self.current_epoch)\n",
        "            self.log_f1(logits,labels,\"train\")\n",
        "\n",
        "\n",
        "        # loss that will be used to update the weights:\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        inputs = batch['inputs']\n",
        "        labels = batch['outputs']\n",
        "\n",
        "        logits, _ = self.forward(inputs)\n",
        "        logits = logits.view(-1, logits.shape[-1])\n",
        "        labels = labels.view(-1)\n",
        "        sample_loss = self.loss_function(logits, labels)\n",
        "        self.log('valid_loss', sample_loss, prog_bar=True)\n",
        "        \n",
        "        if self.epoch_ev != self.current_epoch:\n",
        "            self.epoch_ev = self.current_epoch\n",
        "            self.writer.add_scalar(\"eval/loss\", sample_loss, self.current_epoch)\n",
        "            self.log_f1(logits,labels,\"eval\")\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters())\n",
        "\n",
        "\n",
        "    def log_f1(self,logits,indexed_labels,mode=\"train\"):\n",
        "        predictions = torch.argmax(logits, -1).view(-1)\n",
        "        labels = indexed_labels.view(-1)\n",
        "        valid_indices = labels != 0\n",
        "        \n",
        "        valid_predictions = predictions[valid_indices]\n",
        "        valid_labels = labels[valid_indices]\n",
        "        macro_f1 = f1_score(valid_labels.tolist(), valid_predictions.tolist(), average=\"macro\", zero_division=0)\n",
        "        self.writer.add_scalar(mode+\"/f1\", macro_f1, self.current_epoch)\n"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wATp3pfduPg"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6HpQxFjvhWb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370,
          "referenced_widgets": [
            "0c4bf23057ad473ab513f9bc67d4c06f",
            "7695cd1122d647179166cf7d770d33ba",
            "51228f8176ef44aba0ecc73ad460d971",
            "855dd996a1084ba3b0395f06f9df8986",
            "53ee621c5ed8414794226944a67738ff",
            "ee46b8741402406a8c671f973c94bf26",
            "53286cfb6620430a8f106f5264b1a918",
            "804742c5a6b34ba6bf3a49c73827c7bf",
            "f519da44fee64436896f636be792e378",
            "0a227f1ab5724e20a4944558c48b37d0",
            "8ba8d4d7cbdd4e5f9549d20164635b6f",
            "c8a96d114a954133b0f21e055873d842",
            "a050022fb6f445e8ad4bd29490b94b6b",
            "259fee6a551946c4866c0661a8d2a2c0",
            "b2a017bef4ac47a99ff41cacb455709d",
            "c526908e95664bc6a14353020c1dfcf0",
            "6cae1b17cdce42748e138ea55fe0fb0a",
            "a24b79816a5e42adb07961877700f73e",
            "dc713dbb4f9e4f2194ea331b92b1cb8e",
            "d9918212c34b43609cbd1852affb12a5",
            "adc4a76f848446afa41e9b5df329b7aa",
            "4db07fca272f42709f96d0cb3746a7dd",
            "5ddd1e2f4c8d403baacd0f86af6d5ebf",
            "93d49f4bea9641e8be5a15731ed75edb",
            "0f5750bf236b41faa911919cd4a25431",
            "63b86f1ccae94e9580443bf874acac0e",
            "aac8486269344931a856aea6eb20c84c",
            "23c245ccb0f94774a78c51bae01c3e25",
            "de59041788a84587a134ad67107560ec",
            "8f318ec75bd144c399c6b373723bd482",
            "0d12e8b9ef9c4f6eb4afc102ec016d84",
            "bcfdab36321445a086d93ecb51be4598",
            "c1c842eee22b413d89bc3ccc0053ee44",
            "6c4a265f4bb4414caa7441ff831e7ecb",
            "15121694dd384373bc7d4e91632f8c4a",
            "56e52cd286f14d94a2f92e97c2a42411",
            "40027d83a11f449180e4fb1a22256781",
            "d323420e97d44eac97750215eebce5cd",
            "58fea9252c2746a186bb8eb0a6f0e45f",
            "22720204b6ff4563bb0506642bd59158",
            "ad3eba9005ac4566b4c0e198f0754012",
            "03977f63588b4e619f9effd308b8a333",
            "5b3f3f55086b4ed2baa27a5b13f8f057",
            "148868898ca648c387ef128e6c252f18",
            "b94cc7f3118c4108b828388728c79249",
            "df643593f2a94d9ebb8f5c9a46fe4e26",
            "122c5665787a4bb3878615f150aa30a8",
            "b84e5903d06d4d01998849a55319592a",
            "2ec12ba2017f40c58e3e33a37516dc83",
            "6314d6e64f6242d797903f61410cd788",
            "f3abf8ee1e2a468abdb47f4db0770388",
            "5510b00235c14f56a619bb86874be7c9",
            "0bce419e0a5440738bb14c7323fe55d8",
            "c8bcc48ee2104b15b4f3aeba50e445ca",
            "d98a9e07c4d14b36ab9977bf5cac74dc",
            "132c75c981164d8bbe233e18ccc5bbbe",
            "48b9874749ff4526a14d54418ac7b0ea",
            "ae0290c2b2e04a3d9550ddcf212d09f9",
            "8641917c17404eac9d98a5ebbab99d82",
            "3237c45d09d44de5a7f762b923c188c2",
            "6c90e4cc1b64479c8648e0842f359621",
            "381e5e1f66304c8ca472b4da973a77a8",
            "448d2335aa7942be887927f4e9f2225c",
            "a268972dffea43df8eb62ff6f01bd050",
            "2f0d813832d2449d88e0e91d8f10324d",
            "f3d24578cfd24035b7b7d269835f99a8",
            "fda0662d93b94738869ff7fd035bbe37",
            "8c935faf5e614192933892f5b8572748",
            "911b2c10e4e143e6b17c6584ad6629f2",
            "2fc5476216f14190ad48879ab17cad8d",
            "1e5cd41b4d9a451da41ddc7bc3f3a6ac",
            "eeeaae8dfc604dc883ada2912324ee5f",
            "d6f20357f3bd48c8b0fa3fc95b67082a",
            "80e27c02426b4717a60987598fb6c9b9",
            "4c2b765340dd429cab6dd2ffc7de0bd3",
            "8b45102d4350487a942719fa88b53eaf",
            "ec168f901fbf463bac9e0301b557b42f",
            "ae448f418d5247fdaca3b5041054454f",
            "21db503b8aa743b3b79aeeb6dbc54f1b",
            "ddfa9df8fd1148ac99f1613d8b719cbe",
            "8c41ee7b83244f8489ce7e1212d51b63",
            "1f58d9b2ac29461880e9af4a16e7dd7d",
            "5ad4918bf25c40909c5ac391af20d54d",
            "9ca1c3f3e88e4d3f863774c2fb6a9a16",
            "ff1ad62fa9dc4c3a9a6fefb8d453124e",
            "2b74f0c6bdbf4d95a1fabff0986f5bf9",
            "e89b05cf437a4215b910c9715b434e86",
            "34c8ff4dbe0a4aeaae12ad2bd5af4ad5",
            "a2e570e541b94799b52b60865b742e75",
            "ded769bc281042d586586514e20a7f13",
            "03ef2c01a5954c3aba324d318257d349",
            "8d1dbed7852642cd888cb8661edcd74b",
            "3e796e51e65941a097549efd912cdbfb",
            "6d47e17827564c70a71d93b7364f47f5",
            "c467b5caa12641b090d930c84d6daa40",
            "05c3220e0fa241f8b5e99a2252e424af",
            "e677b5a87f8347b7bda654c38e8e8d05",
            "4052f281c8e34ef7840eb663357b99ab",
            "be72946ca26a48a5a615aabb33c7c312",
            "c68af7eb97cc40fa8ef11da79116b320",
            "86f38478060448aca913855860532574",
            "c1b93b52b28e4fc1bbaf5fdb0cd3cb5b",
            "7481780b1ea045a0b4063b362bc200fd",
            "a23610d2fb134c29be5072486d24a95a",
            "5a18d3b1eca74753828bd2fffd3f1b91",
            "367b3f070bd243b699724f89524eb8eb",
            "bc68a1d07d4a4786887a461ea31681fb",
            "01de6113e7af4e97abacd51dd6308095",
            "65b20a8e91734494ae114ac318e7a83f",
            "08b26668b79d475ebcdeea6e8848f1fd",
            "1ab0c6ae0dce4e23b168e6ca7410bcbc",
            "f5b25cf7e40d48058b1a573a182b19ea",
            "09d3376ad7574cda8f3a88bfd7dfd704",
            "2c72f4859ab5438aa312a866158c46af",
            "921d980f967445b49a992e0845ffebf7",
            "d1403025814443879bfedb0823b0579a",
            "b19ca45847954b9888fe881a5c8cfb02",
            "2ccc0026ab454fa5b1e58d78d799c581",
            "2cf78c7867254befada06275ac839f0b",
            "ac1dcdd1e3ce4db4bc70ce3747380e23",
            "171efa233c084ca9b160561955c4ea2f",
            "6332d071d196421ebd485b8fda0eb266",
            "b5a1447ee5874e23ac5e805c5a222c6c",
            "ab931d676d75474b98b6d3b7859b89c1",
            "9a3c6c6f382045a78545ab7ef0c6a613",
            "843c5203e3dd4095b3ca38650182f885",
            "b355897c3e294cf086593598fa4e283b",
            "b9f3c6900d46425cb41a6969829e3f8a",
            "3047922046c448baace8acb02b6c759c",
            "7851c936c30946debc5d215309faa142",
            "19a3cc9aa60148619bef053d54584108",
            "834f2d527f37421ca4bb11b586c883cb",
            "38c6cb5c482748498b5aa35100f3ccc6",
            "f827502737634ef987a5f0b2b7429a36",
            "58eaff872b1a4141acd24f6ecd2379eb",
            "dc7e9383245048529c35306a6aa9d399"
          ]
        },
        "outputId": "99745f68-a6f9-4e89-abe9-3790e1edd7ce"
      },
      "source": [
        "to_be_saved = False\n",
        "try:\n",
        "    embedding_dim = vocabulary.vectors.shape[1]\n",
        "except:\n",
        "    embedding_dim = 100\n",
        "hparams = {'vocab_size': len(vocabulary),\n",
        "            'hidden_dim': 80,\n",
        "            'embedding_dim': embedding_dim,\n",
        "            'num_classes': len(label_vocabulary), # number of different universal POS tags\n",
        "            'bidirectional': True,\n",
        "            'num_layers': 2,\n",
        "            'dropout': 0.2}\n",
        "window_size, window_shift = 100, 100\n",
        "data_module = DataModuleBiLSTM(training_file, dev_file, window_size, window_shift, vocabulary, label_vocabulary, model_b)\n",
        "trainer = pl.Trainer(gpus=1, val_check_interval=1.0, max_epochs=15)\n",
        "\n",
        "model = ABSAModel(hparams,comments=\"without_pretrained\")\n",
        "#model = ABSAModel(hparams,vocabulary.vectors,comments=\"with_charngram\")\n",
        "trainer.fit(model, datamodule=data_module)\n"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name           | Type             | Params\n",
            "----------------------------------------------------\n",
            "0 | loss_function  | CrossEntropyLoss | 0     \n",
            "1 | word_embedding | Embedding        | 414 K \n",
            "2 | lstm           | LSTM             | 271 K \n",
            "3 | dropout        | Dropout          | 0     \n",
            "4 | classifier     | Linear           | 644   \n",
            "----------------------------------------------------\n",
            "686 K     Trainable params\n",
            "0         Non-trainable params\n",
            "686 K     Total params\n",
            "2.745     Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c4bf23057ad473ab513f9bc67d4c06f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f519da44fee64436896f636be792e378",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6cae1b17cdce42748e138ea55fe0fb0a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f5750bf236b41faa911919cd4a25431",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c1c842eee22b413d89bc3ccc0053ee44",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad3eba9005ac4566b4c0e198f0754012",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ec12ba2017f40c58e3e33a37516dc83",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48b9874749ff4526a14d54418ac7b0ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2f0d813832d2449d88e0e91d8f10324d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6f20357f3bd48c8b0fa3fc95b67082a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8c41ee7b83244f8489ce7e1212d51b63",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2e570e541b94799b52b60865b742e75",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e677b5a87f8347b7bda654c38e8e8d05",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5a18d3b1eca74753828bd2fffd3f1b91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09d3376ad7574cda8f3a88bfd7dfd704",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "171efa233c084ca9b160561955c4ea2f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3047922046c448baace8acb02b6c759c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCL-D3DKd1Sj"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYUsD5Z9hz13"
      },
      "source": [
        "try:\n",
        "    %reload_ext tensorboard\n",
        "except:\n",
        "    %load_ext tensorboard\n",
        "%tensorboard --logdir=runs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s00-6EVFwEqP"
      },
      "source": [
        "from sklearn.metrics import precision_score as sk_precision\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_scores(model:pl.LightningModule, l_dataset:DataLoader, l_label_vocab:Vocab):\n",
        "    model.freeze()\n",
        "    model.cuda()\n",
        "    all_predictions = list()\n",
        "    all_labels = list()\n",
        "    for indexed_elem in l_dataset:\n",
        "        indexed_in = indexed_elem[\"inputs\"]\n",
        "        indexed_labels = indexed_elem[\"outputs\"]\n",
        "        predictions, _ = model(indexed_in)\n",
        "        predictions = torch.argmax(predictions, -1).view(-1)\n",
        "        labels = indexed_labels.view(-1)\n",
        "        valid_indices = labels != 0\n",
        "        \n",
        "        valid_predictions = predictions[valid_indices]\n",
        "        valid_labels = labels[valid_indices]\n",
        "        \n",
        "        all_predictions.extend(valid_predictions.tolist())\n",
        "        all_labels.extend(valid_labels.tolist())\n",
        "\n",
        "    macro_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    macro_f1 = f1_score(all_labels, all_predictions, average=\"macro\", zero_division=0)\n",
        "    per_class_precision = sk_precision(all_labels, all_predictions, labels = list(range(len(l_label_vocab))), average=None, zero_division=0)\n",
        "    model.unfreeze()\n",
        "    return {\"macro_accuracy\":macro_accuracy,\n",
        "            \"f1_macro\":macro_f1, \n",
        "            \"per_class_precision\":per_class_precision}"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNLpNX7Av_PT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63da975e-9f0b-467c-d966-81e1e71ff1ba"
      },
      "source": [
        "scores = compute_scores(model, data_module.val_dataloader(), label_vocabulary)\n",
        "per_class_precision = scores[\"per_class_precision\"]\n",
        "print(\"Accuracy: {}\\nMacro F1: {}\".format(scores[\"macro_accuracy\"], scores[\"f1_macro\"]))\n",
        "print(\"Per class Precision:\")\n",
        "for idx_class, precision in sorted(enumerate(per_class_precision), key=lambda elem: -elem[1]):\n",
        "    label = label_vocabulary.itos[idx_class]\n",
        "    print(label, precision)\n",
        "\n",
        "if to_be_saved:\n",
        "    torch.save(model.state_dict(), root_folder+'/model/model_b={}_f1_{:0.4f}.pt'.format(str(model_b), scores[\"f1_macro\"])) # save the model state\n"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9076615922136262\n",
            "Macro F1: 0.6419478355669707\n",
            "Per class Precision:\n",
            "O 0.9311385459533608\n",
            "I 0.6756756756756757\n",
            "B 0.6701388888888888\n",
            "<pad> 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3QrxZc6U-SN1"
      },
      "source": [
        "## docker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsk7GU5Z-Xmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4e853a-7efc-442a-e669-9945cdea78ba"
      },
      "source": [
        "class PreprocessAB():\n",
        "    def __init__(self,sentences_list):\n",
        "        self.window_size = 100\n",
        "        self.window_shift = 100\n",
        "        self.sentences = self.load_data(sentences_list)\n",
        "        self.data = self.create_windows(self.sentences)\n",
        "        self.encoded_data = None\n",
        "        self.vocabulary = self.build_vocab()\n",
        "        self.label_vocabulary = self.build_label_vocab()\n",
        "        self.index_dataset(self.vocabulary, self.label_vocabulary)\n",
        "\n",
        "    def remove_stopwords(self,sent: str) -> str:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        # remove punkt\n",
        "        others = \"–\" +\"—\" + \"−\" + \"’\" + \"”\" + \"“\" #These chars arent inside the standard punctuation\n",
        "        str_punkt = string.punctuation+ others\n",
        "        translator = str.maketrans(str_punkt, ' '*len(str_punkt)) \n",
        "        word_tokens = word_tokenize(sent.translate(translator)) \n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        return filtered_sentence\n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        sentences = []\n",
        "        for obj in list_of_sentences:\n",
        "            _sentence = []\n",
        "            # lemmatized = [lemmatizer.lemmatize(w)  for w in obj['text'].split(\" \")]\n",
        "            #lemmatized = self.remove_stopwords(\" \".join(lemmatized))\n",
        "            lemmatized = self.remove_stopwords(obj['text'])\n",
        "\n",
        "            for t in lemmatized:\n",
        "                token = {\"token\": t}\n",
        "                _sentence.append(token)\n",
        "            sentences.append(_sentence)\n",
        "        return sentences\n",
        "\n",
        "    def create_windows(self, sentences): # to save space in memory ? why we do not load directly all the sentence?\n",
        "        \"\"\" \n",
        "        Args:\n",
        "            sentences (list of lists of dictionaries, where each dictionary represents a word occurrence)\n",
        "        \"\"\"\n",
        "        data = []\n",
        "        for sentence in sentences:\n",
        "            for i in range(0, len(sentence), self.window_shift):\n",
        "                window = sentence[i:i+self.window_size]\n",
        "                if len(window) < self.window_size:\n",
        "                    window = window + [None]*(self.window_size - len(window))  # to match the same length of sentences\n",
        "                assert len(window) == self.window_size\n",
        "                data.append(window)\n",
        "        return data\n",
        "\n",
        "\n",
        "    def index_dataset(self, l_vocabulary, l_label_vocabulary):\n",
        "        self.encoded_data = list()\n",
        "        for i in range(len(self.data)):\n",
        "            # for each window\n",
        "            sentence = self.data[i]\n",
        "            encoded_sentence = torch.LongTensor(self.encode_text(sentence, l_vocabulary)).cpu()\n",
        "            \n",
        "           \n",
        "            self.encoded_data.append({\"inputs\":encoded_sentence})\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def encode_text(sentence:list, l_vocabulary:Vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (list): list of OrderedDict, each carrying the information about one token.\n",
        "            l_vocabulary (Vocab): vocabulary with mappings from words to indices and viceversa.\n",
        "        Return:\n",
        "            The method returns a list of indices corresponding to the input tokens.\n",
        "        \"\"\"\n",
        "        indices = list()\n",
        "        for w in sentence:\n",
        "            if w is None:\n",
        "                indices.append(l_vocabulary[\"<pad>\"])\n",
        "            elif w[\"token\"] in l_vocabulary.stoi: # vocabulary string to integer (necessary to search faster)\n",
        "                indices.append(l_vocabulary[w[\"token\"]])\n",
        "            else:\n",
        "                indices.append(l_vocabulary[\"<unk>\"])\n",
        "        return indices\n",
        "\n",
        "    \n",
        "    @staticmethod\n",
        "    def decode_output(outputs:torch.Tensor,\n",
        "                    l_label_vocabulary: Vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            outputs (Tensor): a Tensor with shape (batch_size, max_len, label_vocab_size)\n",
        "                containing the logits outputed by the neural network.\n",
        "            l_label_vocabulary (Vocab): is the vocabulary containing the mapping from\n",
        "            a string label to its corresponding index and vice versa\n",
        "        Output:\n",
        "            The method returns a list of batch_size length where each element is a list\n",
        "            of labels, one for each input token.\n",
        "        \"\"\"\n",
        "        max_indices = torch.argmax(outputs, -1).tolist() # shape = (batch_size, max_len)\n",
        "        predictions = list()\n",
        "        for indices in max_indices:\n",
        "            # vocabulary integer to string is used to obtain the corresponding word from the max index\n",
        "            predictions.append([l_label_vocabulary.itos[i] for i in indices])\n",
        "        return predictions\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded_data[idx]\n",
        "    \n",
        "    def get_raw_element(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def build_vocab(self, min_freq=1):\n",
        "        counter = Counter()\n",
        "        for i in tqdm(range(len(self.data))):\n",
        "            # for each token in the sentence viewed as a dictionary of items from the line\n",
        "            for token in self.get_raw_element(i):\n",
        "                if token is not None:\n",
        "                    counter[token[\"token\"]]+=1\n",
        "        #Counter({'the': 1046, 'and': 671, 'to': 604, etc....}\n",
        "        # we add special tokens for handling padding and unknown words at testing time.\n",
        "\n",
        "        return Vocab(counter, specials=['<pad>', '<unk>'], min_freq=min_freq)\n",
        "\n",
        "    def build_label_vocab(self):\n",
        "        counter = Counter({'O': 16101, 'B-positive': 758, 'B-negative': 694, 'B-neutral': 346, 'I-negative': 317, 'I-positive': 242, 'I-neutral': 226, 'B-conflict': 33, 'I-conflict': 15})\n",
        "        return Vocab(counter, specials=['<pad>'])\n",
        "\n",
        "\n",
        "def predict_together_AB(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessAB(samples)\n",
        "    for i,test_elem in tqdm(enumerate(prep.encoded_data)):\n",
        "        json_pred = {\"targets\":[]}\n",
        "        lst,pred = [],[]\n",
        "        test_x = test_elem[\"inputs\"].to(\"cpu\")\n",
        "        logits, predictions = model(test_x.unsqueeze(0))\n",
        "        decoded_labels = prep.decode_output(logits, label_vocabulary)[0]\n",
        "        idxs = test_x.tolist()\n",
        "        for j,word in enumerate(decoded_labels):\n",
        "            if word.startswith(\"B\"):\n",
        "                json_pred[\"targets\"].append((prep.vocabulary.itos[idxs[j]],word.split(\"-\")[1]))\n",
        "            elif (word.startswith(\"I\")) and (decoded_labels[j-1].startswith(\"B\")):\n",
        "                try:\n",
        "                    last_tuple = json_pred['targets'][-1]\n",
        "                    words_tagged = last_tuple[0] + \" \" + prep.vocabulary.itos[idxs[j]]\n",
        "                    sent_tagged = last_tuple[1]\n",
        "                    json_pred['targets'][-1] = (words_tagged, sent_tagged)\n",
        "                except:\n",
        "                    words_tagged = prep.vocabulary.itos[idxs[j]]\n",
        "                    sent_tagged = word.split(\"-\")[1]\n",
        "                    json_pred['targets'].append((words_tagged, sent_tagged))\n",
        "            elif word.startswith(\"I\"):\n",
        "                json_pred[\"targets\"].append((prep.vocabulary.itos[idxs[j]],word.split(\"-\")[1]))\n",
        "\n",
        "        targets.append(json_pred)\n",
        "    #print(targets)\n",
        "    return targets\n",
        "\n",
        "\n",
        "\n",
        "def predict_a_then_b(samples):\n",
        "    targets = []\n",
        "    prep = PreprocessAB(samples)\n",
        "    for i,test_elem in tqdm(enumerate(prep.encoded_data)):\n",
        "        json_pred = {\"targets\":[]}\n",
        "        lst,pred = [],[]\n",
        "        test_x = test_elem[\"inputs\"].to(\"cpu\")\n",
        "        logits, predictions = model(test_x.unsqueeze(0))\n",
        "        decoded_labels = prep.decode_output(logits, label_vocabulary)[0]\n",
        "        idxs = test_x.tolist()\n",
        "        # for a,b in zip(decoded_labels,idxs):\n",
        "        #     print(a,\"\\t\",prep.vocabulary.itos[b])\n",
        "        for j,word in enumerate(decoded_labels):\n",
        "            if word == \"B\":\n",
        "                json_pred[\"targets\"].append((prep.vocabulary.itos[idxs[j]],\"positive\"))\n",
        "            elif (word == \"I\") and (decoded_labels[j-1] == \"B\"):\n",
        "                try:\n",
        "                    last_tuple = json_pred['targets'][-1]\n",
        "                    words_tagged = last_tuple[0] + \" \" + prep.vocabulary.itos[idxs[j]]\n",
        "                    sent_tagged = last_tuple[1]\n",
        "                    json_pred['targets'][-1] = (words_tagged, sent_tagged)\n",
        "                except:\n",
        "                    words_tagged = prep.vocabulary.itos[idxs[j]]\n",
        "                    sent_tagged = \"positive\"\n",
        "                    json_pred['targets'].append((words_tagged, sent_tagged))\n",
        "            elif word == \"I\":\n",
        "                json_pred[\"targets\"].append((prep.vocabulary.itos[idxs[j]],\"positive\"))\n",
        "\n",
        "        targets.append(json_pred)\n",
        "\n",
        "    return targets\n",
        "def load_data(data_path):\n",
        "    with open(data_path) as json_file:\n",
        "        list_of_sentences = json.load(json_file)\n",
        "    return list_of_sentences\n",
        "\n",
        "\n",
        "a = load_data(dataset_folder+\"/laptops_dev.json\")\n",
        "#a = a + load_data(dataset_folder+\"/restaurants_dev.json\")\n",
        "random.shuffle(a)\n",
        "model.cpu()\n",
        "#t = predictB(a[:30])\n",
        "t = predict_a_then_b(a)\n",
        "for gt,pred in zip(a[:40],t[:40]):\n",
        "    print(gt['targets'],\"SEP\",pred['targets'])\n",
        "evaluate_extraction(a,t)\n",
        "evaluate_sentiment(a,t)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "100%|██████████| 545/545 [00:00<00:00, 94470.21it/s]\n",
            "\n",
            "\n",
            "0it [00:00, ?it/s]\u001b[A\u001b[A\n",
            "\n",
            "49it [00:00, 484.32it/s]\u001b[A\u001b[A\n",
            "\n",
            "98it [00:00, 484.62it/s]\u001b[A\u001b[A\n",
            "\n",
            "146it [00:00, 481.33it/s]\u001b[A\u001b[A\n",
            "\n",
            "195it [00:00, 482.39it/s]\u001b[A\u001b[A\n",
            "\n",
            "245it [00:00, 484.61it/s]\u001b[A\u001b[A\n",
            "\n",
            "293it [00:00, 481.18it/s]\u001b[A\u001b[A\n",
            "\n",
            "341it [00:00, 478.81it/s]\u001b[A\u001b[A\n",
            "\n",
            "390it [00:00, 481.85it/s]\u001b[A\u001b[A\n",
            "\n",
            "442it [00:00, 492.14it/s]\u001b[A\u001b[A\n",
            "\n",
            "493it [00:01, 497.20it/s]\u001b[A\u001b[A\n",
            "\n",
            "545it [00:01, 489.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[] SEP [('s5988', 'positive')]\n",
            "[[[142, 150], 'programs', 'negative'], [[155, 162], 'drivers', 'negative']] SEP [('first', 'positive'), ('issues', 'positive'), ('powering', 'positive'), ('issues', 'positive')]\n",
            "[[[31, 39], 'features', 'positive']] SEP []\n",
            "[[[52, 72], 'sound output quality', 'negative']] SEP []\n",
            "[[[33, 37], 'BIOS', 'negative']] SEP []\n",
            "[] SEP [('ago', 'positive')]\n",
            "[] SEP []\n",
            "[] SEP [('desktop', 'positive')]\n",
            "[] SEP []\n",
            "[] SEP [('took', 'positive'), ('bag', 'positive')]\n",
            "[[[39, 43], 'work', 'negative']] SEP []\n",
            "[[[30, 34], 'cost', 'positive']] SEP []\n",
            "[] SEP [('MAC', 'positive')]\n",
            "[] SEP [('fan', 'positive')]\n",
            "[] SEP [('times', 'positive')]\n",
            "[] SEP []\n",
            "[] SEP [('go', 'positive')]\n",
            "[] SEP [('husband', 'positive')]\n",
            "[[[110, 117], 'company', 'negative']] SEP [('another', 'positive')]\n",
            "[] SEP [('love', 'positive')]\n",
            "[[[41, 49], 'programs', 'negative']] SEP [('numbers', 'positive'), ('numbers', 'positive'), ('things', 'positive')]\n",
            "[] SEP []\n",
            "[[[22, 33], 'gaming look', 'positive'], [[70, 88], 'gaming performance', 'positive']] SEP [('machine', 'positive'), ('performance', 'positive')]\n",
            "[[[28, 35], 'program', 'positive']] SEP []\n",
            "[[[35, 46], 'Acer screen', 'negative'], [[114, 122], 'USB port', 'negative'], [[21, 25], 'boot', 'negative']] SEP [('past', 'positive')]\n",
            "[[[74, 80], 'screen', 'positive']] SEP []\n",
            "[] SEP [('home', 'positive')]\n",
            "[[[16, 46], 'combined touch pad and clicker', 'negative']] SEP [('much', 'positive'), ('lauded', 'positive')]\n",
            "[[[4, 13], 'Bluetooth', 'negative'], [[44, 69], 'fingerprint reader driver', 'negative'], [[94, 102], 'software', 'negative']] SEP [('way', 'positive')]\n",
            "[] SEP [('another', 'positive')]\n",
            "[[[46, 56], 'mouse keys', 'negative']] SEP []\n",
            "[[[6, 9], 'HDD', 'positive'], [[31, 36], 'rails', 'neutral'], [[76, 86], 'hard drive', 'neutral']] SEP [('secures', 'positive'), ('main', 'positive')]\n",
            "[[[0, 8], 'Browsing', 'positive'], [[50, 56], 'itunes', 'positive']] SEP [('Browsing', 'positive')]\n",
            "[] SEP [('machine', 'positive')]\n",
            "[] SEP []\n",
            "[[[8, 14], 'screen', 'positive'], [[90, 96], 'gaming', 'positive']] SEP []\n",
            "[[[31, 42], 'performance', 'negative'], [[0, 6], 'System', 'negative']] SEP [('loosing', 'positive'), ('performance', 'positive')]\n",
            "[[[58, 63], 'price', 'positive']] SEP []\n",
            "[[[0, 6], 'Screen', 'positive'], [[19, 31], 'battery life', 'positive']] SEP [('life', 'positive')]\n",
            "[] SEP []\n",
            "Aspect Extraction Evaluation\n",
            "\tAspects\t TP: 19;\tFP: 402;\tFN: 404\n",
            "\t\tprecision: 4.51;\trecall: 4.49;\tf1: 4.50\n",
            "Aspect Sentiment Evaluation\n",
            "\n",
            "\tALL\t TP: 8;\tFP: 413;\tFN: 418\n",
            "\t\t(m avg): precision: 1.90;\trecall: 1.88;\tf1: 1.89 (micro)\n",
            "\t\t(M avg): precision: 0.48;\trecall: 1.09;\tf1: 0.66 (Macro)\n",
            "\n",
            "\tpositive: \tTP: 8;\tFP: 413;\tFN: 175;\tprecision: 1.90;\trecall: 4.37;\tf1: 2.65;\t421\n",
            "\tnegative: \tTP: 0;\tFP: 0;\tFN: 146;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
            "\tneutral: \tTP: 0;\tFP: 0;\tFN: 91;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
            "\tconflict: \tTP: 0;\tFP: 0;\tFN: 6;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFT5dm_5NYeP"
      },
      "source": [
        "# TASK B (Bi-LSTM (WiC))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNLb1VSIS3a8"
      },
      "source": [
        "##Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHfB_TUh3KZH"
      },
      "source": [
        "class TaskBDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, dataset_path: str):\n",
        "        self.data_store,self.sentences = self.load_data(dataset_path)\n",
        "        self.vocabulary = self.build_vocab(self.sentences)\n",
        "        self.convert_all_2_indices()\n",
        "        self.mlb = MultiLabelBinarizer()\n",
        "        self.encode_tags()\n",
        "\n",
        "\n",
        "    def encode_tags(self):\n",
        "        self.tags = self.mlb.fit_transform([c for (a,b,c) in self.data_store])\n",
        "        self.data_store = [(a,b, torch.tensor(self.tags[i]) ) for i,(a,b,c) in enumerate(self.data_store)]\n",
        "    \n",
        "    def remove_stopwords(self,sent: str) -> str:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        # remove punkt\n",
        "        others = \"–\" +\"—\" + \"−\" + \"’\" + \"”\" + \"“\" #These chars arent inside the standard punctuation\n",
        "        str_punkt = string.punctuation+ others\n",
        "        translator = str.maketrans(str_punkt, ' '*len(str_punkt)) \n",
        "        word_tokens = word_tokenize(sent.translate(translator)) \n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        return filtered_sentence\n",
        "\n",
        "    def load_data(self,data_path):\n",
        "        data_store,sentences = [],[]\n",
        "        with open(data_path) as json_file:\n",
        "            list_of_sentences = json.load(json_file)\n",
        "            for obj in list_of_sentences:\n",
        "                _sentence = []\n",
        "                obj['targets'] = sorted(obj['targets'], key=lambda x: x[0][0])\n",
        "                sentiments = [obj['targets'][j][2] for j in range(len(obj['targets']))]\n",
        " \n",
        "                for i,targ_obj in enumerate(obj['targets']):\n",
        "                    #print(targ_obj)\n",
        "                    new_sent = obj['text'][:targ_obj[0][0]-1]+\" <START> \" + obj['text'][targ_obj[0][0]:targ_obj[0][1]] + \" <END>\" + obj['text'][targ_obj[0][1]:]\n",
        "                    new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                    new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))    \n",
        "                    index = self.find_indices(new_sent)\n",
        "                        \n",
        "                    sentences.append(new_sent)\n",
        "                    sentiments_converted = [sentiments[i]]\n",
        "                    data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "\n",
        "                if len(obj['targets'])==0:\n",
        "                    sentiments_converted= [\"NONE\"]\n",
        "                    new_sent = obj['text']\n",
        "                    new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                    new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))\n",
        "                    index = [0,0]\n",
        "                    sentences.append(new_sent)\n",
        "                    data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "            return data_store,sentences\n",
        "\n",
        "\n",
        "    def convert_all_2_indices(self):\n",
        "        self.data_store = [(self.sentence2indices(a),b,c) for (a,b,c) in self.data_store]\n",
        "    \n",
        "    def find_indices(self,new_sent):\n",
        "        splitted = new_sent.split(\" \")\n",
        "        indices = [i+1 for i,w in enumerate(splitted) if (w==\"START\") or (w==\"END\")]\n",
        "        indices[1] = indices[1]-1\n",
        "        return indices\n",
        "    \n",
        "    def build_vocab(self, dataset, min_freq=1):\n",
        "        counter = Counter()\n",
        "        for a in dataset:\n",
        "            for token in a.split(\" \"):\n",
        "                if token is not None:\n",
        "                    counter[token]+=1\n",
        "        #Counter({'the': 1046, 'and': 671, 'to': 604, etc....}\n",
        "        vocabulary = Vocab(counter, specials=['<pad>', '<unk>'], min_freq=min_freq)\n",
        "        vocabulary.load_vectors(\"glove.6B.50d\")\n",
        "        return vocabulary\n",
        "\n",
        "    def sentence2indices(self,sentence: str) -> torch.Tensor:\n",
        "        return torch.tensor([self.vocabulary[word] for word in sentence.split(' ') if word != ''], dtype=torch.long)\n",
        "\n",
        "    def decode_tag(self,tag):\n",
        "        return self.mlb.inverse_transform(tag.reshape(1,-1))\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
        "        return self.data_store[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQkFG9IpNjLk"
      },
      "source": [
        "def rnn_collate_fn(data_elements: List[Tuple[torch.Tensor, list]] # list of (x, y,z) pairs\n",
        ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    X = [de[0] for de in data_elements]  # list of index tensors\n",
        "    X = torch.nn.utils.rnn.pad_sequence(X, batch_first=True, padding_value=0)  #  shape (batch_size x max_seq_len)\n",
        "    \n",
        "    keyword_position = [de[1] for de in data_elements] # list of tuples indices where keyword is [[1st keyword],[2nd keyword]]\n",
        "\n",
        "    keyword_position = torch.nn.utils.rnn.pad_sequence(keyword_position, batch_first=True, padding_value=0) \n",
        "\n",
        "    y = [de[2] for de in data_elements]\n",
        "    y = torch.nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=-1) \n",
        "\n",
        "    return X, keyword_position, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pvh938xOBro"
      },
      "source": [
        "class TaskBDataModule(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        data_train_path: str,\n",
        "        data_dev_path: str,\n",
        "        batch_size: int,\n",
        "        collate_fn=None\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.data_train_path = data_train_path\n",
        "        self.data_dev_path = data_dev_path\n",
        "        self.batch_size = batch_size\n",
        "        self.collate_fn = collate_fn\n",
        "\n",
        "        self.train_dataset = None\n",
        "        self.validation_dataset = None\n",
        "\n",
        "    def train_dataloader(self, *args, **kwargs) -> DataLoader:\n",
        "        self.train_dataset = TaskBDataset(self.data_train_path)\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)\n",
        "\n",
        "    def val_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
        "        self.validation_dataset = TaskBDataset(self.data_dev_path)\n",
        "        return DataLoader(self.validation_dataset, batch_size=self.batch_size,collate_fn=self.collate_fn)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwunMH6fWNkI"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my_Ku2SAvnBc"
      },
      "source": [
        "Recurrent classifier definition with a customized forward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI7M_zasi1ol"
      },
      "source": [
        "class TaskBRecurrentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vectors_store: torch.Tensor,\n",
        "        n_hidden: int,\n",
        "        drop_prob: float,\n",
        "        bidir: bool,\n",
        "        n_layer_lstm: int,\n",
        "        vocab_size:int, \n",
        "        embedding_dim: int =100,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        # embedding layer\n",
        "        \n",
        "        self.embedding = torch.nn.Embedding.from_pretrained(vectors_store)\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim) # hparams.vocab_size words in vocab, hparams.embedding_dim dimensional embeddings\n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        # recurrent layer\n",
        "        self.lstm = torch.nn.LSTM(input_size=vectors_store.shape[1],\n",
        "                                  hidden_size=n_hidden,\n",
        "                                  num_layers=n_layer_lstm, \n",
        "                                  batch_first=True,\n",
        "                                  bidirectional=bidir)\n",
        "\n",
        "        # classification \n",
        "        if bidir:\n",
        "           n_hidden = n_hidden*2\n",
        "        self.lin1 = torch.nn.Linear(n_hidden, n_hidden)\n",
        "        self.classifier = torch.nn.Linear(n_hidden, 5)\n",
        "\n",
        "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        X: torch.Tensor, \n",
        "        indices_keyword: torch.Tensor, \n",
        "        y: Optional[torch.Tensor] = None\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "\n",
        "        embedding_out = self.embedding(X)\n",
        "        # recurrent encoding\n",
        "        lstm_output = self.lstm(embedding_out)[0]\n",
        "        \n",
        "        batch_size, seq_len, hidden_size = lstm_output.shape\n",
        "\n",
        "        #sequence of batch x seq_len vectors \n",
        "        flat_output = lstm_output.reshape(-1, hidden_size)\n",
        "        \n",
        "        # start offsets of each element in the batch\n",
        "        sequences_offsets = torch.arange(batch_size, device=self.device) * seq_len\n",
        "        \n",
        "        summary_vectors_indices_sent1 = self.get_indices_keyword(indices_keyword, sequences_offsets,0)\n",
        "        summary_vectors_indices_sent2 = self.get_indices_keyword(indices_keyword, sequences_offsets,1)\n",
        "        \n",
        "        # we retrieve the vector of the corrseponding states for the keyword given for each sentence.\n",
        "          \n",
        "        summary_vectors_sent1 = flat_output[summary_vectors_indices_sent1]\n",
        "        summary_vectors_sent2 = flat_output[summary_vectors_indices_sent2]\n",
        "        \n",
        "        # do the multiplication of these two vectors retrieved\n",
        "        summary_vectors = summary_vectors_sent1 * summary_vectors_sent2\n",
        "        \n",
        "        # feedforward MLP\n",
        "        out = self.lin1(summary_vectors)\n",
        "        out = F.leaky_relu(out)\n",
        "        \n",
        "        logits = self.classifier(out)\n",
        "        \n",
        "        pred = torch.argmax(logits, -1)\n",
        "        \n",
        "        result = {'logits': logits, 'pred': pred} \n",
        "\n",
        "        # compute loss\n",
        "        if y is not None:\n",
        "            #logits = logits.view(-1, logits.shape[-1])\n",
        "            #y = y.view(-1)\n",
        "            try:\n",
        "                loss = self.loss(logits, torch.tensor(y, dtype=torch.float))\n",
        "            except:\n",
        "                print(logits.shape,y.shape)\n",
        "            result['loss'] = loss\n",
        "        return result\n",
        "        \n",
        "       \n",
        "    def loss(self, pred, y):\n",
        "        return self.loss_fn(pred, y)\n",
        "   \n",
        "    # '''\n",
        "    # return the corresponding position of the indices of the keyword\n",
        "    # summary  = [   0,   57,  114,  171,  228, ...] \n",
        "    # indices_keywords = [ [ 21],[ 4],[ 61],[ 22], ...]\n",
        "    # '''\n",
        "    # def get_indices_keyword(self,indices_keywords, summary: Sequence[int] ,flat_output) -> torch.Tensor:\n",
        "    #     res = flat_output[torch.tensor([item for item in indices_keywords]).to(self.device) + summary]\n",
        "    #     try:\n",
        "    #         return res\n",
        "    #     except:\n",
        "    #         return flat_output[summary]\n",
        "\n",
        "    '''\n",
        "    return the corresponding position of the indices of the keywords, for the sent_num passed, so the first if 0 is passed and the second if 2 is passed\n",
        "    summary  = [   0,   57,  114,  171,  228, ...] \n",
        "    indices_keywords = [ [ 6, 21],[ 4, 22],[ 6, 21],[ 4, 22], ...]\n",
        "    '''\n",
        "    def get_indices_keyword(self,indices_keywords: Sequence[tuple], summary: Sequence[int] ,sent_num: int) -> torch.Tensor:\n",
        "\n",
        "        tens_idx = torch.tensor([item[sent_num] for item in indices_keywords]).to(self.device)\n",
        "        return tens_idx + summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyB77pPuAkLs"
      },
      "source": [
        "Trainer class that will handle the training phase for the RNN classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzBUPzpQzic_"
      },
      "source": [
        "class TaskBTrainer():\n",
        "    def __init__(self, model, optimizer, device, exp_details):\n",
        "\n",
        "        self.device = device\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.writer = SummaryWriter(comment=\"_\"+exp_details)\n",
        "        self.model.train()  # we are using this model for training\n",
        "        self.model.to(self.device)  # move model to GPU if available\n",
        "\n",
        "    def train(self, train_dataset, eval_dataset, epochs: int = 1, early_stopping: bool = False, early_stopping_patience:int = 3, to_be_saved: bool =False) -> float:\n",
        "\n",
        "        train_loss = 0.0\n",
        "       \n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            epoch_loss = 0.0\n",
        "            len_train = 0\n",
        "            \n",
        "            self.model.train()\n",
        "\n",
        "            # each element (sample) in train_dataset is a batch\n",
        "            for sample in train_dataset:\n",
        "                # inputs in the batch\n",
        "                inputs = sample[0].to(self.device)\n",
        "                # indices of keywords\n",
        "                idx_start = sample[1].to(self.device)\n",
        "                # outputs in the batch\n",
        "                targets = sample[2].to(self.device)\n",
        "\n",
        "                forward_result = self.model(inputs, idx_start, targets)\n",
        "\n",
        "                loss = forward_result['loss']\n",
        "                \n",
        "                loss.backward()  #  backpropagate the loss\n",
        "                # updates the parameters\n",
        "                #Clips gradient norm of an iterable of parameters.\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), CLIP_GRAD)\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "                \n",
        "                epoch_loss += loss.item()\n",
        "                len_train += 1\n",
        "            avg_epoch_loss = epoch_loss / len_train\n",
        "\n",
        "            \n",
        "            train_loss += avg_epoch_loss\n",
        "\n",
        "\n",
        "            print(avg_epoch_loss)\n",
        "            self.writer.flush()\n",
        "    \n",
        "        return train_loss/(epoch+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysl5lG_pxhY9"
      },
      "source": [
        "Loading of the handler for the dataset and choose of the batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeaTHJCvvqCh"
      },
      "source": [
        "BATCH_SIZE = 40 #@param {type:\"slider\", min:8, max:64, step:4}\n",
        "\n",
        "sentences_rnn_dm = TaskBDataModule(\n",
        "    data_train_path=dataset_folder+'/laptops_train.json',\n",
        "    data_dev_path=dataset_folder+'/laptops_dev.json',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn = rnn_collate_fn,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o9d52ZOxdiI"
      },
      "source": [
        "Hyperparameter setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j51GSfZSvyTv"
      },
      "source": [
        "#@title Setup of Hyper-parameters{ run: \"auto\" }\n",
        "\n",
        "n_hidden=82 #@param {type:\"slider\", min:50, max:300, step:16}\n",
        "drop_prob=0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "bidir = True #@param [\"True\", \"False\"] {type:\"raw\"}\n",
        "learning_rate = 0.0001 #@param {type:\"slider\", min:0.00001, max:0.001, step:0.00001}\n",
        "epochs = 25 #@param {type:\"slider\", min:10, max:100, step:10}\n",
        "n_layer_lstm = 2 #@param {type:\"slider\", min:1, max:4, step:1}\n",
        "CLIP_GRAD = 2 #@param {type:\"slider\", min:1, max:10, step:1}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxReoMvS70jb"
      },
      "source": [
        "Start the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmaXIR2DjtCg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b67ff07c-1230-46fa-e389-8649f412c9ae"
      },
      "source": [
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "#loading of the datasets\n",
        "train_dataloader = sentences_rnn_dm.train_dataloader()\n",
        "val_dataloader = sentences_rnn_dm.val_dataloader()\n",
        "\n",
        "\n",
        "task_b_classifier = TaskBRecurrentClassifier(sentences_rnn_dm.train_dataset.vocabulary.vectors, n_hidden=n_hidden,drop_prob=drop_prob, bidir = bidir, n_layer_lstm = n_layer_lstm, vocab_size=len(sentences_rnn_dm.train_dataset.vocabulary),embedding_dim=100)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "#define the optimizer\n",
        "optimizer = torch.optim.Adam(task_b_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "# string to indetify the model once saved or in the graphs\n",
        "exp_details=\"mul_leakyrelu_\" + str(drop_prob) + \"drop_\"+str(n_hidden) +\"hidden_\"+str(learning_rate) +\"lr_\" + str(BATCH_SIZE) +\"batch_\" + str(n_layer_lstm) +\"lstmLayer_\" + str(CLIP_GRAD) +\"clipGrad\"\n",
        "\n",
        "trainer = TaskBTrainer(task_b_classifier, optimizer, device, exp_details)\n",
        "\n",
        "avg_train_loss= trainer.train(train_dataloader, val_dataloader, epochs=epochs, early_stopping=False, early_stopping_patience=6, to_be_saved = True)\n",
        "print(\" avg_train_loss={}\\n \".format(avg_train_loss))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ".vector_cache/glove.6B.zip: 862MB [02:41, 5.34MB/s]                           \n",
            " 99%|█████████▉| 395911/400000 [00:08<00:00, 44115.81it/s]\n",
            "  0%|          | 0/25 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  4%|▍         | 1/25 [00:01<00:26,  1.10s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.672441158765628\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  8%|▊         | 2/25 [00:01<00:22,  1.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.4262655292764122\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 12%|█▏        | 3/25 [00:02<00:19,  1.12it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.30747719090661885\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 16%|█▌        | 4/25 [00:03<00:17,  1.19it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.2665410393182142\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 20%|██        | 5/25 [00:03<00:16,  1.24it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.2523760731205528\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 24%|██▍       | 6/25 [00:04<00:14,  1.29it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.24559879394960993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 28%|██▊       | 7/25 [00:05<00:13,  1.33it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.24169516581812023\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 32%|███▏      | 8/25 [00:06<00:12,  1.34it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.2392489006857813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 36%|███▌      | 9/25 [00:06<00:11,  1.36it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.23766608628225916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 40%|████      | 10/25 [00:07<00:10,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.2365509507096844\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 44%|████▍     | 11/25 [00:08<00:10,  1.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.23577217279392995\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 48%|████▊     | 12/25 [00:08<00:09,  1.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.2351816627714369\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 52%|█████▏    | 13/25 [00:09<00:08,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.23471378452248043\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 56%|█████▌    | 14/25 [00:10<00:07,  1.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.23432531584928065\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 60%|██████    | 15/25 [00:10<00:07,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.23399168639271348\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 64%|██████▍   | 16/25 [00:11<00:06,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.2336696711955247\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 68%|██████▊   | 17/25 [00:12<00:05,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.2333509607447518\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 72%|███████▏  | 18/25 [00:13<00:04,  1.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.2329604645938049\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 76%|███████▌  | 19/25 [00:13<00:04,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.23241092595789167\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 80%|████████  | 20/25 [00:14<00:03,  1.40it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.23168356403892423\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 84%|████████▍ | 21/25 [00:15<00:02,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.23080474634965262\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 88%|████████▊ | 22/25 [00:15<00:02,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.2296894809898035\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 92%|█████████▏| 23/25 [00:16<00:01,  1.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.22823590251766604\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 96%|█████████▌| 24/25 [00:17<00:00,  1.42it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.22627398702833387\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 25/25 [00:18<00:00,  1.38it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.22409910883432554\n",
            " avg_train_loss=0.264120972936536\n",
            " \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICC3g_Wu1kjn"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TloazNlkwqxw"
      },
      "source": [
        " def eval_metrics(eval_dataset):\n",
        "    task_b_classifier.eval()\n",
        "    task_b_classifier.cuda()\n",
        "    pred_outs, true_labels = [],[]\n",
        "    for sample in eval_dataset:\n",
        "        # inputs in the batch\n",
        "        inputs = sample[0].to(device)\n",
        "        idx_start = sample[1].to(device)\n",
        "\n",
        "        # outputs in the batch\n",
        "        targets = sample[2].to(device)\n",
        "        with torch.no_grad():\n",
        "\n",
        "            forward_result = task_b_classifier(inputs, idx_start,targets)\n",
        "            loss = forward_result['loss']\n",
        "            pred_out = torch.sigmoid(forward_result['logits'])\n",
        "        \n",
        "            pred_out = pred_out.detach().cpu().numpy()\n",
        "            y_true = targets.cpu().numpy()\n",
        "\n",
        "        pred_outs.append(pred_out)\n",
        "        true_labels.append(y_true)\n",
        "\n",
        "    flat_pred_outs = np.concatenate(pred_outs, axis=0)\n",
        "\n",
        "    # Combine the correct labels for each batch into a single list.\n",
        "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "    return flat_pred_outs,flat_true_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1HORtKiy-wi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0047e605-1aeb-4db8-be6b-73a4d388034b"
      },
      "source": [
        "flat_pred_outs,flat_true_labels= eval_metrics(val_dataloader)\n",
        "y_true = flat_true_labels.ravel()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8mGhSkU0qOt"
      },
      "source": [
        "def classify(pred_prob):\n",
        "    y_pred = []\n",
        "    for tag_label_row in pred_prob:\n",
        "        temp=[]\n",
        "        max_prob = max(tag_label_row)\n",
        "        for tag_label in tag_label_row:\n",
        "            if tag_label == max_prob:\n",
        "                temp.append(1)\n",
        "            else:\n",
        "                temp.append(0) \n",
        "        y_pred.append(temp)\n",
        "    return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH6MD17T9Q2L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e502e39-e575-4b4d-fdc2-c0e8e51db621"
      },
      "source": [
        "y_pred_labels = classify(flat_pred_outs)\n",
        "\n",
        "y_pred = np.array(y_pred_labels).ravel() # Flatten\n",
        "\n",
        "metr = {}\n",
        "metr['f1'] = f1_score(y_true,y_pred, average=\"macro\")\n",
        "\n",
        "print(metr['f1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7940042075736324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eAiZ5j3a9Q2N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 979
        },
        "outputId": "04831b20-1d93-4488-ce8c-52bb0a932af8"
      },
      "source": [
        "y_pred = sentences_rnn_dm.validation_dataset.mlb.inverse_transform(np.array(y_pred_labels))\n",
        "y_act = sentences_rnn_dm.validation_dataset.mlb.inverse_transform(flat_true_labels)\n",
        "\n",
        "df = pd.DataFrame({'Body':sentences_rnn_dm.validation_dataset.sentences,'Actual Tags':y_act,'Predicted Tags':y_pred})\n",
        "pd.set_option('display.max_rows', 500)\n",
        "df.head(30)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body</th>\n",
              "      <th>Actual Tags</th>\n",
              "      <th>Predicted Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wa rated</td>\n",
              "      <td>(NONE,)</td>\n",
              "      <td>(NONE,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sony said could send back charged START adding...</td>\n",
              "      <td>(negative,)</td>\n",
              "      <td>(negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>START Windows 7 Starter END opinion great way ...</td>\n",
              "      <td>(positive,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>START powerpoint END opened seamlessly apple m...</td>\n",
              "      <td>(positive,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chose iBookG4 laptop attractive computer large...</td>\n",
              "      <td>(positive,)</td>\n",
              "      <td>(negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Finally biggest problem ha START tech support END</td>\n",
              "      <td>(negative,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>pleased purchase</td>\n",
              "      <td>(NONE,)</td>\n",
              "      <td>(NONE,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Mac computer automatically defrag time start c...</td>\n",
              "      <td>(NONE,)</td>\n",
              "      <td>(NONE,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Toshiba START sound END everything certain things</td>\n",
              "      <td>(negative,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>sleek lightweight START charge END quickly needed</td>\n",
              "      <td>(positive,)</td>\n",
              "      <td>(negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>wa worried making two compatible literally wa ...</td>\n",
              "      <td>(NONE,)</td>\n",
              "      <td>(NONE,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>one experine</td>\n",
              "      <td>(NONE,)</td>\n",
              "      <td>(NONE,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>reinstall START standard cd END proprietary ha...</td>\n",
              "      <td>(negative,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>reinstall standard cd START proprietary hardwa...</td>\n",
              "      <td>(negative,)</td>\n",
              "      <td>(negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>developed excellent START proprietary software...</td>\n",
              "      <td>(positive,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>much lauded START combined touch pad clicker E...</td>\n",
              "      <td>(negative,)</td>\n",
              "      <td>(negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>time send back 3 times</td>\n",
              "      <td>(NONE,)</td>\n",
              "      <td>(NONE,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Looks nice ha horribly cheap feel START Looks ...</td>\n",
              "      <td>(positive,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Looks nice ha horribly cheap START feel END</td>\n",
              "      <td>(negative,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>thing updated START video END set</td>\n",
              "      <td>(negative,)</td>\n",
              "      <td>(negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>START 17 inch screen END large computer light</td>\n",
              "      <td>(negative,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>True START quality END great price</td>\n",
              "      <td>(positive,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>True quality great START price END</td>\n",
              "      <td>(positive,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>START unibody design END edgy durable</td>\n",
              "      <td>(positive,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Hewitt Packard Pavillion dv6700 wa first lapto...</td>\n",
              "      <td>(NONE,)</td>\n",
              "      <td>(NONE,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>However laptop ha fatal flaw discovered merely...</td>\n",
              "      <td>(NONE,)</td>\n",
              "      <td>(NONE,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>really concerned START portability END large l...</td>\n",
              "      <td>(conflict,)</td>\n",
              "      <td>(positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>First Dell fan fifteen years</td>\n",
              "      <td>(NONE,)</td>\n",
              "      <td>(NONE,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>Breaking within 1 year purchase speaking 4 peo...</td>\n",
              "      <td>(NONE,)</td>\n",
              "      <td>(NONE,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>challenge anyone show proof anywhere near norm...</td>\n",
              "      <td>(NONE,)</td>\n",
              "      <td>(NONE,)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Body  ... Predicted Tags\n",
              "0                                            wa rated  ...        (NONE,)\n",
              "1   Sony said could send back charged START adding...  ...    (negative,)\n",
              "2   START Windows 7 Starter END opinion great way ...  ...    (positive,)\n",
              "3   START powerpoint END opened seamlessly apple m...  ...    (positive,)\n",
              "4   chose iBookG4 laptop attractive computer large...  ...    (negative,)\n",
              "5   Finally biggest problem ha START tech support END  ...    (positive,)\n",
              "6                                    pleased purchase  ...        (NONE,)\n",
              "7   Mac computer automatically defrag time start c...  ...        (NONE,)\n",
              "8   Toshiba START sound END everything certain things  ...    (positive,)\n",
              "9   sleek lightweight START charge END quickly needed  ...    (negative,)\n",
              "10  wa worried making two compatible literally wa ...  ...        (NONE,)\n",
              "11                                       one experine  ...        (NONE,)\n",
              "12  reinstall START standard cd END proprietary ha...  ...    (positive,)\n",
              "13  reinstall standard cd START proprietary hardwa...  ...    (negative,)\n",
              "14  developed excellent START proprietary software...  ...    (positive,)\n",
              "15  much lauded START combined touch pad clicker E...  ...    (negative,)\n",
              "16                             time send back 3 times  ...        (NONE,)\n",
              "17  Looks nice ha horribly cheap feel START Looks ...  ...    (positive,)\n",
              "18        Looks nice ha horribly cheap START feel END  ...    (positive,)\n",
              "19                  thing updated START video END set  ...    (negative,)\n",
              "20      START 17 inch screen END large computer light  ...    (positive,)\n",
              "21                 True START quality END great price  ...    (positive,)\n",
              "22                 True quality great START price END  ...    (positive,)\n",
              "23              START unibody design END edgy durable  ...    (positive,)\n",
              "24  Hewitt Packard Pavillion dv6700 wa first lapto...  ...        (NONE,)\n",
              "25  However laptop ha fatal flaw discovered merely...  ...        (NONE,)\n",
              "26  really concerned START portability END large l...  ...    (positive,)\n",
              "27                       First Dell fan fifteen years  ...        (NONE,)\n",
              "28  Breaking within 1 year purchase speaking 4 peo...  ...        (NONE,)\n",
              "29  challenge anyone show proof anywhere near norm...  ...        (NONE,)\n",
              "\n",
              "[30 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YZoRkeV-WvS"
      },
      "source": [
        "## docker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bva0yl86-Wve"
      },
      "source": [
        "def load_data(data_path):\n",
        "    with open(data_path) as json_file:\n",
        "        list_of_sentences = json.load(json_file)\n",
        "    return list_of_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nU2fH9O8-Wvd"
      },
      "source": [
        "def evaluate_sentiment(samples, predictions_b, mode=\"Aspect Sentiment\"):\n",
        "    scores = {}\n",
        "    if mode == 'Category Extraction':\n",
        "        sentiment_types = [\"anecdotes/miscellaneous\", \"price\", \"food\", \"ambience\"]\n",
        "    else:\n",
        "        sentiment_types = [\"positive\", \"negative\", \"neutral\", \"conflict\"]\n",
        "    scores = {sent: {\"tp\": 0, \"fp\": 0, \"fn\": 0} for sent in sentiment_types + [\"ALL\"]}\n",
        "    for label, pred in zip(samples, predictions_b):\n",
        "        for sentiment in sentiment_types:\n",
        "            if mode == \"Aspect Sentiment\":\n",
        "                pred_sent = {(term_pred[0], term_pred[1]) for term_pred in pred[\"targets\"] if\n",
        "                                    term_pred[1] == sentiment}\n",
        "                gt_sent = {(term_pred[1], term_pred[2]) for term_pred in label[\"targets\"] if\n",
        "                                    term_pred[2] == sentiment}\n",
        "            elif mode == 'Category Extraction' and \"categories\" in label:\n",
        "                pred_sent = {(term_pred[0]) for term_pred in pred[\"categories\"] if\n",
        "                                term_pred[0] == sentiment}\n",
        "                gt_sent = {(term_pred[0]) for term_pred in label[\"categories\"] if\n",
        "                                term_pred[0] == sentiment}\n",
        "            elif \"categories\" in label:\n",
        "                pred_sent = {(term_pred[0], term_pred[1]) for term_pred in pred[\"categories\"] if\n",
        "                                term_pred[1] == sentiment}\n",
        "                gt_sent = {(term_pred[0], term_pred[1]) for term_pred in label[\"categories\"] if\n",
        "                                term_pred[1] == sentiment}\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            scores[sentiment][\"tp\"] += len(pred_sent & gt_sent)\n",
        "            scores[sentiment][\"fp\"] += len(pred_sent - gt_sent)\n",
        "            scores[sentiment][\"fn\"] += len(gt_sent - pred_sent)\n",
        "\n",
        "    # Compute per sentiment Precision / Recall / F1\n",
        "    for sent_type in scores.keys():\n",
        "        if scores[sent_type][\"tp\"]:\n",
        "            scores[sent_type][\"p\"] = 100 * scores[sent_type][\"tp\"] / (scores[sent_type][\"fp\"] + scores[sent_type][\"tp\"])\n",
        "            scores[sent_type][\"r\"] = 100 * scores[sent_type][\"tp\"] / (scores[sent_type][\"fn\"] + scores[sent_type][\"tp\"])\n",
        "        else:\n",
        "            scores[sent_type][\"p\"], scores[sent_type][\"r\"] = 0, 0\n",
        "\n",
        "        if not scores[sent_type][\"p\"] + scores[sent_type][\"r\"] == 0:\n",
        "            scores[sent_type][\"f1\"] = 2 * scores[sent_type][\"p\"] * scores[sent_type][\"r\"] / (\n",
        "                    scores[sent_type][\"p\"] + scores[sent_type][\"r\"])\n",
        "        else:\n",
        "            scores[sent_type][\"f1\"] = 0\n",
        "\n",
        "    # Compute micro F1 Scores\n",
        "    tp = sum([scores[sent_type][\"tp\"] for sent_type in sentiment_types])\n",
        "    fp = sum([scores[sent_type][\"fp\"] for sent_type in sentiment_types])\n",
        "    fn = sum([scores[sent_type][\"fn\"] for sent_type in sentiment_types])\n",
        "\n",
        "    if tp:\n",
        "        precision = 100 * tp / (tp + fp)\n",
        "        recall = 100 * tp / (tp + fn)\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    else:\n",
        "        precision, recall, f1 = 0, 0, 0\n",
        "\n",
        "    scores[\"ALL\"][\"p\"] = precision\n",
        "    scores[\"ALL\"][\"r\"] = recall\n",
        "    scores[\"ALL\"][\"f1\"] = f1\n",
        "    scores[\"ALL\"][\"tp\"] = tp\n",
        "    scores[\"ALL\"][\"fp\"] = fp\n",
        "    scores[\"ALL\"][\"fn\"] = fn\n",
        "\n",
        "    # Compute Macro F1 Scores\n",
        "    scores[\"ALL\"][\"Macro_f1\"] = sum([scores[ent_type][\"f1\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "    scores[\"ALL\"][\"Macro_p\"] = sum([scores[ent_type][\"p\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "    scores[\"ALL\"][\"Macro_r\"] = sum([scores[ent_type][\"r\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "\n",
        "    print(f\"{mode} Evaluation\\n\")\n",
        "\n",
        "    print(\n",
        "        \"\\tALL\\t TP: {};\\tFP: {};\\tFN: {}\".format(\n",
        "            scores[\"ALL\"][\"tp\"],\n",
        "            scores[\"ALL\"][\"fp\"],\n",
        "            scores[\"ALL\"][\"fn\"]))\n",
        "    print(\n",
        "        \"\\t\\t(m avg): precision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f} (micro)\".format(\n",
        "            precision,\n",
        "            recall,\n",
        "            f1))\n",
        "    print(\n",
        "        \"\\t\\t(M avg): precision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f} (Macro)\\n\".format(\n",
        "            scores[\"ALL\"][\"Macro_p\"],\n",
        "            scores[\"ALL\"][\"Macro_r\"],\n",
        "            scores[\"ALL\"][\"Macro_f1\"]))\n",
        "\n",
        "    for sent_type in sentiment_types:\n",
        "        print(\"\\t{}: \\tTP: {};\\tFP: {};\\tFN: {};\\tprecision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f};\\t{}\".format(\n",
        "            sent_type,\n",
        "            scores[sent_type][\"tp\"],\n",
        "            scores[sent_type][\"fp\"],\n",
        "            scores[sent_type][\"fn\"],\n",
        "            scores[sent_type][\"p\"],\n",
        "            scores[sent_type][\"r\"],\n",
        "            scores[sent_type][\"f1\"],\n",
        "            scores[sent_type][\"tp\"] +\n",
        "            scores[sent_type][\n",
        "                \"fp\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdak0rlf-Wvc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89832447-9a04-4e63-8daf-1fa13cddad50"
      },
      "source": [
        "class PreprocessBNEW():\n",
        "    def __init__(self, sentences):\n",
        "        self.data_store,self.sentences,self.targets = self.load_data(sentences)\n",
        "        self.vocabulary = self.build_vocab(self.sentences)\n",
        "        self.convert_all_2_indices()\n",
        "        self.tags = [[\"neutral\",\"negative\", \"conflict\", \"positive\", \"NONE\"]]\n",
        "        self.mlb = MultiLabelBinarizer()\n",
        "        self.mlb.fit_transform(self.tags)\n",
        "        \n",
        "    def remove_stopwords(self,sent: str) -> str:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        # remove punkt\n",
        "        others = \"–\" +\"—\" + \"−\" + \"’\" + \"”\" + \"“\" #These chars arent inside the standard punctuation\n",
        "        str_punkt = string.punctuation+ others\n",
        "        translator = str.maketrans(str_punkt, ' '*len(str_punkt)) \n",
        "        word_tokens = word_tokenize(sent.translate(translator)) \n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        return filtered_sentence\n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        data_store,sentences,targets = [],[],[]\n",
        "        for obj in list_of_sentences:\n",
        "            _sentence = []\n",
        "            obj['targets'] = sorted(obj['targets'], key=lambda x: x[0][0])\n",
        "            sentiments = [obj['targets'][j][2] for j in range(len(obj['targets']))]\n",
        "\n",
        "            for i,targ_obj in enumerate(obj['targets']):\n",
        "                #print(targ_obj)\n",
        "                new_sent = obj['text'][:targ_obj[0][0]-1]+\" <START> \" + obj['text'][targ_obj[0][0]:targ_obj[0][1]] + \" <END>\" + obj['text'][targ_obj[0][1]:]\n",
        "                new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))    \n",
        "                index = self.find_indices(new_sent)\n",
        "                    \n",
        "                sentences.append(new_sent)\n",
        "                sentiments_converted = [sentiments[i]]\n",
        "                targets.append([(targ[1], \"\") for j,targ in enumerate(obj['targets'])])\n",
        "\n",
        "                data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "\n",
        "            if len(obj['targets'])==0:\n",
        "                sentiments_converted= [\"NONE\"]\n",
        "                targets.append([(targ[1], \"\") for j,targ in enumerate(obj['targets'])])\n",
        "\n",
        "                new_sent = obj['text']\n",
        "                # new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                # new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))\n",
        "                index = [0,0]\n",
        "                sentences.append(new_sent)\n",
        "                data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "        \n",
        "        return data_store,sentences,targets\n",
        "\n",
        "\n",
        "    def convert_all_2_indices(self):\n",
        "        self.data_store = [(self.sentence2indices(a),b,c) for (a,b,c) in self.data_store]\n",
        "    \n",
        "    def find_indices(self,new_sent):\n",
        "        splitted = new_sent.split(\" \")\n",
        "        indices = [i+1 for i,w in enumerate(splitted) if (w==\"START\") or (w==\"END\")]\n",
        "        indices[1] = indices[1]-1\n",
        "        return indices\n",
        "                \n",
        "    \n",
        "    def build_vocab(self, dataset, min_freq=1):\n",
        "        counter = Counter()\n",
        "        for a in dataset:\n",
        "            # for each token in the sentence viewed as a dictionary of items from the line\n",
        "            for token in a.split(\" \"):\n",
        "                if token is not None:\n",
        "                    counter[token]+=1\n",
        "        #Counter({'the': 1046, 'and': 671, 'to': 604, etc....}\n",
        "        # we add special tokens for handling padding and unknown words at testing time.\n",
        "        vocabulary = Vocab(counter, specials=['<pad>', '<unk>'], min_freq=min_freq)\n",
        "        #vocabulary.load_vectors(\"glove.6B.50d\")\n",
        "        return vocabulary\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
        "        return self.data_store[idx]\n",
        "\n",
        "    def sentence2indices(self,sentence: str) -> torch.Tensor:\n",
        "        return torch.tensor([self.vocabulary[word] for word in sentence.split(' ') if word != ''], dtype=torch.long)\n",
        "\n",
        "    def decode_tag(self,tag):\n",
        "        return self.mlb.inverse_transform(tag.reshape(1,-1))\n",
        "    \n",
        "    \n",
        "def rnn_collate_fn(data_elements: List[Tuple[torch.Tensor, list]] # list of (x, y,z) pairs\n",
        ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    X = [de[0] for de in data_elements]  # list of index tensors\n",
        "    X = torch.nn.utils.rnn.pad_sequence(X, batch_first=True, padding_value=0)  #  shape (batch_size x max_seq_len)\n",
        "    \n",
        "    keyword_position = [de[1] for de in data_elements] # list of tuples indices where keyword is [[1st sent, 2nd sent]]\n",
        "\n",
        "    keyword_position = torch.nn.utils.rnn.pad_sequence(keyword_position, batch_first=True, padding_value=0) \n",
        "\n",
        "\n",
        "\n",
        "    return X, keyword_position\n",
        "\n",
        "def classify(pred_prob):\n",
        "    y_pred = []\n",
        "\n",
        "    for tag_label_row in pred_prob:\n",
        "        temp=[]\n",
        "        max_prob = max(tag_label_row)\n",
        "        for tag_label in tag_label_row:\n",
        "            if tag_label == max_prob:\n",
        "                temp.append(1) # Infer tag value as 1 (present)\n",
        "            else:\n",
        "                temp.append(0) # Infer tag value as 0 (absent)\n",
        "        y_pred.append(temp)\n",
        "\n",
        "    return y_pred\n",
        "    \n",
        "# def predictBNEW(samples: List[Dict]) -> List[Dict]:\n",
        "#     targets = []\n",
        "#     prep = PreprocessBNEW(samples)\n",
        "#     task_b_classifier.eval()\n",
        "#     pred_outs = []\n",
        "#     for i,sample in enumerate(prep.data_store):\n",
        "#         try: #yet started\n",
        "#             started = started\n",
        "#         except:\n",
        "#             started = False\n",
        "        \n",
        "#         if len(prep.targets[i])>1 and not started:\n",
        "#             cont = len(prep.targets[i])\n",
        "#             started = True\n",
        "#             json_pred = {\"targets\":prep.targets[i]}\n",
        "#             sentiments = []\n",
        "        \n",
        "#         elif len(prep.targets[i]) == 1:\n",
        "#             json_pred = {\"targets\":prep.targets[i]}\n",
        "#             cont = 1\n",
        "#             sentiments = []\n",
        "#         elif len(prep.targets[i]) == 0:\n",
        "#             cont = 0\n",
        "#             json_pred = {\"targets\":prep.targets[i]}\n",
        "#             sentiments = []\n",
        "        \n",
        "#         lst,pred = [],[]\n",
        "\n",
        "#         inputs,idx_start = rnn_collate_fn([sample]) # inputs in the batch\n",
        "#         with torch.no_grad():\n",
        "#             forward_result = task_b_classifier(inputs.cpu(), idx_start.cpu())\n",
        "#             pred_out = torch.sigmoid(forward_result['logits'])\n",
        "#             pred_out = pred_out.detach().cpu().numpy()\n",
        "\n",
        "#         y_pred_labels = classify(pred_out)\n",
        "#         y_pred = prep.mlb.inverse_transform(np.array(y_pred_labels))\n",
        "#         for pred in y_pred:\n",
        "#             sentiments += list(pred)\n",
        "        \n",
        "#         cont-=1\n",
        "#         if cont <= 0:\n",
        "#             for k,targ in enumerate(json_pred['targets']):\n",
        "#                 try:\n",
        "#                     if sentiments[k] != \"NONE\":\n",
        "#                         json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],sentiments[k])\n",
        "#                 except:\n",
        "#                     json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],\"conflict\")\n",
        "#             started = False\n",
        "#             if len(prep.targets[i]) == len(json_pred['targets']):\n",
        "#                 targets.append(json_pred)\n",
        "#             else:\n",
        "#                 print(prep.sentences[i-1], prep.targets[i-1],targets[-2]['targets'])\n",
        "#                 print(prep.sentences[i], prep.targets[i] ,json_pred['targets'])\n",
        "#                 targets[-2]['targets'] = json_pred['targets']\n",
        "#                 targets.append(json_pred)\n",
        "#     return targets\n",
        "\n",
        "def predictBBNEW(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessBNEW(samples)\n",
        "    task_b_classifier.eval()\n",
        "    i = 0\n",
        "    task_b_classifier.cpu()\n",
        "    print(len(prep.data_store))\n",
        "    while i < len(prep.data_store):\n",
        "        cont = len(prep.targets[i])\n",
        "        json_pred = {\"targets\":prep.targets[i]}\n",
        "        if cont==0:\n",
        "            i+=1\n",
        "        sentiments = []\n",
        "        while cont > 0:\n",
        "            inputs,idx_start = rnn_collate_fn([prep.data_store[i]]) # inputs in the batch\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                forward_result = task_b_classifier(inputs.cpu(), idx_start.cpu())\n",
        "                pred_out = torch.sigmoid(forward_result['logits'])\n",
        "                pred_out = pred_out.detach().cpu().numpy()\n",
        "\n",
        "            y_pred_labels = classify(pred_out)\n",
        "            y_pred = prep.mlb.inverse_transform(np.array(y_pred_labels))\n",
        "            for pred in y_pred:\n",
        "                sentiments += list(pred)\n",
        "            cont-=1\n",
        "            i+=1\n",
        "        for k,targ in enumerate(json_pred['targets']):\n",
        "            try:\n",
        "                if sentiments[k] != \"NONE\":\n",
        "                    json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],sentiments[k])\n",
        "            except:\n",
        "                json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],\"conflict\")\n",
        "        targets.append(json_pred)\n",
        "    return targets\n",
        "\n",
        "a = load_data(dataset_folder+\"/laptops_dev.json\")\n",
        "random.shuffle(a)\n",
        "t = predictBBNEW(a)\n",
        "for x,y in zip(a[:30],t[:30]):\n",
        "    print(x['targets'],\"SEP\",y['targets'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "713\n",
            "[[[131, 143], 'applications', 'neutral']] SEP [('applications', 'positive')]\n",
            "[] SEP []\n",
            "[[[11, 19], 'programs', 'positive'], [[21, 28], 'Keynote', 'neutral'], [[30, 35], 'Pages', 'neutral'], [[37, 44], 'Numbers', 'neutral']] SEP [('programs', 'positive'), ('Keynote', 'positive'), ('Pages', 'positive'), ('Numbers', 'positive')]\n",
            "[[[21, 29], 'operates', 'positive']] SEP [('operates', 'positive')]\n",
            "[[[0, 8], 'Delivery', 'positive']] SEP [('Delivery', 'positive')]\n",
            "[] SEP []\n",
            "[] SEP []\n",
            "[[[110, 117], 'company', 'negative']] SEP [('company', 'positive')]\n",
            "[[[12, 25], 'aluminum body', 'positive']] SEP [('aluminum body', 'positive')]\n",
            "[[[0, 14], 'Windows XP SP2', 'negative']] SEP [('Windows XP SP2', 'positive')]\n",
            "[] SEP []\n",
            "[[[10, 29], 'Toshiba online help', 'positive']] SEP [('Toshiba online help', 'positive')]\n",
            "[[[32, 39], 'charges', 'positive']] SEP [('charges', 'positive')]\n",
            "[[[37, 41], 'look', 'positive'], [[61, 80], 'after sales support', 'negative']] SEP [('look', 'negative'), ('after sales support', 'negative')]\n",
            "[] SEP []\n",
            "[[[23, 30], 'service', 'negative']] SEP [('service', 'positive')]\n",
            "[[[15, 18], 'use', 'positive'], [[33, 42], 'transport', 'positive']] SEP [('use', 'positive'), ('transport', 'positive')]\n",
            "[[[85, 94], 'Pentium 4', 'neutral'], [[103, 111], '1 GB ram', 'neutral']] SEP [('Pentium 4', 'negative'), ('1 GB ram', 'negative')]\n",
            "[] SEP []\n",
            "[[[48, 61], 'recovery DVDs', 'neutral'], [[73, 95], 'driver/application DVD', 'neutral']] SEP [('recovery DVDs', 'positive'), ('driver/application DVD', 'positive')]\n",
            "[] SEP []\n",
            "[] SEP []\n",
            "[[[11, 21], 'booting up', 'positive'], [[24, 37], 'shutting down', 'positive'], [[43, 71], 'connection with the internet', 'positive']] SEP [('booting up', 'positive'), ('shutting down', 'negative'), ('connection with the internet', 'positive')]\n",
            "[[[4, 16], 'battery life', 'negative']] SEP [('battery life', 'positive')]\n",
            "[] SEP []\n",
            "[] SEP []\n",
            "[] SEP []\n",
            "[[[38, 50], 'tech support', 'negative']] SEP [('tech support', 'positive')]\n",
            "[[[104, 115], 'trend micro', 'neutral'], [[122, 139], 'antiviral program', 'neutral']] SEP [('trend micro', 'negative'), ('antiviral program', 'positive')]\n",
            "[[[21, 35], 'standard os cd', 'negative'], [[47, 75], 'proprietary hardware drivers', 'negative']] SEP [('standard os cd', 'positive'), ('proprietary hardware drivers', 'positive')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGPgX7edIMpb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27339a93-41d5-4f59-c685-99d14edf6e69"
      },
      "source": [
        "evaluate_sentiment(a,t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aspect Sentiment Evaluation\n",
            "\n",
            "\tALL\t TP: 195;\tFP: 229;\tFN: 231\n",
            "\t\t(m avg): precision: 45.99;\trecall: 45.77;\tf1: 45.88 (micro)\n",
            "\t\t(M avg): precision: 22.78;\trecall: 27.85;\tf1: 22.94 (Macro)\n",
            "\n",
            "\tpositive: \tTP: 160;\tFP: 186;\tFN: 23;\tprecision: 46.24;\trecall: 87.43;\tf1: 60.49;\t346\n",
            "\tnegative: \tTP: 35;\tFP: 43;\tFN: 111;\tprecision: 44.87;\trecall: 23.97;\tf1: 31.25;\t78\n",
            "\tneutral: \tTP: 0;\tFP: 0;\tFN: 91;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
            "\tconflict: \tTP: 0;\tFP: 0;\tFN: 6;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7cdZZOGT-3y"
      },
      "source": [
        "# TASK A-B (DistillBERT fine tuning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzeLLprlNkYo"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qga1F6PWMAJ7"
      },
      "source": [
        "Define of the transfomers dataset class, this class will load raw data and then encode the labels into tag and using the Bert tokenizer, tokenize the sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Uhysd9XzAS"
      },
      "source": [
        "class TransformersDataset(Dataset):\n",
        "    def __init__(self, path,path2, model_b):\n",
        "        self.model_b = model_b\n",
        "        self.texts, self.tags = self.load_data(path)\n",
        "        texts2,tags2 = self.load_data(path2)\n",
        "        self.texts = self.texts + texts2\n",
        "        self.tags = self.tags + tags2\n",
        "\n",
        "        self.tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
        "        self.encodings = self.tokenizer(self.texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "        self.unique_tags = set(tag for doc in self.tags for tag in doc)\n",
        "        self.tag2id = {tag: id for id, tag in enumerate(self.unique_tags)}\n",
        "        self.id2tag = {id: tag for tag, id in self.tag2id.items()}\n",
        "        self.labels = self.encode_tags(self.tags, self.encodings)\n",
        "        \n",
        "\n",
        "    def load_data(self,data_path):\n",
        "        sentences,texts,tags = [], [], []\n",
        "        with open(data_path) as json_file:\n",
        "            list_of_sentences = json.load(json_file)\n",
        "            for obj in list_of_sentences:\n",
        "                _sentence = []\n",
        "                for t in tokenizer.tokenize(obj['text']):\n",
        "                    ne_label = \"O\"\n",
        "                    sentiment = \"\"\n",
        "                    for i in range(len(obj['targets'])):\n",
        "                        if t in obj['targets'][i][1] and len(t)>2:\n",
        "                            #if its first word i.e. \"battery life\" (battery)\n",
        "                            ne_label = \"B\" if t == obj['targets'][i][1].split(\" \")[0] else \"I\"\n",
        "                            #if for any reason the I tag is assigned but the word before its not a B\n",
        "                            try:\n",
        "                                if ne_label == \"I\" and _sentence[-1][\"ne_label\"] == \"O\":\n",
        "                                    ne_label = \"O\"\n",
        "                            except:\n",
        "                                pass\n",
        "                            sentiment = obj['targets'][i][2]\n",
        "                            if self.model_b and ne_label != \"O\":\n",
        "                                ne_label = ne_label +\"-\"+sentiment\n",
        "                    token = {\"token\": t, \"ne_label\": ne_label , \"sentiment\" :sentiment}\n",
        "                    _sentence.append(token)\n",
        "                sentences.append(_sentence)\n",
        "\n",
        "            for elem in sentences:\n",
        "                texts.append([tok['token'] for tok in elem])\n",
        "                tags.append([tag['ne_label'] for tag in elem])\n",
        "            return texts, tags\n",
        "    \n",
        "    def encode_tags(self,tags, encodings):\n",
        "        labels = [[self.tag2id[tag] for tag in doc] for doc in tags]\n",
        "        encoded_labels = []\n",
        "        for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
        "            # create an empty array of -100\n",
        "            doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
        "            arr_offset = np.array(doc_offset)\n",
        "\n",
        "            try:\n",
        "                # set labels whose first offset position is 0 and the second is not 0\n",
        "                doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
        "                encoded_labels.append(doc_enc_labels.tolist())\n",
        "            except:\n",
        "                print(doc_labels, doc_offset)\n",
        "\n",
        "        return encoded_labels\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        item['text'] = self.texts[idx] + [\"<end>\"] *(100-len(self.texts[idx]))\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkoCFfmtNajs"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgsLrhLeMWgK"
      },
      "source": [
        "I used a custom Trainer, instead of using the one of huggingface because I do not know if we were allowed to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bAOyDBNlVyK"
      },
      "source": [
        "class TrainerTransformers():\n",
        "    def __init__(self, model, optimizer, device,comments=\"transformers\"):\n",
        "\n",
        "        self.device = device\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.writer = SummaryWriter(comment=\"_\"+comments)\n",
        "        self.model.train()  # we are using this model for training\n",
        "        self.model.to(self.device)  # move model to GPU if available\n",
        "\n",
        "    def train(self, train_loader, val_loader, epochs: int = 1) -> float:\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            tot_loss,tot_train_f1 = 0,0\n",
        "            model.train()\n",
        "            for i,batch in enumerate(train_loader):\n",
        "                optim.zero_grad()\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                loss = outputs[0]\n",
        "                loss.backward()\n",
        "                optim.step()\n",
        "                tot_loss += loss.item()\n",
        "                #tot_train_f1+=self.calc_f1(outputs['logits'],labels,batch['text'])\n",
        "                \n",
        "            train_loss,train_f1 = tot_loss/i+1, tot_train_f1/i+1\n",
        "            val_loss,val_f1 = self.eval_metrics(val_loader,epochs)\n",
        "            \n",
        "            self.writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
        "            #self.writer.add_scalar(\"train/f1\", tot_train_f1, epoch)\n",
        "\n",
        "            self.writer.add_scalar(\"eval/loss\", val_loss, epoch)\n",
        "            #self.writer.add_scalar(\"eval/f1\", val_f1, epoch)\n",
        "            \n",
        "            print(\"epoch {} train_loss={:0.4f} eval_loss={:0.4f}\".format(epoch+1,train_loss,val_loss))\n",
        "\n",
        "    def eval_metrics(self,val_loader,epochs):\n",
        "        model.eval()\n",
        "        tot_val_loss,tot_val_f1 = 0,0\n",
        "        for idx,batch in enumerate(val_loader):\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs[0]\n",
        "            #tot_val_f1+=self.calc_f1(outputs['logits'],labels,batch['text'])\n",
        "\n",
        "            tot_val_loss += loss.item()\n",
        "        return tot_val_loss/idx+1, tot_val_f1/idx+1\n",
        "\n",
        "    \n",
        "    # def calc_f1(self,logits,labels,text):\n",
        "    #     lst = []\n",
        "    #     for id in logits[0].argmax(1):\n",
        "    #         lst.append(id.item())\n",
        "    #     ground_truth = labels\n",
        "    #     text = [sent for sent in text if \"<end>\" not in sent]\n",
        "    #     text = [item for sublist in text for item in sublist]\n",
        "    #     print(text)\n",
        "    #     pred = self.new_logits(text, lst,val_dataset.tokenizer)[1:-1]\n",
        "    #     print(pred)\n",
        "\n",
        "    #     f1_macro = f1_score(ground_truth, pred, average=\"macro\", zero_division=0)\n",
        "    #     return f1_macro\n",
        "    # def new_logits(self,text,logits,tokenizer):\n",
        "    #     new_logits = list()\n",
        "    #     for t in text:\n",
        "    #         offset = tokenizer(t, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)['offset_mapping']\n",
        "    #         for i, tup in enumerate(offset):\n",
        "    #             if tup[0] == 0:\n",
        "    #                 new_logits.append(logits[i])\n",
        "    #     return new_logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozyl5hh8Mk-v"
      },
      "source": [
        "Declaration of the datasets, dataloaders and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKG9h3ClX3Gr"
      },
      "source": [
        "train_dataset = TransformersDataset(dataset_folder+\"/laptops_train.json\",dataset_folder+\"/restaurants_train.json\",model_b)\n",
        "val_dataset = TransformersDataset(dataset_folder+\"/laptops_dev.json\",dataset_folder+\"/restaurants_dev.json\",model_b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1ja43QlEEt_",
        "outputId": "88568c87-4fad-434d-fd00-2411b0a94c58"
      },
      "source": [
        "for id, tag in enumerate(val_dataset.unique_tags):\n",
        "    print(id,tag)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 I-conflict\n",
            "1 I-negative\n",
            "2 I-neutral\n",
            "3 B-positive\n",
            "4 B-conflict\n",
            "5 B-negative\n",
            "6 O\n",
            "7 B-neutral\n",
            "8 I-positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXbXR7yinbhV",
        "outputId": "10f30846-2684-47e2-9c84-4dd24125aabf"
      },
      "source": [
        "model = DistilBertForTokenClassification.from_pretrained('distilbert-base-cased', num_labels=len(train_dataset.unique_tags))\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "optim = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForTokenClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8Rkeo6HM7YH"
      },
      "source": [
        "Start of the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNqv6uTuJrT-",
        "outputId": "8e731786-9b73-4bd9-8337-9e599576c565"
      },
      "source": [
        "trainer = TrainerTransformers(model,optim,device, comments=\"comment\")\n",
        "trainer.train(train_loader,val_loader, epochs=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 1/3 [00:27<00:55, 27.76s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 1 train_loss=1.2462 eval_loss=1.1778\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r 67%|██████▋   | 2/3 [00:55<00:27, 27.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 2 train_loss=1.1232 eval_loss=1.1656\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [01:23<00:00, 27.77s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch 3 train_loss=1.0698 eval_loss=1.1941\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCwLdySOM9it"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN2i1zyOlX03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea210d85-ad1d-440d-f79d-0695eb8f5f48"
      },
      "source": [
        "def new_logits(text,logits,tokenizer):\n",
        "    offset = tokenizer(text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)['offset_mapping']\n",
        "    new_logits = list()\n",
        "    for i, tup in enumerate(offset):\n",
        "        if tup[0] == 0:\n",
        "            new_logits.append(logits[i])\n",
        "    return new_logits\n",
        "\n",
        "def calculate_metrics(model,val_dataset):\n",
        "    model.eval()\n",
        "    model.cuda()\n",
        "    ground_truth,pred = [],[]\n",
        "    for i,t in enumerate(val_dataset.texts):\n",
        "        lst = []\n",
        "        ids = val_dataset.tokenizer(val_dataset.texts[i], is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)[\"input_ids\"]\n",
        "        logits = model(torch.tensor([ids]).to(device))[\"logits\"]\n",
        "        for id in logits[0].argmax(1):\n",
        "            lst.append(id.item())\n",
        "        #print(val_dataset.texts[i])\n",
        "        ground_truth.append([val_dataset.tag2id[tag] for tag in val_dataset.tags[i]])\n",
        "        pred.append((new_logits(val_dataset.texts[i], lst,val_dataset.tokenizer)[1:-1]))\n",
        "    ground_truth = [item for sublist in ground_truth for item in sublist]\n",
        "    pred = [item for sublist in pred for item in sublist]\n",
        "    \n",
        "    micro_precision = sk_precision(ground_truth, pred, average=\"macro\", zero_division=0)\n",
        "    \n",
        "    # precision per class and arithmetic average of them. Does not take into account class imbalance.\n",
        "    f1_macro = f1_score(ground_truth, pred, average=\"macro\", zero_division=0)\n",
        "    per_class_precision = sk_precision(ground_truth, pred, labels = list(range(len(val_dataset.tag2id))), average=None, zero_division=0)\n",
        "    precisions = {\"micro_precision\":micro_precision, \"f1_macro\":f1_macro, \"per_class_precision\":per_class_precision}\n",
        "    return precisions\n",
        "\n",
        "precisions = calculate_metrics(model,val_dataset)\n",
        "\n",
        "print(\"Macro Precision: {}\\nMacro F1: {}\".format(precisions[\"micro_precision\"], precisions[\"f1_macro\"]))\n",
        "print(\"Per class Precision:\")\n",
        "for idx_class, precision in sorted(enumerate(precisions[\"per_class_precision\"]), key=lambda elem: -elem[1]):\n",
        "    label = val_dataset.id2tag[idx_class]\n",
        "    print(label, precision)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Macro Precision: 0.44363683375640456\n",
            "Macro F1: 0.44115863159254076\n",
            "Per class Precision:\n",
            "O 0.9870322080484882\n",
            "B-positive 0.6145833333333334\n",
            "B-negative 0.5494505494505495\n",
            "I-positive 0.525096525096525\n",
            "I-negative 0.48514851485148514\n",
            "B-neutral 0.4411764705882353\n",
            "I-neutral 0.3902439024390244\n",
            "I-conflict 0.0\n",
            "B-conflict 0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAOR0KOb4ZKG"
      },
      "source": [
        "torch.save(model.state_dict(), root_folder+'/model/model_AB_together={}_f1_{:0.4f}.pt'.format(str(model_b), precisions[\"f1_macro\"])) # save the model state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSG4VPikPMqp"
      },
      "source": [
        "## docker"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiGlYlt9DiaM"
      },
      "source": [
        "#### Model B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "896ZmUjE6GPh"
      },
      "source": [
        "class PreprocessB():\n",
        "    def __init__(self, sentences):\n",
        "        self.texts, self.tags = self.load_data(sentences)\n",
        "        self.tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
        "        self.encodings = self.tokenizer(self.texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "        \n",
        "        self.tag2id = {'neutral':0, 'negative':1, 'conflict':2, 'O':3,'positive':4 }\n",
        "        #self.tag2id = {tag: id for id, tag in enumerate(self.unique_tags)}\n",
        "        self.id2tag = {id: tag for tag, id in self.tag2id.items()}\n",
        "                \n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        sentences,texts,tags = [], [], []\n",
        "        for obj in list_of_sentences:\n",
        "            _sentence = []\n",
        "            for t in tokenizer.tokenize(obj['text']):\n",
        "                ne_label =\"O\"\n",
        "                for i in range(len(obj['targets'])):\n",
        "                    if t in obj['targets'][i][1]: #if target word\n",
        "                        ne_label = obj['targets'][i][1]\n",
        "                        break\n",
        "                        \n",
        "                token = {\"token\": t, \"ne_label\": ne_label}\n",
        "                _sentence.append(token)\n",
        "\n",
        "            sentences.append(_sentence)\n",
        "\n",
        "        for i,elem in enumerate(sentences):\n",
        "            texts.append([tok['token'] for tok in elem])\n",
        "            #new_lst = list()\n",
        "            tags.append([(targ[1], \"\") for j,targ in enumerate(list_of_sentences[i]['targets'])])\n",
        "            #print(tags)\n",
        "            # for tag in elem:\n",
        "            #     if tag['ne_label'] != \"O\" and tag['ne_label'] not in new_lst:\n",
        "            #         new_lst.append(tag['ne_label'])\n",
        "            # tags.append(new_lst)\n",
        "        return texts, tags\n",
        "    \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "def new_logits(text,logits,tokenizer):\n",
        "    offset = tokenizer(text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)['offset_mapping']\n",
        "    new_logits = list()\n",
        "    for i, tup in enumerate(offset):\n",
        "        if tup[0] == 0:\n",
        "            new_logits.append(logits[i])\n",
        "    return new_logits\n",
        "\n",
        "def predictB(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessB(samples)\n",
        "    for i,encode in enumerate(prep.encodings['input_ids']):\n",
        "        json_pred = {\"targets\":prep.tags[i]}\n",
        "        lst,pred = [],[]\n",
        "        ids = torch.unsqueeze(torch.tensor(encode),0)\n",
        "        attention_mask = torch.unsqueeze(torch.tensor(prep.encodings['attention_mask'][i]),0)\n",
        "\n",
        "        logits = model(torch.tensor(ids).to(\"cpu\"), torch.tensor(attention_mask).cpu())[\"logits\"]\n",
        "        for id in logits[0].argmax(1):\n",
        "            lst.append(id.item())\n",
        "        p = new_logits(prep.texts[i], lst,prep.tokenizer)[1:-1]\n",
        "        idtotag = [prep.id2tag[raw_pred] for raw_pred in p]\n",
        "        sentiments = []\n",
        "        # for j,sentiment in enumerate(idtotag):\n",
        "        #     if (sentiment != \"O\"):\n",
        "        #         try:\n",
        "        #             if (idtotag[j+1] == \"O\"):\n",
        "        #                 sentiments.append(sentiment)\n",
        "        #                 #print(prep.texts[i][j],sentiment)\n",
        "        #         except:\n",
        "        #             sentiments.append(sentiment)\n",
        "        #             #print(prep.texts[i][j],sentiment)\n",
        "\n",
        "                \n",
        "        # for k,targ in enumerate(json_pred['targets']):\n",
        "        #     try:\n",
        "        #         json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],sentiments[k])\n",
        "        #     except:\n",
        "        #         print(prep.texts[i],idtotag)\n",
        "        #         json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],\"conflict\")\n",
        "        idd = 0\n",
        "        if (len(json_pred['targets'])>0):\n",
        "            for word, sentiment in zip(prep.texts[i],idtotag):\n",
        "                if word in json_pred[\"targets\"][idd][0]:\n",
        "                    if sentiment !=\"O\": \n",
        "                        json_pred[\"targets\"][idd] = (json_pred[\"targets\"][idd][0],sentiment)\n",
        "                    else:\n",
        "                        json_pred[\"targets\"][idd] = (json_pred[\"targets\"][idd][0],\"positive\") \n",
        "                    idd+=1\n",
        "                    if idd==len(json_pred[\"targets\"]):\n",
        "                        break\n",
        "        targets.append(json_pred)\n",
        "    return targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABh7UkQBDlKt"
      },
      "source": [
        "###Model AB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dn0Gw3f1zf_"
      },
      "source": [
        "class PreprocessAB():\n",
        "    def __init__(self, sentences):\n",
        "        self.texts = self.load_data(sentences)\n",
        "        self.tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
        "        self.encodings = self.tokenizer(self.texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "        \n",
        "        self.tag2id = {'O':0, 'I':1, 'B':2}\n",
        "        #self.tag2id = {tag: id for id, tag in enumerate(self.unique_tags)}\n",
        "        self.id2tag = {id: tag for tag, id in self.tag2id.items()}\n",
        "                \n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        sentences,texts = [], []\n",
        "        for obj in list_of_sentences:\n",
        "            _sentence = []\n",
        "            for t in tokenizer.tokenize(obj['text']):\n",
        "                token = {\"token\": t}\n",
        "                _sentence.append(token)\n",
        "            sentences.append(_sentence)\n",
        "\n",
        "        for elem in sentences:\n",
        "            texts.append([tok['token'] for tok in elem])\n",
        "        return texts\n",
        "    \n",
        "    \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "def predictAB(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessAB(samples)\n",
        "\n",
        "    for i,encode in tqdm(enumerate(prep.encodings['input_ids'])):\n",
        "        json_pred = {\"targets\":[]}\n",
        "        lst,pred = [],[]\n",
        "        ids = torch.unsqueeze(torch.tensor(encode),0)\n",
        "        attention_mask = torch.unsqueeze(torch.tensor(prep.encodings['attention_mask'][i]),0)\n",
        "        logits = modelAB(torch.tensor(ids).to(\"cpu\"), torch.tensor(attention_mask).cpu())[\"logits\"]\n",
        "        \n",
        "        for id in logits[0].argmax(1):\n",
        "            lst.append(id.item())\n",
        "        p = new_logits(prep.texts[i], lst,prep.tokenizer)[1:-1]\n",
        "        idtotag = [prep.id2tag[raw_pred] for raw_pred in p]\n",
        "\n",
        "        for j,word in enumerate(idtotag):\n",
        "            if word == \"B\":\n",
        "                json_pred[\"targets\"].append((prep.texts[i][j],\"positive\"))\n",
        "            elif (word == \"I\") and (idtotag[j-1] == \"B\"):\n",
        "                try:\n",
        "                    last_tuple = json_pred['targets'][-1]\n",
        "                    words_tagged = last_tuple[0] + \" \" + prep.texts[i][j]\n",
        "                    sent_tagged = last_tuple[1]\n",
        "                    json_pred['targets'][-1] = (words_tagged, sent_tagged)\n",
        "                except:\n",
        "                    words_tagged = prep.texts[i][j]\n",
        "                    sent_tagged = \"positive\"\n",
        "                    json_pred['targets'].append((words_tagged, sent_tagged))\n",
        "            elif word == \"I\":\n",
        "                json_pred[\"targets\"].append((prep.texts[i][j],\"positive\"))\n",
        "\n",
        "        targets.append(predictBAB(json_pred,prep.texts[i],prep.tokenizer,ids,attention_mask))\n",
        "\n",
        "    return targets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predictBAB(json_pred,text,tokenizer,ids,attention_mask) -> List[Dict]:\n",
        "    tag2id = {'neutral':0, 'negative':1, 'conflict':2, 'O':3,'positive':4 }\n",
        "    id2tag = {id: tag for tag, id in tag2id.items()}\n",
        "    \n",
        "    lst,pred = [],[]\n",
        "    logits = modelB(torch.tensor(ids).to(\"cpu\"), torch.tensor(attention_mask).cpu())[\"logits\"]\n",
        "    for id in logits[0].argmax(1):\n",
        "        lst.append(id.item())\n",
        "    p = new_logits(text, lst,tokenizer)[1:-1]\n",
        "    idtotag = [id2tag[raw_pred] for raw_pred in p]\n",
        "    sentiments = []\n",
        "    \n",
        "    idd = 0\n",
        "    if (len(json_pred['targets'])>0):\n",
        "        for word, sentiment in zip(text,idtotag):\n",
        "            if word in json_pred[\"targets\"][idd][0]:\n",
        "                if sentiment !=\"O\": \n",
        "                    json_pred[\"targets\"][idd] = (json_pred[\"targets\"][idd][0],sentiment)\n",
        "                else:\n",
        "                    json_pred[\"targets\"][idd] = (json_pred[\"targets\"][idd][0],\"positive\") \n",
        "                idd+=1\n",
        "                if idd==len(json_pred[\"targets\"]):\n",
        "                    break\n",
        "    \n",
        "    return json_pred\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def predict_together_AB(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessAB(samples)\n",
        "    for i,encode in tqdm(enumerate(prep.encodings['input_ids'])):\n",
        "        json_pred = {\"targets\":[]}\n",
        "        lst,pred = [],[]\n",
        "        ids = torch.unsqueeze(torch.tensor(encode),0)\n",
        "        attention_mask = torch.unsqueeze(torch.tensor(prep.encodings['attention_mask'][i]),0)\n",
        "        logits = model(torch.tensor(ids).to(\"cpu\"), torch.tensor(attention_mask).cpu())[\"logits\"]\n",
        "        \n",
        "        for id in logits[0].argmax(1):\n",
        "            lst.append(id.item())\n",
        "        p = new_logits(prep.texts[i], lst,prep.tokenizer)[1:-1]\n",
        "        #idtotag = [val_dataset.id2tag[raw_pred] for raw_pred in p]\n",
        "        idtotag = [label_vocabulary.itos[raw_pred] for raw_pred in p]\n",
        "\n",
        "\n",
        "\n",
        "        for j,word in enumerate(idtotag):\n",
        "            if word.startswith(\"B\"):\n",
        "                json_pred[\"targets\"].append((prep.texts[i][j],word.split(\"-\")[1]))\n",
        "            elif (word.startswith(\"I\")) and (idtotag[j-1].startswith(\"B\")):\n",
        "                try:\n",
        "                    last_tuple = json_pred['targets'][-1]\n",
        "                    words_tagged = last_tuple[0] + \" \" + prep.texts[i][j]\n",
        "                    sent_tagged = last_tuple[1]\n",
        "                    json_pred['targets'][-1] = (words_tagged, sent_tagged)\n",
        "                except:\n",
        "                    words_tagged = prep.texts[i][j]\n",
        "                    sent_tagged = word.split(\"-\")[1]\n",
        "                    json_pred['targets'].append((words_tagged, sent_tagged))\n",
        "            elif word == \"I\":\n",
        "                json_pred[\"targets\"].append((prep.texts[i][j],word.split(\"-\")[1]))\n",
        "\n",
        "        targets.append(predictBAB(json_pred,prep.texts[i],prep.tokenizer,ids,attention_mask))\n",
        "\n",
        "    return targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKpRzNWqTcXO"
      },
      "source": [
        "### test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nO5vf_9PXvZ_"
      },
      "source": [
        "def load_data(data_path):\n",
        "    with open(data_path) as json_file:\n",
        "        list_of_sentences = json.load(json_file)\n",
        "    return list_of_sentences\n",
        "\n",
        "\n",
        "# model_state_dictB = torch.load(root_folder+\"/model/model_b=True_f1_0.5406.pt\", map_location=torch.device(\"cpu\"))\n",
        "# modelB = DistilBertForTokenClassification.from_pretrained('distilbert-base-cased', state_dict=model_state_dictB, num_labels=5)\n",
        "# modelB.eval()\n",
        "# modelB.cpu()\n",
        "\n",
        "\n",
        "# model_state_dictAB = torch.load(root_folder+\"/model/model_b=False_f1_0.8333.pt\", map_location=torch.device(\"cpu\"))\n",
        "# modelAB = DistilBertForTokenClassification.from_pretrained('distilbert-base-cased', state_dict=model_state_dictAB, num_labels=3)\n",
        "# modelAB.eval()\n",
        "# modelAB.cpu()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpyu8rGA2BQw"
      },
      "source": [
        "a = load_data(dataset_folder+\"/laptops_dev.json\")\n",
        "a = a + load_data(dataset_folder+\"/restaurants_dev.json\")\n",
        "random.shuffle(a)\n",
        "model.cpu()\n",
        "#t = predictB(a[:30])\n",
        "t = predict_together_AB(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0tCcPim6ZQ"
      },
      "source": [
        "for gt,pred in zip(a[:40],t[:40]):\n",
        "    print(gt['targets'],\"SEP\",pred['targets'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gUCA9zb0eo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dccd9a08-9fbc-41ff-f6ae-6543e4225aee"
      },
      "source": [
        "evaluate_sentiment(a,t)\n",
        "evaluate_extraction(a,t)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aspect Sentiment Evaluation\n",
            "\n",
            "\tALL\t TP: 9;\tFP: 1219;\tFN: 1074\n",
            "\t\t(m avg): precision: 0.73;\trecall: 0.83;\tf1: 0.78 (micro)\n",
            "\t\t(M avg): precision: 0.66;\trecall: 0.67;\tf1: 0.65 (Macro)\n",
            "\n",
            "\tpositive: \tTP: 4;\tFP: 701;\tFN: 536;\tprecision: 0.57;\trecall: 0.74;\tf1: 0.64;\t705\n",
            "\tnegative: \tTP: 3;\tFP: 221;\tFN: 299;\tprecision: 1.34;\trecall: 0.99;\tf1: 1.14;\t224\n",
            "\tneutral: \tTP: 2;\tFP: 267;\tFN: 214;\tprecision: 0.74;\trecall: 0.93;\tf1: 0.82;\t269\n",
            "\tconflict: \tTP: 0;\tFP: 30;\tFN: 25;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t30\n",
            "Aspect Extraction Evaluation\n",
            "\tAspects\t TP: 42;\tFP: 1186;\tFN: 1037\n",
            "\t\tprecision: 3.42;\trecall: 3.89;\tf1: 3.64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIpUKOcg0MO6"
      },
      "source": [
        "def evaluate_sentiment(samples, predictions_b, mode=\"Aspect Sentiment\"):\n",
        "    scores = {}\n",
        "    if mode == 'Category Extraction':\n",
        "        sentiment_types = [\"anecdotes/miscellaneous\", \"price\", \"food\", \"ambience\"]\n",
        "    else:\n",
        "        sentiment_types = [\"positive\", \"negative\", \"neutral\", \"conflict\"]\n",
        "    scores = {sent: {\"tp\": 0, \"fp\": 0, \"fn\": 0} for sent in sentiment_types + [\"ALL\"]}\n",
        "    for label, pred in zip(samples, predictions_b):\n",
        "        for sentiment in sentiment_types:\n",
        "            if mode == \"Aspect Sentiment\":\n",
        "                pred_sent = {(term_pred[0], term_pred[1]) for term_pred in pred[\"targets\"] if\n",
        "                                    term_pred[1] == sentiment}\n",
        "                gt_sent = {(term_pred[1], term_pred[2]) for term_pred in label[\"targets\"] if\n",
        "                                    term_pred[2] == sentiment}\n",
        "            elif mode == 'Category Extraction' and \"categories\" in label:\n",
        "                pred_sent = {(term_pred[0]) for term_pred in pred[\"categories\"] if\n",
        "                                term_pred[0] == sentiment}\n",
        "                gt_sent = {(term_pred[0]) for term_pred in label[\"categories\"] if\n",
        "                                term_pred[0] == sentiment}\n",
        "            elif \"categories\" in label:\n",
        "                pred_sent = {(term_pred[0], term_pred[1]) for term_pred in pred[\"categories\"] if\n",
        "                                term_pred[1] == sentiment}\n",
        "                gt_sent = {(term_pred[0], term_pred[1]) for term_pred in label[\"categories\"] if\n",
        "                                term_pred[1] == sentiment}\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            scores[sentiment][\"tp\"] += len(pred_sent & gt_sent)\n",
        "            scores[sentiment][\"fp\"] += len(pred_sent - gt_sent)\n",
        "            scores[sentiment][\"fn\"] += len(gt_sent - pred_sent)\n",
        "\n",
        "    # Compute per sentiment Precision / Recall / F1\n",
        "    for sent_type in scores.keys():\n",
        "        if scores[sent_type][\"tp\"]:\n",
        "            scores[sent_type][\"p\"] = 100 * scores[sent_type][\"tp\"] / (scores[sent_type][\"fp\"] + scores[sent_type][\"tp\"])\n",
        "            scores[sent_type][\"r\"] = 100 * scores[sent_type][\"tp\"] / (scores[sent_type][\"fn\"] + scores[sent_type][\"tp\"])\n",
        "        else:\n",
        "            scores[sent_type][\"p\"], scores[sent_type][\"r\"] = 0, 0\n",
        "\n",
        "        if not scores[sent_type][\"p\"] + scores[sent_type][\"r\"] == 0:\n",
        "            scores[sent_type][\"f1\"] = 2 * scores[sent_type][\"p\"] * scores[sent_type][\"r\"] / (\n",
        "                    scores[sent_type][\"p\"] + scores[sent_type][\"r\"])\n",
        "        else:\n",
        "            scores[sent_type][\"f1\"] = 0\n",
        "\n",
        "    # Compute micro F1 Scores\n",
        "    tp = sum([scores[sent_type][\"tp\"] for sent_type in sentiment_types])\n",
        "    fp = sum([scores[sent_type][\"fp\"] for sent_type in sentiment_types])\n",
        "    fn = sum([scores[sent_type][\"fn\"] for sent_type in sentiment_types])\n",
        "\n",
        "    if tp:\n",
        "        precision = 100 * tp / (tp + fp)\n",
        "        recall = 100 * tp / (tp + fn)\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    else:\n",
        "        precision, recall, f1 = 0, 0, 0\n",
        "\n",
        "    scores[\"ALL\"][\"p\"] = precision\n",
        "    scores[\"ALL\"][\"r\"] = recall\n",
        "    scores[\"ALL\"][\"f1\"] = f1\n",
        "    scores[\"ALL\"][\"tp\"] = tp\n",
        "    scores[\"ALL\"][\"fp\"] = fp\n",
        "    scores[\"ALL\"][\"fn\"] = fn\n",
        "\n",
        "    # Compute Macro F1 Scores\n",
        "    scores[\"ALL\"][\"Macro_f1\"] = sum([scores[ent_type][\"f1\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "    scores[\"ALL\"][\"Macro_p\"] = sum([scores[ent_type][\"p\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "    scores[\"ALL\"][\"Macro_r\"] = sum([scores[ent_type][\"r\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "\n",
        "    print(f\"{mode} Evaluation\\n\")\n",
        "\n",
        "    print(\n",
        "        \"\\tALL\\t TP: {};\\tFP: {};\\tFN: {}\".format(\n",
        "            scores[\"ALL\"][\"tp\"],\n",
        "            scores[\"ALL\"][\"fp\"],\n",
        "            scores[\"ALL\"][\"fn\"]))\n",
        "    print(\n",
        "        \"\\t\\t(m avg): precision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f} (micro)\".format(\n",
        "            precision,\n",
        "            recall,\n",
        "            f1))\n",
        "    print(\n",
        "        \"\\t\\t(M avg): precision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f} (Macro)\\n\".format(\n",
        "            scores[\"ALL\"][\"Macro_p\"],\n",
        "            scores[\"ALL\"][\"Macro_r\"],\n",
        "            scores[\"ALL\"][\"Macro_f1\"]))\n",
        "\n",
        "    for sent_type in sentiment_types:\n",
        "        print(\"\\t{}: \\tTP: {};\\tFP: {};\\tFN: {};\\tprecision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f};\\t{}\".format(\n",
        "            sent_type,\n",
        "            scores[sent_type][\"tp\"],\n",
        "            scores[sent_type][\"fp\"],\n",
        "            scores[sent_type][\"fn\"],\n",
        "            scores[sent_type][\"p\"],\n",
        "            scores[sent_type][\"r\"],\n",
        "            scores[sent_type][\"f1\"],\n",
        "            scores[sent_type][\"tp\"] +\n",
        "            scores[sent_type][\n",
        "                \"fp\"]))\n",
        "\n",
        "def evaluate_extraction(samples, predictions_b):\n",
        "    scores = {\"tp\": 0, \"fp\": 0, \"fn\": 0}\n",
        "    for label, pred in zip (samples, predictions_b):\n",
        "        pred_terms = {term_pred[0] for term_pred in pred[\"targets\"]}\n",
        "        gt_terms = {term_gt[1] for term_gt in label[\"targets\"]}\n",
        "\n",
        "        scores[\"tp\"] += len(pred_terms & gt_terms)\n",
        "        scores[\"fp\"] += len(pred_terms - gt_terms)\n",
        "        scores[\"fn\"] += len(gt_terms - pred_terms)\n",
        "\n",
        "    precision = 100 * scores[\"tp\"] / (scores[\"tp\"] + scores[\"fp\"])\n",
        "    recall = 100 * scores[\"tp\"] / (scores[\"tp\"] + scores[\"fn\"])\n",
        "    f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    print(f\"Aspect Extraction Evaluation\")\n",
        "\n",
        "    print(\n",
        "        \"\\tAspects\\t TP: {};\\tFP: {};\\tFN: {}\".format(\n",
        "            scores[\"tp\"],\n",
        "            scores[\"fp\"],\n",
        "            scores[\"fn\"]))\n",
        "    print(\n",
        "        \"\\t\\tprecision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f}\".format(\n",
        "            precision,\n",
        "            recall,\n",
        "            f1))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFGbrVy9YX7R"
      },
      "source": [
        "# TASK C-D (DistillBERT fine tuning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW7JmyGUXmJu"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr9hcu_PbOSF"
      },
      "source": [
        "class TaskCDDataset (Dataset):\n",
        "    def __init__(self,path, tokenizer, max_len,model_b):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model_b = model_b\n",
        "\n",
        "        self.texts, self.tags = self.load_data(path)\n",
        "        self.mlb = MultiLabelBinarizer()\n",
        "        self.encode_tags()\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def encode_tags(self):\n",
        "        self.tags = self.mlb.fit_transform(self.tags)\n",
        "\n",
        "    def decode_tag(self,tag):\n",
        "        return self.mlb.inverse_transform(tag.reshape(1,-1))\n",
        "\n",
        "    def load_data(self,datapath):\n",
        "        sentences = []     \n",
        "        texts = []\n",
        "        tags = []\n",
        "        with open(datapath) as json_file:\n",
        "            list_of_sentences = json.load(json_file)\n",
        "            for obj in list_of_sentences:\n",
        "                texts.append(obj['text'])\n",
        "                if self.model_b:\n",
        "                    tags.append([cat[0]+\"-\"+cat[1] for cat in obj['categories']])\n",
        "                else:\n",
        "                    tags.append([cat[0] for cat in obj['categories']])\n",
        "\n",
        "                \n",
        "        return texts, tags  \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, item_idx):\n",
        "        text = self.texts[item_idx]\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True, # Add [CLS] [SEP]\n",
        "            max_length= self.max_len,\n",
        "            padding = 'max_length',\n",
        "            return_token_type_ids= False,\n",
        "            return_attention_mask= True, \n",
        "            truncation=True,\n",
        "            return_tensors = 'pt'\n",
        "          )\n",
        "        \n",
        "        input_ids = inputs['input_ids'].flatten()\n",
        "        attn_mask = inputs['attention_mask'].flatten()\n",
        "        \n",
        "        return {\n",
        "            'input_ids': input_ids ,\n",
        "            'attention_mask': attn_mask,\n",
        "            'label': torch.tensor(self.tags[item_idx], dtype=torch.float)\n",
        "        }\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLM-mkSobQwc"
      },
      "source": [
        "class TaskCDDataModule (pl.LightningDataModule):\n",
        "    \n",
        "    def __init__(self,training_file, dev_file, tokenizer,batch_size=16,max_token_len=200):\n",
        "        super().__init__()\n",
        "        self.training_file = training_file\n",
        "        self.dev_file = dev_file\n",
        "        \n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "        self.max_token_len = max_token_len\n",
        "\n",
        "    def setup(self):\n",
        "        self.train_dataset = TaskCDDataset(self.training_file, tokenizer=self.tokenizer,max_len = self.max_token_len,model_b=model_b)\n",
        "        self.val_dataset  = TaskCDDataset(self.dev_file, tokenizer=self.tokenizer,max_len = self.max_token_len,model_b=model_b)\n",
        "           \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset,batch_size = self.batch_size,shuffle = True , num_workers=2)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset,batch_size= 16)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilD0LTOxXp1x"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-72hvEzANOvf"
      },
      "source": [
        "Set up the classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkTK8rJocqxC"
      },
      "source": [
        "class TaskCDClassifier(pl.LightningModule):\n",
        "    def __init__(self, n_classes=5, steps_per_epoch=None, n_epochs=3, lr=2e-5,device=\"cuda\" ):\n",
        "        super().__init__()\n",
        "        self.bert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased',num_labels=n_classes)\n",
        "        #self.classifier = nn.Linear(self.bert.config.hidden_size,n_classes) # outputs = number of labels\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        self.n_epochs = n_epochs\n",
        "        self.lr = lr\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.to(device)\n",
        "    \n",
        "    def forward(self,input_ids, attn_mask):\n",
        "        output = self.bert(input_ids = input_ids ,attention_mask = attn_mask)\n",
        "        #pooler output --> Last layer hidden-state of the first token of the sequence (classification token) further processed \n",
        "        #by a Linear layer and a Tanh activation function. The Linear layer weights are trained from the next \n",
        "        #sentence prediction (classification) objective during pretraining.\n",
        "        #output = self.classifier(output.pooler_output)\n",
        "        output = output['logits']        \n",
        "        return output\n",
        "    \n",
        "    \n",
        "    def training_step(self,batch,batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['label']\n",
        "        \n",
        "        outputs = self(input_ids,attention_mask)\n",
        "        loss = self.criterion(outputs,labels)\n",
        "        self.log('train_loss',loss , prog_bar=True,logger=True)\n",
        "        \n",
        "        return {\"loss\" :loss, \"predictions\":outputs, \"labels\": labels }\n",
        "\n",
        "\n",
        "    def validation_step(self,batch,batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['label']\n",
        "        \n",
        "        outputs = self(input_ids,attention_mask)\n",
        "        loss = self.criterion(outputs,labels)\n",
        "        self.log('val_loss',loss , prog_bar=True,logger=True)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters() , lr=self.lr)\n",
        "        return optimizer\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3FpYR3RNf_L"
      },
      "source": [
        "Initialize the parameters that will be use for training\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fXn-TfKcdNo"
      },
      "source": [
        "bert_tokenizer=DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
        "N_EPOCHS = 3\n",
        "BATCH_SIZE = 32\n",
        "MAX_LEN = 100\n",
        "LR = 2e-05"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCLqAz22UG7q"
      },
      "source": [
        "Instantiate and set up the data_module\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AggiQVrcgr5"
      },
      "source": [
        "TaskCD_data_module = TaskCDDataModule(\n",
        "    dataset_folder+\"/restaurants_train.json\",\n",
        "    dataset_folder+\"/restaurants_dev.json\",\n",
        "    bert_tokenizer,\n",
        "    BATCH_SIZE,\n",
        "    MAX_LEN\n",
        "    )\n",
        "TaskCD_data_module.setup()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HRpWKBYVkuz"
      },
      "source": [
        "Instantiate the classifier model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvv6Au-icsVm",
        "outputId": "3551f8d7-e435-483c-874d-98532428e5e4"
      },
      "source": [
        "train_d = TaskCD_data_module.train_dataset\n",
        "steps_per_epoch = len(train_d.texts)//BATCH_SIZE\n",
        "from transformers import DistilBertForSequenceClassification\n",
        "model = TaskCDClassifier(n_classes=train_d.tags.shape[1], steps_per_epoch=steps_per_epoch,n_epochs=N_EPOCHS,lr=LR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjiaWac8X1rL"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WurD2_IQXFU9"
      },
      "source": [
        "Instantiate the Model Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY53knvdGoA"
      },
      "source": [
        "trainer = pl.Trainer(max_epochs = N_EPOCHS , gpus = 1,progress_bar_refresh_rate = 10)\n",
        "model.parameters\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxD3MwFwXHmo"
      },
      "source": [
        "Train the Classifier Model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285,
          "referenced_widgets": [
            "682d231fd2ac457cbd91075bf097cdd6",
            "4fb98503a1284e0a8e7dc5ba739b0c5f",
            "561cf0f183714a6a98adfc87f6fe7ad8",
            "6b9d83fb359c4687adf6bf14a7ad4938",
            "5ba0d42dc42a4b868c6c0c050610596c",
            "a8ab4af71149418b9935de1af76d7c2f",
            "8fbf6108dda04800bb7c922552a0c06f",
            "6e742a4dbbab472296cc3e18c9cb1caa",
            "6639cf669b91431ba7e65b4e21a7e05d",
            "630c24c32c8b434a91abf8952c750e38",
            "688d29acd1fe4d0fb55162ae0003ae66",
            "1aa4fc94c24d45ff95e393b06cf275e2",
            "f9831b7785da4105ac75673904561cc7",
            "3659c9aafa834ebc8f4dce423fe05ac0",
            "dbe15891353b4ac3a00900c0a40d4d17",
            "91c0d02b549649a5914e14f1eadfb831",
            "975c81bedb094f2ba91fdb1fa0b59910",
            "f3a96835683944fca8d36fc2a27a241c",
            "5b0f2dc7d2f44d0fb1df9a9fce900020",
            "85d821827b094fbbb0136d7473ff0fbc",
            "08b486b1d68c4d339a696274dd614a78",
            "60fed79d68f54041b4a9b54d822fbb31",
            "3d1730504e3645a088685c8e35f6f34d",
            "54ece2437df546ac85038009c2a63f42",
            "9790a66e88a14e83b8a40f59175c9e64",
            "97374d53cba44b628ec24fb1d7ac2a4b",
            "bcfb1277c63144198533777ecee7efac",
            "4f9a12829b5a48a8ae8eb1f15d64010a",
            "a71d6ceade7a464481f9318e6ec66477",
            "b4732df9c5454e67b07f1c98bb233283",
            "e918cd0899dc43b9b2be95babe02627e",
            "3b55de595d324fa6ab7aa0e841ec4b3a",
            "0415aed3e61d4644af2266d8bbc3a6a6",
            "0f1da48a6aec4e468fc1ee436f2820f2",
            "f45eff8183f74537b8e7de052f37ac28",
            "c8d73fa3b8e847d099dc6d3e3c9ea75b",
            "5fcda640ec724cfca83399605978142c",
            "22961161f6744ed1803f495773672b96",
            "3a7b59ed13104aabb0359273d9af802d",
            "de74826bd170494683392a915a4924f5"
          ]
        },
        "id": "izy9dwfBdOW_",
        "outputId": "6a15bd68-c840-4554-c741-9b2bbb7e993e"
      },
      "source": [
        "trainer.fit(model, TaskCD_data_module)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type                                | Params\n",
            "------------------------------------------------------------------\n",
            "0 | bert      | DistilBertForSequenceClassification | 65.8 M\n",
            "1 | criterion | BCEWithLogitsLoss                   | 0     \n",
            "------------------------------------------------------------------\n",
            "65.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "65.8 M    Total params\n",
            "263.188   Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "682d231fd2ac457cbd91075bf097cdd6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6639cf669b91431ba7e65b4e21a7e05d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "975c81bedb094f2ba91fdb1fa0b59910",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9790a66e88a14e83b8a40f59175c9e64",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0415aed3e61d4644af2266d8bbc3a6a6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNOOSb92X31J"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvffKboBbJ2E"
      },
      "source": [
        "pred_outs, true_labels = [], []\n",
        "model.cuda()\n",
        "for batch in TaskCD_data_module.val_dataloader():\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids = batch[\"input_ids\"].cuda()\n",
        "    b_attn_mask = batch[\"attention_mask\"].cuda()\n",
        "    b_labels = batch[\"label\"].cuda()\n",
        "    \n",
        "    #print(b_input_ids)\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions\n",
        "        pred_out = model(b_input_ids,b_attn_mask)\n",
        "        pred_out = torch.sigmoid(pred_out)\n",
        "        # Move predicted output and labels to CPU\n",
        "        \n",
        "        pred_out = pred_out.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    pred_outs.append(pred_out)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "flat_pred_outs = np.concatenate(pred_outs, axis=0)\n",
        "\n",
        "# Combine the correct labels for each batch into a single list.\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VWpPZmxf8zy"
      },
      "source": [
        "convert probabilities into 0 or 1 based on a threshold value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E1Ap_QVFfbTx",
        "outputId": "ccb21a53-3f23-446a-85cd-303a3146ee52"
      },
      "source": [
        "threshold  = np.arange(0.2,0.51,0.01)\n",
        "\n",
        "# convert probabilities into 0 or 1 based on a threshold value\n",
        "def classify(pred_prob,thresh):\n",
        "    y_pred = []\n",
        "\n",
        "    for tag_label_row in pred_prob:\n",
        "        temp=[]\n",
        "        for tag_label in tag_label_row:\n",
        "            if tag_label >= thresh:\n",
        "                temp.append(1) # Infer tag value as 1 (present)\n",
        "            else:\n",
        "                temp.append(0) # Infer tag value as 0 (absent)\n",
        "        y_pred.append(temp)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "scores=[] # Store the list of f1 scores for prediction on each threshold\n",
        "\n",
        "#convert labels to 1D array\n",
        "y_true = flat_true_labels.ravel() \n",
        "\n",
        "for thresh in threshold:\n",
        "    \n",
        "    #classes for each threshold\n",
        "    pred_bin_label = classify(flat_pred_outs,thresh) \n",
        "\n",
        "    #convert to 1D array\n",
        "    y_pred = np.array(pred_bin_label).ravel()\n",
        "\n",
        "    scores.append(f1_score(y_true,y_pred))\n",
        "\n",
        "# find the optimal threshold\n",
        "opt_thresh = threshold[scores.index(max(scores))]\n",
        "print(f'Optimal Threshold Value = {opt_thresh}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Optimal Threshold Value = 0.23000000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CrC_H3DVfU0N",
        "outputId": "eba885a7-5ae5-41d5-edd8-53c7f4dc7af3"
      },
      "source": [
        "#predictions for optimal threshold\n",
        "y_pred_labels = classify(flat_pred_outs,opt_thresh)\n",
        "\n",
        "print(y_pred_labels)\n",
        "y_pred = np.array(y_pred_labels).ravel() # Flatten\n",
        "\n",
        "metr = {}\n",
        "metr['f1'] = f1_score(y_true,y_pred, average=\"macro\")\n",
        "\n",
        "print(metr['f1'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
            "0.7455841667791916\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UdQso0-TOwW"
      },
      "source": [
        "import pandas as pd\n",
        "y_pred = TaskCD_data_module.val_dataset.mlb.inverse_transform(np.array(y_pred_labels))\n",
        "y_act = TaskCD_data_module.val_dataset.mlb.inverse_transform(flat_true_labels)\n",
        "\n",
        "\n",
        "df = pd.DataFrame({'Body':TaskCD_data_module.val_dataset.texts,'Actual Tags':y_act,'Predicted Tags':y_pred})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LlBy4rhPTVRb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "outputId": "f92700a3-2512-47ba-817e-52e86e1b6ede"
      },
      "source": [
        "pd.set_option('display.max_rows', 500)\n",
        "df.sample(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Body</th>\n",
              "      <th>Actual Tags</th>\n",
              "      <th>Predicted Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Good food at the restaurant (a bit expensive, ...</td>\n",
              "      <td>(food-positive, price-negative)</td>\n",
              "      <td>(food-positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>But don't ever order bacon late at nite (eithe...</td>\n",
              "      <td>(food-negative,)</td>\n",
              "      <td>(food-negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>I'm still mad that i had to pay for lousy food.</td>\n",
              "      <td>(food-negative,)</td>\n",
              "      <td>(food-negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>Restaurant was dirty and unkempt.</td>\n",
              "      <td>(ambience-negative,)</td>\n",
              "      <td>(service-negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>There are many Thai places in the city but so ...</td>\n",
              "      <td>(anecdotes/miscellaneous-positive,)</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>Been there, done that, and New York, it's not ...</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral,)</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>In fact, two people could really share one plate.</td>\n",
              "      <td>(food-positive,)</td>\n",
              "      <td>()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>444</th>\n",
              "      <td>The food is very good for it's price, better t...</td>\n",
              "      <td>(food-positive, price-positive)</td>\n",
              "      <td>(food-positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>We visit at least once a month.</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral,)</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral, anecdotes/mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>Others have to go to other restaurants and fee...</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral,)</td>\n",
              "      <td>()</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  Body  ...                                     Predicted Tags\n",
              "20   Good food at the restaurant (a bit expensive, ...  ...                                   (food-positive,)\n",
              "447  But don't ever order bacon late at nite (eithe...  ...                                   (food-negative,)\n",
              "456    I'm still mad that i had to pay for lousy food.  ...                                   (food-negative,)\n",
              "528                  Restaurant was dirty and unkempt.  ...                                (service-negative,)\n",
              "335  There are many Thai places in the city but so ...  ...                 (anecdotes/miscellaneous-neutral,)\n",
              "224  Been there, done that, and New York, it's not ...  ...                 (anecdotes/miscellaneous-neutral,)\n",
              "21   In fact, two people could really share one plate.  ...                                                 ()\n",
              "444  The food is very good for it's price, better t...  ...                                   (food-positive,)\n",
              "154                    We visit at least once a month.  ...  (anecdotes/miscellaneous-neutral, anecdotes/mi...\n",
              "268  Others have to go to other restaurants and fee...  ...                                                 ()\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8prLjGUxwkh",
        "outputId": "49b8e0f0-8fc3-4577-a846-7cea25107852"
      },
      "source": [
        "TaskCD_data_module.val_dataset.mlb.classes_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ambience-conflict', 'ambience-negative', 'ambience-neutral',\n",
              "       'ambience-positive', 'anecdotes/miscellaneous-conflict',\n",
              "       'anecdotes/miscellaneous-negative',\n",
              "       'anecdotes/miscellaneous-neutral',\n",
              "       'anecdotes/miscellaneous-positive', 'food-conflict',\n",
              "       'food-negative', 'food-neutral', 'food-positive', 'price-conflict',\n",
              "       'price-negative', 'price-neutral', 'price-positive',\n",
              "       'service-conflict', 'service-negative', 'service-neutral',\n",
              "       'service-positive'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIZcJMYGAibp"
      },
      "source": [
        "torch.save(model.state_dict(), root_folder+'/model/TASKCD_model_b={}_f1_{:0.4f}.pt'.format(str(model_b), metr[\"f1\"])) # save the model state"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOQl4xWw9kU9"
      },
      "source": [
        "## docker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cPk37qN_XNv"
      },
      "source": [
        "def load_data(data_path):\n",
        "    with open(data_path) as json_file:\n",
        "        list_of_sentences = json.load(json_file)\n",
        "    return list_of_sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IIf9100usmW9",
        "outputId": "fe0f1d32-aaa8-40e0-d156-10caa139b950"
      },
      "source": [
        "class PreprocessCD():\n",
        "    def __init__(self, sentences):\n",
        "        self.texts, self.tags = self.load_data(sentences)\n",
        "        self.tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
        "        self.max_len = 200\n",
        "        self.mlb = MultiLabelBinarizer()\n",
        "        self.mlb.fit_transform([['ambience-conflict', 'ambience-negative', 'ambience-neutral',\n",
        "       'ambience-positive', 'anecdotes/miscellaneous-conflict',\n",
        "       'anecdotes/miscellaneous-negative',\n",
        "       'anecdotes/miscellaneous-neutral',\n",
        "       'anecdotes/miscellaneous-positive', 'food-conflict',\n",
        "       'food-negative', 'food-neutral', 'food-positive', 'price-conflict',\n",
        "       'price-negative', 'price-neutral', 'price-positive',\n",
        "       'service-conflict', 'service-negative', 'service-neutral',\n",
        "       'service-positive']])\n",
        "        self.encodings = self.encode_texts()\n",
        "        \n",
        "    def encode_texts(self):\n",
        "        encodings = []\n",
        "        for item_idx,text in enumerate(self.texts):\n",
        "            inputs = self.tokenizer.encode_plus(\n",
        "                text,\n",
        "                None,\n",
        "                add_special_tokens=True, # Add [CLS] [SEP]\n",
        "                max_length= self.max_len,\n",
        "                padding = 'max_length',\n",
        "                return_token_type_ids= False,\n",
        "                return_attention_mask= True, # Differentiates padded vs normal token\n",
        "                truncation=True, # Truncate data beyond max length\n",
        "                return_tensors = 'pt' # PyTorch Tensor format\n",
        "            )\n",
        "            \n",
        "            input_ids = inputs['input_ids'].flatten()\n",
        "            attn_mask = inputs['attention_mask'].flatten()\n",
        "            \n",
        "            encodings.append({\n",
        "                'input_ids': input_ids ,\n",
        "                'attention_mask': attn_mask,\n",
        "            })\n",
        "        return encodings\n",
        "        \n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        texts = []\n",
        "        tags = []\n",
        "\n",
        "        for obj in list_of_sentences:\n",
        "            texts.append(obj['text'])            \n",
        "        return texts, tags  \n",
        "    \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "def classify(pred_prob,thresh):\n",
        "    y_pred = []\n",
        "\n",
        "    for tag_label_row in pred_prob:\n",
        "        temp=[]\n",
        "        for tag_label in tag_label_row:\n",
        "            if tag_label >= thresh:\n",
        "                temp.append(1) # Infer tag value as 1 (present)\n",
        "            else:\n",
        "                temp.append(0) # Infer tag value as 0 (absent)\n",
        "        y_pred.append(temp)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "def predictCD(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessCD(samples)\n",
        "    model.eval()\n",
        "    model.cpu()\n",
        "    for i,batch in enumerate(prep.encodings):\n",
        "\n",
        "        json_pred = {\"targets\":[], \"categories\": []}\n",
        "        b_input_ids = batch[\"input_ids\"]\n",
        "        b_attn_mask = batch[\"attention_mask\"]\n",
        "        \n",
        "        ids = torch.unsqueeze(torch.tensor(b_input_ids),0).cpu()\n",
        "        attmasks = torch.unsqueeze(torch.tensor(b_attn_mask),0).cpu()\n",
        "        # Forward pass, calculate logit predictions\n",
        "        pred_out = model(ids,attmasks)\n",
        "        pred_out = torch.sigmoid(pred_out)\n",
        "        \n",
        "        pred_out = pred_out.detach().cpu().numpy()\n",
        "\n",
        "        y_pred_labels = classify(pred_out,0.23)\n",
        "        \n",
        "        y_pred = prep.mlb.inverse_transform(np.array(y_pred_labels))\n",
        "        for pred in y_pred:\n",
        "            try:\n",
        "                asd = pred[0].split(\"-\")\n",
        "                json_pred[\"categories\"].append((asd[0],asd[1]))\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        targets.append(json_pred)\n",
        "    \n",
        "    return targets\n",
        "\n",
        "            \n",
        "a = load_data(dataset_folder+\"/restaurants_dev.json\")\n",
        "random.shuffle(a)\n",
        "t = predictCD(a)\n",
        "\n",
        "for obj,o in zip(a[:30],t):\n",
        "    print(obj[\"categories\"],\"SEP\",o[\"categories\"])\n",
        "# print(t['categories'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:84: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:85: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[['service', 'conflict']] SEP [('service', 'negative')]\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP [('anecdotes/miscellaneous', 'positive')]\n",
            "[['food', 'conflict']] SEP [('food', 'positive')]\n",
            "[['food', 'positive'], ['service', 'positive']] SEP []\n",
            "[['food', 'positive'], ['ambience', 'positive']] SEP [('food', 'positive')]\n",
            "[['anecdotes/miscellaneous', 'neutral']] SEP []\n",
            "[['service', 'conflict']] SEP [('service', 'negative')]\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP [('anecdotes/miscellaneous', 'positive')]\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP [('anecdotes/miscellaneous', 'neutral')]\n",
            "[['service', 'negative'], ['anecdotes/miscellaneous', 'negative']] SEP [('food', 'negative')]\n",
            "[['service', 'negative']] SEP []\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP [('food', 'positive')]\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP []\n",
            "[['food', 'positive'], ['service', 'negative']] SEP [('food', 'negative')]\n",
            "[['food', 'positive'], ['ambience', 'positive']] SEP [('food', 'positive')]\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP [('anecdotes/miscellaneous', 'positive')]\n",
            "[['ambience', 'neutral']] SEP []\n",
            "[['food', 'positive']] SEP [('food', 'positive')]\n",
            "[['anecdotes/miscellaneous', 'neutral'], ['price', 'negative']] SEP []\n",
            "[['food', 'positive']] SEP [('food', 'positive')]\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP [('anecdotes/miscellaneous', 'positive')]\n",
            "[['ambience', 'positive']] SEP [('anecdotes/miscellaneous', 'positive')]\n",
            "[['service', 'positive']] SEP [('service', 'positive')]\n",
            "[['food', 'positive']] SEP [('food', 'positive')]\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP [('food', 'positive')]\n",
            "[['service', 'positive']] SEP [('service', 'negative')]\n",
            "[['food', 'negative'], ['price', 'negative']] SEP []\n",
            "[['anecdotes/miscellaneous', 'neutral']] SEP [('anecdotes/miscellaneous', 'positive')]\n",
            "[['food', 'positive']] SEP [('anecdotes/miscellaneous', 'positive')]\n",
            "[['food', 'positive']] SEP [('food', 'positive')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JTrvz4d_yZD",
        "outputId": "73770091-dd9b-4931-f182-8e20e7c584fa"
      },
      "source": [
        "evaluate_sentiment(a,t,mode=\"Category Extraction\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Category Extraction Evaluation\n",
            "\n",
            "\tALL\t TP: 313;\tFP: 54;\tFN: 231\n",
            "\t\t(m avg): precision: 85.29;\trecall: 57.54;\tf1: 68.72 (micro)\n",
            "\t\t(M avg): precision: 60.97;\trecall: 40.25;\tf1: 46.18 (Macro)\n",
            "\n",
            "\tanecdotes/miscellaneous: \tTP: 118;\tFP: 13;\tFN: 73;\tprecision: 90.08;\trecall: 61.78;\tf1: 73.29;\t131\n",
            "\tprice: \tTP: 0;\tFP: 0;\tFN: 53;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
            "\tfood: \tTP: 181;\tFP: 35;\tFN: 43;\tprecision: 83.80;\trecall: 80.80;\tf1: 82.27;\t216\n",
            "\tambience: \tTP: 14;\tFP: 6;\tFN: 62;\tprecision: 70.00;\trecall: 18.42;\tf1: 29.17;\t20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mAdtLPo_xVn"
      },
      "source": [
        "def evaluate_sentiment(samples, predictions_b, mode=\"Aspect Sentiment\"):\n",
        "    scores = {}\n",
        "    if mode == 'Category Extraction':\n",
        "        sentiment_types = [\"anecdotes/miscellaneous\", \"price\", \"food\", \"ambience\"]\n",
        "    else:\n",
        "        sentiment_types = [\"positive\", \"negative\", \"neutral\", \"conflict\"]\n",
        "    scores = {sent: {\"tp\": 0, \"fp\": 0, \"fn\": 0} for sent in sentiment_types + [\"ALL\"]}\n",
        "    for label, pred in zip(samples, predictions_b):\n",
        "        for sentiment in sentiment_types:\n",
        "            if mode == \"Aspect Sentiment\":\n",
        "                pred_sent = {(term_pred[0], term_pred[1]) for term_pred in pred[\"targets\"] if\n",
        "                                    term_pred[1] == sentiment}\n",
        "                gt_sent = {(term_pred[1], term_pred[2]) for term_pred in label[\"targets\"] if\n",
        "                                    term_pred[2] == sentiment}\n",
        "            elif mode == 'Category Extraction' and \"categories\" in label:\n",
        "                pred_sent = {(term_pred[0]) for term_pred in pred[\"categories\"] if\n",
        "                                term_pred[0] == sentiment}\n",
        "                gt_sent = {(term_pred[0]) for term_pred in label[\"categories\"] if\n",
        "                                term_pred[0] == sentiment}\n",
        "            elif \"categories\" in label:\n",
        "                pred_sent = {(term_pred[0], term_pred[1]) for term_pred in pred[\"categories\"] if\n",
        "                                term_pred[1] == sentiment}\n",
        "                gt_sent = {(term_pred[0], term_pred[1]) for term_pred in label[\"categories\"] if\n",
        "                                term_pred[1] == sentiment}\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            scores[sentiment][\"tp\"] += len(pred_sent & gt_sent)\n",
        "            scores[sentiment][\"fp\"] += len(pred_sent - gt_sent)\n",
        "            scores[sentiment][\"fn\"] += len(gt_sent - pred_sent)\n",
        "\n",
        "    # Compute per sentiment Precision / Recall / F1\n",
        "    for sent_type in scores.keys():\n",
        "        if scores[sent_type][\"tp\"]:\n",
        "            scores[sent_type][\"p\"] = 100 * scores[sent_type][\"tp\"] / (scores[sent_type][\"fp\"] + scores[sent_type][\"tp\"])\n",
        "            scores[sent_type][\"r\"] = 100 * scores[sent_type][\"tp\"] / (scores[sent_type][\"fn\"] + scores[sent_type][\"tp\"])\n",
        "        else:\n",
        "            scores[sent_type][\"p\"], scores[sent_type][\"r\"] = 0, 0\n",
        "\n",
        "        if not scores[sent_type][\"p\"] + scores[sent_type][\"r\"] == 0:\n",
        "            scores[sent_type][\"f1\"] = 2 * scores[sent_type][\"p\"] * scores[sent_type][\"r\"] / (\n",
        "                    scores[sent_type][\"p\"] + scores[sent_type][\"r\"])\n",
        "        else:\n",
        "            scores[sent_type][\"f1\"] = 0\n",
        "\n",
        "    # Compute micro F1 Scores\n",
        "    tp = sum([scores[sent_type][\"tp\"] for sent_type in sentiment_types])\n",
        "    fp = sum([scores[sent_type][\"fp\"] for sent_type in sentiment_types])\n",
        "    fn = sum([scores[sent_type][\"fn\"] for sent_type in sentiment_types])\n",
        "\n",
        "    if tp:\n",
        "        precision = 100 * tp / (tp + fp)\n",
        "        recall = 100 * tp / (tp + fn)\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    else:\n",
        "        precision, recall, f1 = 0, 0, 0\n",
        "\n",
        "    scores[\"ALL\"][\"p\"] = precision\n",
        "    scores[\"ALL\"][\"r\"] = recall\n",
        "    scores[\"ALL\"][\"f1\"] = f1\n",
        "    scores[\"ALL\"][\"tp\"] = tp\n",
        "    scores[\"ALL\"][\"fp\"] = fp\n",
        "    scores[\"ALL\"][\"fn\"] = fn\n",
        "\n",
        "    # Compute Macro F1 Scores\n",
        "    scores[\"ALL\"][\"Macro_f1\"] = sum([scores[ent_type][\"f1\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "    scores[\"ALL\"][\"Macro_p\"] = sum([scores[ent_type][\"p\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "    scores[\"ALL\"][\"Macro_r\"] = sum([scores[ent_type][\"r\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "\n",
        "    print(f\"{mode} Evaluation\\n\")\n",
        "\n",
        "    print(\n",
        "        \"\\tALL\\t TP: {};\\tFP: {};\\tFN: {}\".format(\n",
        "            scores[\"ALL\"][\"tp\"],\n",
        "            scores[\"ALL\"][\"fp\"],\n",
        "            scores[\"ALL\"][\"fn\"]))\n",
        "    print(\n",
        "        \"\\t\\t(m avg): precision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f} (micro)\".format(\n",
        "            precision,\n",
        "            recall,\n",
        "            f1))\n",
        "    print(\n",
        "        \"\\t\\t(M avg): precision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f} (Macro)\\n\".format(\n",
        "            scores[\"ALL\"][\"Macro_p\"],\n",
        "            scores[\"ALL\"][\"Macro_r\"],\n",
        "            scores[\"ALL\"][\"Macro_f1\"]))\n",
        "\n",
        "    for sent_type in sentiment_types:\n",
        "        print(\"\\t{}: \\tTP: {};\\tFP: {};\\tFN: {};\\tprecision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f};\\t{}\".format(\n",
        "            sent_type,\n",
        "            scores[sent_type][\"tp\"],\n",
        "            scores[sent_type][\"fp\"],\n",
        "            scores[sent_type][\"fn\"],\n",
        "            scores[sent_type][\"p\"],\n",
        "            scores[sent_type][\"r\"],\n",
        "            scores[sent_type][\"f1\"],\n",
        "            scores[sent_type][\"tp\"] +\n",
        "            scores[sent_type][\n",
        "                \"fp\"]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}