{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "nlp_hw2.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "DyM39Hb89WdF",
        "MMcutM72NGcI",
        "vyY3M7Un0VXu",
        "EnJuu3tbUgvn",
        "L8vzinmvb4x2",
        "hYjbtu2qVq5W",
        "2wATp3pfduPg",
        "xCL-D3DKd1Sj",
        "YFT5dm_5NYeP",
        "vNLb1VSIS3a8",
        "2KE1BtxsmBNJ",
        "OwunMH6fWNkI",
        "ICC3g_Wu1kjn",
        "8YZoRkeV-WvS",
        "bCwLdySOM9it",
        "kiGlYlt9DiaM",
        "ABh7UkQBDlKt",
        "jcwzOXhlZDQY",
        "UKpRzNWqTcXO",
        "zMclicKXGZ9C",
        "KzdRK6LlpV1r",
        "zwCMfEutpccP",
        "au-5s3YWTPiF",
        "pW7JmyGUXmJu",
        "GNOOSb92X31J"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "961f7b94248e4b2cbbf3a9f8745e9dfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a8aa9d851f584c64b168c185099e81ca",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_fb21a7aab56847b1bf6ec5fe09951858",
              "IPY_MODEL_c928c7509c7246378ee1b2a36ef56eea"
            ]
          }
        },
        "a8aa9d851f584c64b168c185099e81ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb21a7aab56847b1bf6ec5fe09951858": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3b0b50dc1bb04f1187ffd399d52793bc",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84af3a64efa249af985b8e3411fb2215"
          }
        },
        "c928c7509c7246378ee1b2a36ef56eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_67c8cab8bcea4dd89ec37b46c8b053c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:01&lt;00:00, 125kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a5356aadc26425aa6bf12b1acb7d66d"
          }
        },
        "3b0b50dc1bb04f1187ffd399d52793bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84af3a64efa249af985b8e3411fb2215": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "67c8cab8bcea4dd89ec37b46c8b053c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a5356aadc26425aa6bf12b1acb7d66d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d5de18b4e0743039fa1de698214637d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cc6c8ba264d641998d26ff383cabf602",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b89d9b2b53d44b8ebec4d9d97b9440bf",
              "IPY_MODEL_b183d0dc380f4a83a441cb475900d845"
            ]
          }
        },
        "cc6c8ba264d641998d26ff383cabf602": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b89d9b2b53d44b8ebec4d9d97b9440bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b8e092aa942b4350b5b2173676f49245",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4feafb44e306435c886f545a4d2b1177"
          }
        },
        "b183d0dc380f4a83a441cb475900d845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a97790d345674a01ad1658e3f4d3ffe4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [00:04&lt;00:00, 106kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_64a4fd85b7394c388f35fd07c5afb3cf"
          }
        },
        "b8e092aa942b4350b5b2173676f49245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4feafb44e306435c886f545a4d2b1177": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a97790d345674a01ad1658e3f4d3ffe4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "64a4fd85b7394c388f35fd07c5afb3cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe333864048e4d85abc13b594b21f559": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_92f69ef8429e4d7cb4dfee43bd916637",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d21b5c985ad440529c5d4913fd7d391a",
              "IPY_MODEL_4b94d3d2a71542819da584d007f7932f"
            ]
          }
        },
        "92f69ef8429e4d7cb4dfee43bd916637": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d21b5c985ad440529c5d4913fd7d391a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f80c0f3b1d1d4c699c00dea61c93f1b8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b2ab44c2c29345e595ddd86340e2793c"
          }
        },
        "4b94d3d2a71542819da584d007f7932f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c682a18c95504b15a97979d9347d11c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 70.1B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b40b5433814450da884878511f6ae73"
          }
        },
        "f80c0f3b1d1d4c699c00dea61c93f1b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b2ab44c2c29345e595ddd86340e2793c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c682a18c95504b15a97979d9347d11c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b40b5433814450da884878511f6ae73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ec5d2ee121f2445f86e7db9a62d4b9ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3cfd9d12fcbd407baab948ce5f338d61",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f31769e55b1c419887f7ac95ea95aee9",
              "IPY_MODEL_ef67b8f242a4421f8b27f98a3f1d9f6a"
            ]
          }
        },
        "3cfd9d12fcbd407baab948ce5f338d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "f31769e55b1c419887f7ac95ea95aee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8917e5fdad8f4fc1a0628a4dac2c2587",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_271cfc12a9d149fda8a2585ee7cacd04"
          }
        },
        "ef67b8f242a4421f8b27f98a3f1d9f6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_be287613e58a477f962fc047298f442f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [36:46&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_977795e642e74750a0c1a1bc6de8abf6"
          }
        },
        "8917e5fdad8f4fc1a0628a4dac2c2587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "271cfc12a9d149fda8a2585ee7cacd04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be287613e58a477f962fc047298f442f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "977795e642e74750a0c1a1bc6de8abf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "767dc8a4397c46eea32c81bc15410feb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1983c7d04653475f9dba7386da821d36",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c631e18f453e45bea09a72f9d835280e",
              "IPY_MODEL_508e06b71c85492d9a41cf0fe6471fde"
            ]
          }
        },
        "1983c7d04653475f9dba7386da821d36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "c631e18f453e45bea09a72f9d835280e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d97e892804e941c0aa6958a714a0fc26",
            "_dom_classes": [],
            "description": "Epoch 4: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 69,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 69,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24c418beb59b45b486e59af1215bdb26"
          }
        },
        "508e06b71c85492d9a41cf0fe6471fde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fda0a2e978c84e898cd6d99a959fcb6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 69/69 [40:54&lt;00:00, 35.57s/it, loss=0.274, v_num=0, valid_loss=0.733, val_f1=0.589, train_loss=0.0857, train_f1=0.834]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_630879492b6e49828bb85cac79d50ccf"
          }
        },
        "d97e892804e941c0aa6958a714a0fc26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24c418beb59b45b486e59af1215bdb26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fda0a2e978c84e898cd6d99a959fcb6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "630879492b6e49828bb85cac79d50ccf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7597c039d01d4132a80c2fb07776df1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9572759a16fa4ca9863e77e2c63a9f07",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ae6205a662e2430d84a42d9acd29d083",
              "IPY_MODEL_9646f325afe34e4c929f061738600392"
            ]
          }
        },
        "9572759a16fa4ca9863e77e2c63a9f07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "ae6205a662e2430d84a42d9acd29d083": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9308f2d6fbe487a82798bdafbafc7b3",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 13,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 13,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4b2c130c7094968a6129d49e87a2825"
          }
        },
        "9646f325afe34e4c929f061738600392": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5542f48537054c1f8b1569ca19df1a16",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13/13 [00:08&lt;00:00,  1.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b59b085570f4a3a9a30677567c69f8f"
          }
        },
        "b9308f2d6fbe487a82798bdafbafc7b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4b2c130c7094968a6129d49e87a2825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5542f48537054c1f8b1569ca19df1a16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b59b085570f4a3a9a30677567c69f8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4f4392d922f4790ba5fb551a3739c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7dbc1371b5e946869f739d20263bb36e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_93cad05753a2406199a740bbc7dc01e4",
              "IPY_MODEL_ec561e23321749b48d5cc21cdd408e67"
            ]
          }
        },
        "7dbc1371b5e946869f739d20263bb36e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "93cad05753a2406199a740bbc7dc01e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f59d5510c64747d4ab1af44e3e900aa4",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 13,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 13,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3c307732fd9647b3891406b1d8f85d03"
          }
        },
        "ec561e23321749b48d5cc21cdd408e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5a164b87d2dd437daccbe28ef0255ae6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13/13 [00:08&lt;00:00,  1.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_59f1151bba71484c9c447a53b99ace7a"
          }
        },
        "f59d5510c64747d4ab1af44e3e900aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3c307732fd9647b3891406b1d8f85d03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5a164b87d2dd437daccbe28ef0255ae6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "59f1151bba71484c9c447a53b99ace7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "157c2e45b14b4a649cb32dda44dbbf41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3bf0cef774c340f5ab0718373134814a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bd25333d0c724917aba696c583fc6971",
              "IPY_MODEL_8d7cb264d5c3429b884ebd75754635f9"
            ]
          }
        },
        "3bf0cef774c340f5ab0718373134814a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "bd25333d0c724917aba696c583fc6971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fba21f42944449d984838fba5d491c4a",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 13,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 13,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5d158fd48314602ad6159008f719c69"
          }
        },
        "8d7cb264d5c3429b884ebd75754635f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_448a40b6473d4a03ab7d7f62843b7357",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13/13 [00:08&lt;00:00,  1.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_dbea96771fa548d4acd5307f2b7299cc"
          }
        },
        "fba21f42944449d984838fba5d491c4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5d158fd48314602ad6159008f719c69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "448a40b6473d4a03ab7d7f62843b7357": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "dbea96771fa548d4acd5307f2b7299cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87047ec3a20b433ca2b829ed51bc5c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_68d52d8d0f7240019700009f590f40f9",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d90a11c16f744ecdafb3ea9e238b5d7d",
              "IPY_MODEL_75ad54de64674bc38faabb0abdf991ed"
            ]
          }
        },
        "68d52d8d0f7240019700009f590f40f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "d90a11c16f744ecdafb3ea9e238b5d7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3e1883e7ab7e47c8b380515630cec588",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 13,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 13,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a6a1bbf180b4cf4b42b0b467e0d4a8d"
          }
        },
        "75ad54de64674bc38faabb0abdf991ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21dc18fedd824b549e53af35823e111f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13/13 [00:08&lt;00:00,  1.59it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_57aed45a7c93405aa64f5ccbf5c6cdbb"
          }
        },
        "3e1883e7ab7e47c8b380515630cec588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a6a1bbf180b4cf4b42b0b467e0d4a8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "21dc18fedd824b549e53af35823e111f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "57aed45a7c93405aa64f5ccbf5c6cdbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1229eb30c104b64bb0c7771745a870a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_67d0de59949e47fe926a6af32945ba95",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a3c1437cb4740719af950b640c0f872",
              "IPY_MODEL_6dd70528342d4433a612624c146afbd5"
            ]
          }
        },
        "67d0de59949e47fe926a6af32945ba95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "2a3c1437cb4740719af950b640c0f872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_aed852bc135b42f38e810eb33559d931",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 13,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 13,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_674ae67a3fa042a8881f0026443ba05c"
          }
        },
        "6dd70528342d4433a612624c146afbd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_87577ef68222471490f4b679263ce09b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 13/13 [00:08&lt;00:00,  1.60it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4fda82fd1a1947838e94953db9989d9b"
          }
        },
        "aed852bc135b42f38e810eb33559d931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "674ae67a3fa042a8881f0026443ba05c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "87577ef68222471490f4b679263ce09b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4fda82fd1a1947838e94953db9989d9b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f78cb654444440e68205a5cdfbaa9c40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c8b4683ca42a406a8b4f827485065d47",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_13813d43539c46afb32fbd18a9ce9418",
              "IPY_MODEL_4cdafb3516944813bbb55d91cc519779"
            ]
          }
        },
        "c8b4683ca42a406a8b4f827485065d47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13813d43539c46afb32fbd18a9ce9418": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6d05b1682b8640bb8c204305147a93ce",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 411,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 411,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9e5ec14b12734b69892d10893132470e"
          }
        },
        "4cdafb3516944813bbb55d91cc519779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fb653e39201d4a87a9309c22866aa585",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 411/411 [00:00&lt;00:00, 2.06kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b287e412b7ee43f5affd7056362482fd"
          }
        },
        "6d05b1682b8640bb8c204305147a93ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9e5ec14b12734b69892d10893132470e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fb653e39201d4a87a9309c22866aa585": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b287e412b7ee43f5affd7056362482fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f47dcd371bca4130a116954c02ebe7a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_87fcf59c8b01446b96a3a666b17c0a7e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4900b010d1f24ca7832a65b65fffde1e",
              "IPY_MODEL_4e361a3f640a4982820bdc6d9010db99"
            ]
          }
        },
        "87fcf59c8b01446b96a3a666b17c0a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4900b010d1f24ca7832a65b65fffde1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d1fec17d6f524a7986a7712060d3d8b6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 263273408,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 263273408,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_83e46cce8ed44ddc88dd7e71213692d4"
          }
        },
        "4e361a3f640a4982820bdc6d9010db99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa39c854f7cd44cfacba68f3345b4a56",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 263M/263M [00:05&lt;00:00, 47.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4514b493168d4587ba62d13b71665f51"
          }
        },
        "d1fec17d6f524a7986a7712060d3d8b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "83e46cce8ed44ddc88dd7e71213692d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa39c854f7cd44cfacba68f3345b4a56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4514b493168d4587ba62d13b71665f51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3dc5f9dfeabf423ba0c0fa9960f12347": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_95252eefb12a44418b77f1ae6bb416f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9105d6b5b0164b72814ba9ec4a600d1c",
              "IPY_MODEL_d4398e50c6a643c2976b3019e44c227d"
            ]
          }
        },
        "95252eefb12a44418b77f1ae6bb416f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "9105d6b5b0164b72814ba9ec4a600d1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_11f8eb13292b44a3b4277181bf382a82",
            "_dom_classes": [],
            "description": "Validation sanity check:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_da0aa675e64e48fbb1aaa57778c93198"
          }
        },
        "d4398e50c6a643c2976b3019e44c227d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ddc70421593d4d02920a5b8d5e79d4a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/2 [00:14&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62a224f9f97f4a45b780fd566f367adb"
          }
        },
        "11f8eb13292b44a3b4277181bf382a82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "da0aa675e64e48fbb1aaa57778c93198": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ddc70421593d4d02920a5b8d5e79d4a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62a224f9f97f4a45b780fd566f367adb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "430968a2dc804c5e86f7a8bcf1e858c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6afc79977fcf46c193b2d408d83f8b51",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5b6244fe03cd45f1ae61843f5848d8c8",
              "IPY_MODEL_85b0af61eacd4e75975c66a183d66ca8"
            ]
          }
        },
        "6afc79977fcf46c193b2d408d83f8b51": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "5b6244fe03cd45f1ae61843f5848d8c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7cac26539d7a4e7fa0f79b79898ff04c",
            "_dom_classes": [],
            "description": "Epoch 4: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 96,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 96,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_740f7ca5b0e64b738fefb6b4d3bed8db"
          }
        },
        "85b0af61eacd4e75975c66a183d66ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_69600d43d29048c4a36ff06875b7df2f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 96/96 [00:21&lt;00:00,  4.50it/s, loss=0.137, v_num=0, val_loss=0.143, train_loss=0.0938]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_741a5400490348f6b27a6b77a25c97f0"
          }
        },
        "7cac26539d7a4e7fa0f79b79898ff04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "740f7ca5b0e64b738fefb6b4d3bed8db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "69600d43d29048c4a36ff06875b7df2f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "741a5400490348f6b27a6b77a25c97f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4169416293b24a688adfe216d9f70c1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f80bb77861f7457a8d9fa588a10f950c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea5c18dc4c5a41bebf5a7fd12ba04e54",
              "IPY_MODEL_8889aeee02e2414591815ced3a0bf3fb"
            ]
          }
        },
        "f80bb77861f7457a8d9fa588a10f950c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "ea5c18dc4c5a41bebf5a7fd12ba04e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_96f0fcdc54af4a36a6a31a5758b4ec7f",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 17,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55acc995971444a9b5365f6a23a340b3"
          }
        },
        "8889aeee02e2414591815ced3a0bf3fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c79f28ea040841f491d729bf37f3c5f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 17/17 [00:00&lt;00:00, 71.37it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1ce5d18c7be14b3898ba630a7f94af2b"
          }
        },
        "96f0fcdc54af4a36a6a31a5758b4ec7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55acc995971444a9b5365f6a23a340b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c79f28ea040841f491d729bf37f3c5f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1ce5d18c7be14b3898ba630a7f94af2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a695e7339ce14af995ca0704793749cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6061d0ab824c419a8cf4b74114c947d8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_92eb8a0627f245d2ace7fc9821d6ccc6",
              "IPY_MODEL_4df02b18266c4c38908879283f2ec274"
            ]
          }
        },
        "6061d0ab824c419a8cf4b74114c947d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "92eb8a0627f245d2ace7fc9821d6ccc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6224f3b491d4a799dcfa26fc246c6b2",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 17,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e46be26d39e943b8b6ef9f150f09cf22"
          }
        },
        "4df02b18266c4c38908879283f2ec274": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c2c9b4a59a649e1806034c2138d0c0f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 17/17 [00:00&lt;00:00, 68.82it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_466afbdd755542589a6179d8aab1c242"
          }
        },
        "e6224f3b491d4a799dcfa26fc246c6b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e46be26d39e943b8b6ef9f150f09cf22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c2c9b4a59a649e1806034c2138d0c0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "466afbdd755542589a6179d8aab1c242": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e7c295bdf4464de0ac565eb509fcb312": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_662354f27bc94e818bbc53b14294773e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e854c194b0d5446ca3f5493b7a961498",
              "IPY_MODEL_87885b44690744a2952cd14cfbdb9a6f"
            ]
          }
        },
        "662354f27bc94e818bbc53b14294773e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e854c194b0d5446ca3f5493b7a961498": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0f78a31aa741420aa23fc7f0342fed22",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 17,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cf07cf2f19a4b9280a2a6fc9a8c0ca2"
          }
        },
        "87885b44690744a2952cd14cfbdb9a6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f69848b564e74b55a42ada63f864276b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 17/17 [00:00&lt;00:00, 66.93it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8a307bfc1bf41a0911b283dc5cd1b07"
          }
        },
        "0f78a31aa741420aa23fc7f0342fed22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cf07cf2f19a4b9280a2a6fc9a8c0ca2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f69848b564e74b55a42ada63f864276b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8a307bfc1bf41a0911b283dc5cd1b07": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3c02e1231134c8bae34ea0bc146d6bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d66ce2c7b82c430489a51ede8e681a5c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_96c1f1ebf2d64ef2b91c971043c49097",
              "IPY_MODEL_851614ab0b5b4417a647ef1428358a9b"
            ]
          }
        },
        "d66ce2c7b82c430489a51ede8e681a5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "96c1f1ebf2d64ef2b91c971043c49097": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_503a5d96684e48efa2fe69736ebe8587",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 17,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f06f3b0f52b047babd74bc9caad416f8"
          }
        },
        "851614ab0b5b4417a647ef1428358a9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dcabf24fcfbe489b9a99b0149ab66497",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 17/17 [00:00&lt;00:00, 75.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6901287d42ef4e1d8c86341d1a577a96"
          }
        },
        "503a5d96684e48efa2fe69736ebe8587": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f06f3b0f52b047babd74bc9caad416f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dcabf24fcfbe489b9a99b0149ab66497": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6901287d42ef4e1d8c86341d1a577a96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99eabc2aa9a5417a84117b2c78e128d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1c5a0a6cc1a40658928ca3e5c8d9e17",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e8218bac3c524760aeeb601904d7a61b",
              "IPY_MODEL_3d448834ee5843be8d3d1e0e9591941f"
            ]
          }
        },
        "e1c5a0a6cc1a40658928ca3e5c8d9e17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "e8218bac3c524760aeeb601904d7a61b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8f2c1439cf9c48bca413cbef242dace4",
            "_dom_classes": [],
            "description": "Validating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 17,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 17,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42292eab50524a59881af600d5f91be7"
          }
        },
        "3d448834ee5843be8d3d1e0e9591941f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c8ceb563081d492aa4dd4f20cd8d3a05",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 17/17 [00:00&lt;00:00, 73.30it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_23aa81e3c5924a6fb0eb5be7cdaea76e"
          }
        },
        "8f2c1439cf9c48bca413cbef242dace4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42292eab50524a59881af600d5f91be7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c8ceb563081d492aa4dd4f20cd8d3a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "23aa81e3c5924a6fb0eb5be7cdaea76e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyM39Hb89WdF"
      },
      "source": [
        "## Imports and setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2n5xn1F5kvq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5de88038-0963-4eb8-9421-88de87671b5a"
      },
      "source": [
        "from google.colab import drive\n",
        "# general\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import *\n",
        "import string\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader,SequentialSampler\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# torch text\n",
        "!pip install torchtext --upgrade\n",
        "\n",
        "from torchtext import data\n",
        "from torchtext.vocab import Vectors\n",
        "\n",
        "from pprint import pprint\n",
        "from torchtext.vocab import *\n",
        "from collections import Counter\n",
        "import random\n",
        "\n",
        "# nltk\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "!pip install pytorch_lightning\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "\n",
        "# SKLEARN\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
        "from sklearn.metrics import precision_score\n",
        "\n",
        "# transformers\n",
        "!pip install transformers\n",
        "from transformers import DistilBertTokenizerFast, BertTokenizerFast,BertForTokenClassification,BertTokenizerFast\n",
        "from transformers import DistilBertForSequenceClassification, BertForSequenceClassification, AdamW\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import DistilBertForTokenClassification\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from transformers import BertModel,DistilBertModel\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: torchtext in /usr/local/lib/python3.7/dist-packages (0.9.1)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from torchtext) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchtext) (3.7.4.3)\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Collecting pytorch_lightning\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b6/6a/20d0bf3b967ab62333efea36fe922aaa252d1762555b4a7afb2be5bbdcbf/pytorch_lightning-1.3.5-py3-none-any.whl (808kB)\n",
            "\u001b[K     |████████████████████████████████| 808kB 38.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (20.9)\n",
            "Collecting future>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/45/0b/38b06fd9b92dc2b68d58b75f900e97884c45bedd2ff83203d933cf5851c9/future-0.18.2.tar.gz (829kB)\n",
            "\u001b[K     |████████████████████████████████| 829kB 45.0MB/s \n",
            "\u001b[?25hCollecting tensorboard!=2.5.0,>=2.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/64/21/eebd23060763fedeefb78bc2b286e00fa1d8abda6f70efa2ee08c28af0d4/tensorboard-2.4.1-py3-none-any.whl (10.6MB)\n",
            "\u001b[K     |████████████████████████████████| 10.6MB 145kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.4 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.8.1+cu101)\n",
            "Collecting torchmetrics>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/e8/513cd9d0b1c83dc14cd8f788d05cd6a34758d4fd7e4f9e5ecd5d7d599c95/torchmetrics-0.3.2-py3-none-any.whl (274kB)\n",
            "\u001b[K     |████████████████████████████████| 276kB 52.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.41.1)\n",
            "Collecting PyYAML<=5.4.1,>=5.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n",
            "\u001b[K     |████████████████████████████████| 645kB 50.0MB/s \n",
            "\u001b[?25hCollecting fsspec[http]!=2021.06.0,>=2021.05.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/52/816d1a3a599176057bf29dfacb1f8fadb61d35fbd96cb1bab4aaa7df83c0/fsspec-2021.5.0-py3-none-any.whl (111kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 58.6MB/s \n",
            "\u001b[?25hCollecting pyDeprecate==0.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/14/52/aa227a0884df71ed1957649085adf2b8bc2a1816d037c2f18b3078854516/pyDeprecate-0.3.0-py3-none-any.whl\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch_lightning) (2.4.7)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.12.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.34.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (57.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.3.4)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.30.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.4)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.36.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.4->pytorch_lightning) (3.7.4.3)\n",
            "Collecting aiohttp; extra == \"http\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/88/c0/5890b4c8b04a79b7360e8fe4490feb0bb3ab179743f199f0e6220cebd568/aiohttp-3.7.4.post0-cp37-cp37m-manylinux2014_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 48.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (4.2.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp; extra == \"http\"->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.2.0)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 54.2MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting multidict<7.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 57.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.4.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning) (3.1.0)\n",
            "Building wheels for collected packages: future\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.2-cp37-none-any.whl size=491070 sha256=b3682679ffd8c126bd38af6121d56c4e52aefac46803c760db8b5abb677447c3\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/99/a0/81daf51dcd359a9377b110a8a886b3895921802d2fc1b2397e\n",
            "Successfully built future\n",
            "\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorboard~=2.5, but you'll have tensorboard 2.4.1 which is incompatible.\u001b[0m\n",
            "Installing collected packages: future, tensorboard, torchmetrics, PyYAML, multidict, yarl, async-timeout, aiohttp, fsspec, pyDeprecate, pytorch-lightning\n",
            "  Found existing installation: future 0.16.0\n",
            "    Uninstalling future-0.16.0:\n",
            "      Successfully uninstalled future-0.16.0\n",
            "  Found existing installation: tensorboard 2.5.0\n",
            "    Uninstalling tensorboard-2.5.0:\n",
            "      Successfully uninstalled tensorboard-2.5.0\n",
            "  Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed PyYAML-5.4.1 aiohttp-3.7.4.post0 async-timeout-3.0.1 fsspec-2021.5.0 future-0.18.2 multidict-5.1.0 pyDeprecate-0.3.0 pytorch-lightning-1.3.5 tensorboard-2.4.1 torchmetrics-0.3.2 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\r\u001b[K     |▏                               | 10kB 22.0MB/s eta 0:00:01\r\u001b[K     |▎                               | 20kB 27.8MB/s eta 0:00:01\r\u001b[K     |▍                               | 30kB 30.7MB/s eta 0:00:01\r\u001b[K     |▋                               | 40kB 32.3MB/s eta 0:00:01\r\u001b[K     |▊                               | 51kB 34.3MB/s eta 0:00:01\r\u001b[K     |▉                               | 61kB 35.8MB/s eta 0:00:01\r\u001b[K     |█                               | 71kB 36.2MB/s eta 0:00:01\r\u001b[K     |█▏                              | 81kB 35.0MB/s eta 0:00:01\r\u001b[K     |█▎                              | 92kB 36.0MB/s eta 0:00:01\r\u001b[K     |█▌                              | 102kB 37.3MB/s eta 0:00:01\r\u001b[K     |█▋                              | 112kB 37.3MB/s eta 0:00:01\r\u001b[K     |█▊                              | 122kB 37.3MB/s eta 0:00:01\r\u001b[K     |██                              | 133kB 37.3MB/s eta 0:00:01\r\u001b[K     |██                              | 143kB 37.3MB/s eta 0:00:01\r\u001b[K     |██▏                             | 153kB 37.3MB/s eta 0:00:01\r\u001b[K     |██▎                             | 163kB 37.3MB/s eta 0:00:01\r\u001b[K     |██▌                             | 174kB 37.3MB/s eta 0:00:01\r\u001b[K     |██▋                             | 184kB 37.3MB/s eta 0:00:01\r\u001b[K     |██▊                             | 194kB 37.3MB/s eta 0:00:01\r\u001b[K     |███                             | 204kB 37.3MB/s eta 0:00:01\r\u001b[K     |███                             | 215kB 37.3MB/s eta 0:00:01\r\u001b[K     |███▏                            | 225kB 37.3MB/s eta 0:00:01\r\u001b[K     |███▍                            | 235kB 37.3MB/s eta 0:00:01\r\u001b[K     |███▌                            | 245kB 37.3MB/s eta 0:00:01\r\u001b[K     |███▋                            | 256kB 37.3MB/s eta 0:00:01\r\u001b[K     |███▉                            | 266kB 37.3MB/s eta 0:00:01\r\u001b[K     |████                            | 276kB 37.3MB/s eta 0:00:01\r\u001b[K     |████                            | 286kB 37.3MB/s eta 0:00:01\r\u001b[K     |████▎                           | 296kB 37.3MB/s eta 0:00:01\r\u001b[K     |████▍                           | 307kB 37.3MB/s eta 0:00:01\r\u001b[K     |████▌                           | 317kB 37.3MB/s eta 0:00:01\r\u001b[K     |████▋                           | 327kB 37.3MB/s eta 0:00:01\r\u001b[K     |████▉                           | 337kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 348kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████                           | 358kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 368kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 378kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 389kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 399kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 409kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 419kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 430kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 440kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 450kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 460kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 471kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 481kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████                         | 491kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 501kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 512kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 522kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 532kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 542kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 552kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████                        | 563kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 573kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 583kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 593kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 604kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 614kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 624kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████                       | 634kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 645kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 655kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 665kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 675kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 686kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 696kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████                      | 706kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 716kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 727kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 737kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 747kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 757kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 768kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████                     | 778kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 788kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 798kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 808kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 819kB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 829kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 839kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████                    | 849kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 860kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 870kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 880kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 890kB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 901kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 911kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 921kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 931kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 942kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 952kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 962kB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 972kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 983kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 993kB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 1.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 1.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 1.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 1.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 1.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 1.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 1.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 1.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 1.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 1.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 1.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 1.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████                | 1.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 1.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 1.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 1.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 1.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 1.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 1.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 1.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 1.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 1.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 1.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 1.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 1.3MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 1.3MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 1.3MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 1.3MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 1.3MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 1.3MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.3MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.4MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 1.4MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.4MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 1.4MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.4MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.4MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.4MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 1.4MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.4MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 1.5MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.5MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.5MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 1.5MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.5MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.5MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.5MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 1.5MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.5MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.5MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.6MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 1.6MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.6MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.6MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 1.6MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.6MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.6MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.6MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 1.6MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 1.6MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.7MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.7MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.7MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.7MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.7MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.7MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.7MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 1.7MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.7MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.8MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.8MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.8MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.8MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.8MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.8MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.8MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 1.8MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 1.9MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.9MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 1.9MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.9MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.9MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.9MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 1.9MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.9MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.9MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 2.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 2.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 2.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 2.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 2.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 2.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 2.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 2.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 2.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 2.0MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 2.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 2.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 2.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 2.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 2.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 2.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 2.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 2.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 2.1MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 2.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 2.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 2.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 2.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 2.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 2.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 2.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 2.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 2.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.2MB 37.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 2.3MB 37.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub==0.0.8\n",
            "  Downloading https://files.pythonhosted.org/packages/a1/88/7b1e45720ecf59c6c6737ff332f41c955963090a18e72acbcbeac6b25e86/huggingface_hub-0.0.8-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 53.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 51.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Installing collected packages: huggingface-hub, tokenizers, sacremoses, transformers\n",
            "Successfully installed huggingface-hub-0.0.8 sacremoses-0.0.45 tokenizers-0.10.3 transformers-4.6.1\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7lIQtGqAoLS"
      },
      "source": [
        "Set up of seeds and  folders\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPQc6F08AlBP"
      },
      "source": [
        "root_folder = '/content/drive/My Drive/NLP/nlp2021-hw2'\n",
        "dataset_folder = os.path.join(root_folder,'data')\n",
        "\n",
        "SEED = 42\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True  \n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# !nvidia-smi"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7whUvJQzHQHd"
      },
      "source": [
        "#@title Setup of parameters{ run: \"auto\" }\n",
        "WE_LENGTH = \"50\" #@param [50,100,200,300]\n",
        "WE = \"glove\" #@param [\"glove\", \"chargram\", \"fasttext\"]\n",
        "REMOVE_STOPWORDS = True #@param [\"True\", \"False\"] {type:\"raw\"}\n",
        "LEMMATIZATION = True #@param [\"True\", \"False\"] {type:\"raw\"}\n",
        "LOWERED = True #@param [\"True\", \"False\"] {type:\"raw\"}\n",
        "model_b = False #@param [\"True\", \"False\"] {type:\"raw\"}\n",
        "model_AB = False #@param [\"True\", \"False\"] {type:\"raw\"}\n",
        "bert_model = \"bert-base-uncased\" if LOWERED else \"bert-base-cased\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyH_9P2VJY6U"
      },
      "source": [
        "needed for all models evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIpUKOcg0MO6"
      },
      "source": [
        "def evaluate_sentiment(samples, predictions_b, mode=\"Aspect Sentiment\"):\n",
        "    scores = {}\n",
        "    if mode == 'Category Extraction':\n",
        "        sentiment_types = [\"anecdotes/miscellaneous\", \"price\", \"food\", \"ambience\"]\n",
        "    else:\n",
        "        sentiment_types = [\"positive\", \"negative\", \"neutral\", \"conflict\"]\n",
        "    scores = {sent: {\"tp\": 0, \"fp\": 0, \"fn\": 0} for sent in sentiment_types + [\"ALL\"]}\n",
        "    for label, pred in zip(samples, predictions_b):\n",
        "        for sentiment in sentiment_types:\n",
        "            if mode == \"Aspect Sentiment\":\n",
        "                pred_sent = {(term_pred[0], term_pred[1]) for term_pred in pred[\"targets\"] if\n",
        "                                    term_pred[1] == sentiment}\n",
        "                gt_sent = {(term_pred[1], term_pred[2]) for term_pred in label[\"targets\"] if\n",
        "                                    term_pred[2] == sentiment}\n",
        "            elif mode == 'Category Extraction' and \"categories\" in label:\n",
        "                pred_sent = {(term_pred[0]) for term_pred in pred[\"categories\"] if\n",
        "                                term_pred[0] == sentiment}\n",
        "                gt_sent = {(term_pred[0]) for term_pred in label[\"categories\"] if\n",
        "                                term_pred[0] == sentiment}\n",
        "            elif \"categories\" in label:\n",
        "                pred_sent = {(term_pred[0], term_pred[1]) for term_pred in pred[\"categories\"] if\n",
        "                                term_pred[1] == sentiment}\n",
        "                gt_sent = {(term_pred[0], term_pred[1]) for term_pred in label[\"categories\"] if\n",
        "                                term_pred[1] == sentiment}\n",
        "            else:\n",
        "                continue\n",
        "\n",
        "            scores[sentiment][\"tp\"] += len(pred_sent & gt_sent)\n",
        "            scores[sentiment][\"fp\"] += len(pred_sent - gt_sent)\n",
        "            scores[sentiment][\"fn\"] += len(gt_sent - pred_sent)\n",
        "\n",
        "    # Compute per sentiment Precision / Recall / F1\n",
        "    for sent_type in scores.keys():\n",
        "        if scores[sent_type][\"tp\"]:\n",
        "            scores[sent_type][\"p\"] = 100 * scores[sent_type][\"tp\"] / (scores[sent_type][\"fp\"] + scores[sent_type][\"tp\"])\n",
        "            scores[sent_type][\"r\"] = 100 * scores[sent_type][\"tp\"] / (scores[sent_type][\"fn\"] + scores[sent_type][\"tp\"])\n",
        "        else:\n",
        "            scores[sent_type][\"p\"], scores[sent_type][\"r\"] = 0, 0\n",
        "\n",
        "        if not scores[sent_type][\"p\"] + scores[sent_type][\"r\"] == 0:\n",
        "            scores[sent_type][\"f1\"] = 2 * scores[sent_type][\"p\"] * scores[sent_type][\"r\"] / (\n",
        "                    scores[sent_type][\"p\"] + scores[sent_type][\"r\"])\n",
        "        else:\n",
        "            scores[sent_type][\"f1\"] = 0\n",
        "\n",
        "    # Compute micro F1 Scores\n",
        "    tp = sum([scores[sent_type][\"tp\"] for sent_type in sentiment_types])\n",
        "    fp = sum([scores[sent_type][\"fp\"] for sent_type in sentiment_types])\n",
        "    fn = sum([scores[sent_type][\"fn\"] for sent_type in sentiment_types])\n",
        "\n",
        "    if tp:\n",
        "        precision = 100 * tp / (tp + fp)\n",
        "        recall = 100 * tp / (tp + fn)\n",
        "        f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    else:\n",
        "        precision, recall, f1 = 0, 0, 0\n",
        "\n",
        "    scores[\"ALL\"][\"p\"] = precision\n",
        "    scores[\"ALL\"][\"r\"] = recall\n",
        "    scores[\"ALL\"][\"f1\"] = f1\n",
        "    scores[\"ALL\"][\"tp\"] = tp\n",
        "    scores[\"ALL\"][\"fp\"] = fp\n",
        "    scores[\"ALL\"][\"fn\"] = fn\n",
        "\n",
        "    # Compute Macro F1 Scores\n",
        "    scores[\"ALL\"][\"Macro_f1\"] = sum([scores[ent_type][\"f1\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "    scores[\"ALL\"][\"Macro_p\"] = sum([scores[ent_type][\"p\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "    scores[\"ALL\"][\"Macro_r\"] = sum([scores[ent_type][\"r\"] for ent_type in sentiment_types])/len(sentiment_types)\n",
        "\n",
        "    print(f\"{mode} Evaluation\\n\")\n",
        "\n",
        "    print(\n",
        "        \"\\tALL\\t TP: {};\\tFP: {};\\tFN: {}\".format(\n",
        "            scores[\"ALL\"][\"tp\"],\n",
        "            scores[\"ALL\"][\"fp\"],\n",
        "            scores[\"ALL\"][\"fn\"]))\n",
        "    print(\n",
        "        \"\\t\\t(m avg): precision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f} (micro)\".format(\n",
        "            precision,\n",
        "            recall,\n",
        "            f1))\n",
        "    print(\n",
        "        \"\\t\\t(M avg): precision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f} (Macro)\\n\".format(\n",
        "            scores[\"ALL\"][\"Macro_p\"],\n",
        "            scores[\"ALL\"][\"Macro_r\"],\n",
        "            scores[\"ALL\"][\"Macro_f1\"]))\n",
        "\n",
        "    for sent_type in sentiment_types:\n",
        "        print(\"\\t{}: \\tTP: {};\\tFP: {};\\tFN: {};\\tprecision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f};\\t{}\".format(\n",
        "            sent_type,\n",
        "            scores[sent_type][\"tp\"],\n",
        "            scores[sent_type][\"fp\"],\n",
        "            scores[sent_type][\"fn\"],\n",
        "            scores[sent_type][\"p\"],\n",
        "            scores[sent_type][\"r\"],\n",
        "            scores[sent_type][\"f1\"],\n",
        "            scores[sent_type][\"tp\"] +\n",
        "            scores[sent_type][\n",
        "                \"fp\"]))\n",
        "\n",
        "def evaluate_extraction(samples, predictions_b):\n",
        "    scores = {\"tp\": 0, \"fp\": 0, \"fn\": 0}\n",
        "    for label, pred in zip (samples, predictions_b):\n",
        "        pred_terms = {term_pred[0] for term_pred in pred[\"targets\"]}\n",
        "        gt_terms = {term_gt[1] for term_gt in label[\"targets\"]}\n",
        "\n",
        "        scores[\"tp\"] += len(pred_terms & gt_terms)\n",
        "        scores[\"fp\"] += len(pred_terms - gt_terms)\n",
        "        scores[\"fn\"] += len(gt_terms - pred_terms)\n",
        "\n",
        "    precision = 100 * scores[\"tp\"] / (scores[\"tp\"] + scores[\"fp\"])\n",
        "    recall = 100 * scores[\"tp\"] / (scores[\"tp\"] + scores[\"fn\"])\n",
        "    f1 = 2 * precision * recall / (precision + recall)\n",
        "\n",
        "    print(f\"Aspect Extraction Evaluation\")\n",
        "\n",
        "    print(\n",
        "        \"\\tAspects\\t TP: {};\\tFP: {};\\tFN: {}\".format(\n",
        "            scores[\"tp\"],\n",
        "            scores[\"fp\"],\n",
        "            scores[\"fn\"]))\n",
        "    print(\n",
        "        \"\\t\\tprecision: {:.2f};\\trecall: {:.2f};\\tf1: {:.2f}\".format(\n",
        "            precision,\n",
        "            recall,\n",
        "            f1))\n",
        "\n",
        "\n",
        "def load_data(data_path):\n",
        "    with open(data_path) as json_file:\n",
        "        list_of_sentences = json.load(json_file)\n",
        "    return list_of_sentences"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMcutM72NGcI"
      },
      "source": [
        "# TASK A-B (Bi-LSTM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vyY3M7Un0VXu"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un8I8KTkr1zR"
      },
      "source": [
        "class BiLSTMDataset(Dataset):\n",
        "\n",
        "    def __init__(self, \n",
        "                 data_path:str,\n",
        "                 window_size:int, \n",
        "                 model_b:bool=False,\n",
        "                 device=\"cuda\"):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            data_path (string): The path containing the data\n",
        "            window_size (integer): The maximum length of a sentence in terms of number of tokens.\n",
        "            model_b:bool=False,\n",
        "        \"\"\"\n",
        "\n",
        "        self.window_size = window_size\n",
        "        self.model_b = model_b\n",
        "\n",
        "        sentences = self.load_data(data_path)\n",
        "        self.device = device\n",
        "        self.data = self.create_windows(sentences)\n",
        "        self.encoded_data = None\n",
        "    \n",
        "\n",
        "    def remove_stopwords(self,sent: str) -> str:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        # remove punkt\n",
        "        others = \"–\" +\"—\" + \"−\" + \"’\" + \"”\" + \"“\" #These chars arent inside the standard punctuation\n",
        "        str_punkt = string.punctuation+ others\n",
        "        translator = str.maketrans(str_punkt, ' '*len(str_punkt)) \n",
        "        word_tokens = word_tokenize(sent.translate(translator)) \n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        return filtered_sentence\n",
        "\n",
        "    def load_data(self,data_path):\n",
        "        sentences = []\n",
        "        with open(data_path) as json_file:\n",
        "            list_of_sentences = json.load(json_file)\n",
        "            for obj in list_of_sentences:\n",
        "                _sentence = []\n",
        "                lemmatized = obj['text'].split(\" \")\n",
        "                if LEMMATIZATION:\n",
        "                    lemmatized = [lemmatizer.lemmatize(w)  for w in obj['text'].split(\" \")]\n",
        "                if REMOVE_STOPWORDS:\n",
        "                    if LEMMATIZATION:    \n",
        "                        lemmatized = self.remove_stopwords(\" \".join(lemmatized))\n",
        "                    else:\n",
        "                        lemmatized = self.remove_stopwords(obj['text'])\n",
        "                if LOWERED:\n",
        "                    lemmatized = [x.lower() for x in lemmatized]\n",
        "                for t in lemmatized:\n",
        "                    ne_label = \"O\"\n",
        "                    sentiment = \"\"\n",
        "                    for i in range(len(obj['targets'])):\n",
        "                        lemmatized_target = obj['targets'][i][1]\n",
        "                        if LEMMATIZATION:\n",
        "                            lemmatized_target = lemmatizer.lemmatize(obj['targets'][i][1])\n",
        "                        if LOWERED:\n",
        "                            lemmatized_target = lemmatized_target.lower()\n",
        "                        \n",
        "                        if t in lemmatized_target:\n",
        "                            ne_label = \"B\" if t == lemmatized_target.split(\" \")[0] else \"I\"\n",
        "                            try:\n",
        "                                if ne_label == \"I\" and _sentence[-1][\"ne_label\"] == \"O\":\n",
        "                                    ne_label = \"O\"\n",
        "                            except:\n",
        "                                ne_label = \"O\"\n",
        "                                \n",
        "                            sentiment = obj['targets'][i][2]\n",
        "                            #embed sentiment directly into the position of word\n",
        "                            if self.model_b and ne_label != \"O\":\n",
        "                                ne_label = ne_label +\"-\"+sentiment\n",
        "                    token = {\"token\": t, \"ne_label\": ne_label , \"sentiment\" :sentiment}\n",
        "                    _sentence.append(token)\n",
        "                sentences.append(_sentence)\n",
        "            return sentences\n",
        "\n",
        "    def create_windows(self, sentences): \n",
        "        data = []\n",
        "        for sentence in sentences:\n",
        "            for i in range(0, len(sentence), self.window_size):\n",
        "                window = sentence[i:i+self.window_size]\n",
        "                if len(window) < self.window_size:\n",
        "                    window = window + [None]*(self.window_size - len(window))  # to match the same length of sentences\n",
        "                assert len(window) == self.window_size\n",
        "                data.append(window)\n",
        "        return data\n",
        "\n",
        "\n",
        "    def index_dataset(self, l_vocabulary, l_label_vocabulary):\n",
        "        self.encoded_data = list()\n",
        "        for i in range(len(self.data)):\n",
        "            sentence = self.data[i]\n",
        "            encoded_sentence = torch.LongTensor(self.encode_text(sentence, l_vocabulary)).to(self.device)\n",
        "            encoded_labels = torch.LongTensor([l_label_vocabulary[d[\"ne_label\"]] if d is not None else l_label_vocabulary[\"<pad>\"] for d in sentence]).to(self.device)\n",
        "            \n",
        "            self.encoded_data.append({\"inputs\":encoded_sentence, \"outputs\":encoded_labels})\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def encode_text(sentence:list, l_vocabulary:Vocab):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            sentences (list): list of OrderedDict, each carrying the information about one token.\n",
        "            l_vocabulary (Vocab): vocabulary with mappings from words to indices and viceversa.\n",
        "        Return:\n",
        "            The method returns a list of indices corresponding to the input tokens.\n",
        "        \"\"\"\n",
        "        indices = list()\n",
        "        for w in sentence:\n",
        "            if w is None:\n",
        "                indices.append(l_vocabulary[\"<pad>\"])\n",
        "            elif w[\"token\"] in l_vocabulary.stoi: # vocabulary string to integer (necessary to search faster)\n",
        "                indices.append(l_vocabulary[w[\"token\"]])\n",
        "            else:\n",
        "                indices.append(l_vocabulary[\"<unk>\"])\n",
        "        return indices\n",
        "\n",
        "    \n",
        "    @staticmethod\n",
        "    def decode_output(outputs:torch.Tensor,label_vocabulary: Vocab):\n",
        "        max_indices = torch.argmax(outputs, -1).tolist() # shape = (batch_size, max_len)\n",
        "        predictions = list()\n",
        "        for indices in max_indices:\n",
        "            # vocabulary integer to string is used to obtain the corresponding word from the max index\n",
        "            predictions.append([label_vocabulary.itos[i] for i in indices])\n",
        "        return predictions\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded_data[idx]\n",
        "    \n",
        "    def get_raw_element(self, idx):\n",
        "        return self.data[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4IXoEzFqdp6E"
      },
      "source": [
        "Data module definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnjG9vx0dpOa"
      },
      "source": [
        "class DataModuleBiLSTM(pl.LightningDataModule):\n",
        "    def __init__(self, training_file, dev_file, window_size, vocabulary, label_vocabulary, model_b=None):\n",
        "        super().__init__()\n",
        "        self.training_file = training_file\n",
        "        self.dev_file = dev_file\n",
        "        self.window_size = window_size\n",
        "        self.vocabulary = vocabulary\n",
        "        self.label_vocabulary = label_vocabulary\n",
        "        self.model_b = model_b\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "      self.trainingset = BiLSTMDataset(self.training_file, self.window_size,  self.model_b)\n",
        "      self.devset = BiLSTMDataset(self.dev_file, self.window_size,  self.model_b)\n",
        "\n",
        "      self.trainingset.index_dataset(self.vocabulary, self.label_vocabulary)\n",
        "      self.devset.index_dataset(self.vocabulary, self.label_vocabulary)\n",
        "          \n",
        "    def train_dataloader(self):\n",
        "      return DataLoader(self.trainingset, batch_size=128)\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.devset, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EnJuu3tbUgvn"
      },
      "source": [
        "### Building vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rjbrH-mCu8iZ"
      },
      "source": [
        "def build_vocab(dataset, min_freq=1):\n",
        "    counter = Counter()\n",
        "    for i in tqdm(range(len(dataset))):\n",
        "        for token in dataset.get_raw_element(i):\n",
        "            if token is not None:\n",
        "                counter[token[\"token\"]]+=1\n",
        "    #Counter({'the': 1046, 'and': 671, 'to': 604, etc....}\n",
        "\n",
        "    return Vocab(counter, specials=['<pad>', '<unk>'], min_freq=min_freq)\n",
        "\n",
        "def build_label_vocab(dataset):\n",
        "    counter = Counter()\n",
        "    for i in tqdm(range(len(dataset))):\n",
        "        for token in dataset.get_raw_element(i):\n",
        "            if token is not None:\n",
        "                counter[token[\"ne_label\"]]+=1\n",
        "    # No <unk> token for labels. Counter({'O': 19179, 'B': 1548, 'I': 718})\n",
        "    print(counter)\n",
        "    return Vocab(counter, specials=['<pad>'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyvdW3GtwelF"
      },
      "source": [
        "training_file = dataset_folder+\"/laptops_train.json\"\n",
        "dev_file = dataset_folder+\"/laptops_dev.json\"\n",
        "\n",
        "window_size = 20\n",
        "dataset = BiLSTMDataset(training_file, window_size, model_b)\n",
        "\n",
        "vocabulary = build_vocab(dataset)\n",
        "label_vocabulary = build_label_vocab(dataset)\n",
        "dataset.index_dataset(vocabulary, label_vocabulary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8vzinmvb4x2"
      },
      "source": [
        "## Usage of pretrained embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUhw7SOT3a_-"
      },
      "source": [
        "if WE ==\"glove\":\n",
        "    vocabulary.load_vectors(\"glove.6B.\"+WE_LENGTH+\"d\")\n",
        "elif WE == \"charngram\":\n",
        "    vocabulary.load_vectors(\"charngram.100d\")\n",
        "else:\n",
        "    vocabulary.load_vectors(\"fasttext.en.300d\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2BiDElNVaRJ"
      },
      "source": [
        "print(vocabulary.vectors[1165])\n",
        "#print(vocabulary.vectors[0].get_vecs_by_tokens(\"pain\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYjbtu2qVq5W"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaxUAwmSutnW"
      },
      "source": [
        "class ABSAModel(pl.LightningModule):\n",
        "    def __init__(self, hparams, embeddings = None, comments=\"without_pretrained_embeddings\",*args, **kwargs):\n",
        "        super(ABSAModel, self).__init__(*args, **kwargs)\n",
        "\n",
        "        self.save_hyperparameters(hparams)\n",
        "        self.loss_function = nn.CrossEntropyLoss(ignore_index=label_vocabulary['<pad>'])\n",
        "        self.word_embedding = nn.Embedding(self.hparams.vocab_size, self.hparams.embedding_dim) # hparams.vocab_size words in vocab, hparams.embedding_dim dimensional embeddings\n",
        "\n",
        "        if embeddings is not None:\n",
        "            print(\"embeddings from pretrained\")\n",
        "            self.word_embedding = nn.Embedding.from_pretrained(embeddings)\n",
        "\n",
        "        self.lstm = nn.LSTM(self.hparams.embedding_dim, self.hparams.hidden_dim, \n",
        "                            bidirectional=self.hparams.bidirectional,\n",
        "                            num_layers=self.hparams.num_layers, \n",
        "                            dropout = self.hparams.dropout if self.hparams.num_layers > 1 else 0)\n",
        "        \n",
        "        lstm_output_dim = self.hparams.hidden_dim if self.hparams.bidirectional is False else self.hparams.hidden_dim * 2\n",
        "\n",
        "        self.dropout = nn.Dropout(self.hparams.dropout)\n",
        "        self.classifier = nn.Linear(lstm_output_dim, self.hparams.num_classes)\n",
        "\n",
        "        self.writer = SummaryWriter(comment=comments+\"_modelb=\"+str(model_b))\n",
        "        self.epoch_t, self.epoch_ev = -1,-1\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeddings = self.word_embedding(x)\n",
        "        embeddings = self.dropout(embeddings)\n",
        "        o, (h, c) = self.lstm(embeddings)\n",
        "        o = self.dropout(o)\n",
        "        logits = self.classifier(o)\n",
        "        \n",
        "        predictions = torch.argmax(logits, -1)\n",
        "        \n",
        "        return logits, predictions\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        '''\n",
        "        {\n",
        "        'inputs': tensor([  5, 121,  34,   6, 834,  68, 307,   4, 370, 684, 663,  40,  42, 748, 0,   0,   0,   0,   0], device='cuda:0'), \n",
        "        'outputs': tensor([1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
        "        }\n",
        "        '''\n",
        "        inputs = batch['inputs']\n",
        "        labels = batch['outputs']\n",
        "        logits, _ = self.forward(inputs)\n",
        "\n",
        "        logits = logits.view(-1, logits.shape[-1])\n",
        "        labels = labels.view(-1)\n",
        "\n",
        "        loss = self.loss_function(logits, labels)\n",
        "        \n",
        "        # Log it:\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        if self.epoch_t != self.current_epoch:\n",
        "            self.epoch_t = self.current_epoch\n",
        "            self.writer.add_scalar(\"train/loss\", loss, self.current_epoch)\n",
        "            self.log_f1(logits,labels,\"train\")\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        inputs = batch['inputs']\n",
        "        labels = batch['outputs']\n",
        "\n",
        "        logits, _ = self.forward(inputs)\n",
        "        logits = logits.view(-1, logits.shape[-1])\n",
        "        labels = labels.view(-1)\n",
        "        sample_loss = self.loss_function(logits, labels)\n",
        "        self.log('valid_loss', sample_loss, prog_bar=True)\n",
        "        \n",
        "        if self.epoch_ev != self.current_epoch:\n",
        "            self.epoch_ev = self.current_epoch\n",
        "            self.writer.add_scalar(\"eval/loss\", sample_loss, self.current_epoch)\n",
        "            self.log_f1(logits,labels,\"eval\")\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return optim.Adam(self.parameters())\n",
        "\n",
        "\n",
        "    def log_f1(self,logits,indexed_labels,mode=\"train\"):\n",
        "        predictions = torch.argmax(logits, -1).view(-1)\n",
        "        labels = indexed_labels.view(-1)\n",
        "        valid_indices = labels != 0\n",
        "        \n",
        "        valid_predictions = predictions[valid_indices]\n",
        "        valid_labels = labels[valid_indices]\n",
        "        macro_f1 = f1_score(valid_labels.tolist(), valid_predictions.tolist(), average=\"macro\", zero_division=0)\n",
        "        self.writer.add_scalar(mode+\"/f1\", macro_f1, self.current_epoch)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wATp3pfduPg"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6HpQxFjvhWb"
      },
      "source": [
        "to_be_saved = False\n",
        "try:\n",
        "    embedding_dim = vocabulary.vectors.shape[1]\n",
        "except:\n",
        "    embedding_dim = 100\n",
        "hparams = {'vocab_size': len(vocabulary),\n",
        "            'hidden_dim': 80,\n",
        "            'embedding_dim': embedding_dim,\n",
        "            'num_classes': len(label_vocabulary), # number of different universal POS tags\n",
        "            'bidirectional': True,\n",
        "            'num_layers': 2,\n",
        "            'dropout': 0.2}\n",
        "window_size = 25\n",
        "data_module = DataModuleBiLSTM(training_file, dev_file, window_size, vocabulary, label_vocabulary, model_b)\n",
        "trainer = pl.Trainer(gpus=1, val_check_interval=1.0, max_epochs=20)\n",
        "\n",
        "model = ABSAModel(hparams,comments=\"lem=\"+str(LEMMATIZATION)+\"_stopwords_remove=\"+str(REMOVE_STOPWORDS) + \"_low=\"+str(LOWERED))\n",
        "#model = ABSAModel(hparams,vocabulary.vectors,comments=\"with_charngram\") #if pretrained embeddings in use uncomment this line\n",
        "trainer.fit(model, datamodule=data_module)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCL-D3DKd1Sj"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VF8NINZ9FH5x"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYUsD5Z9hz13"
      },
      "source": [
        "try:\n",
        "    %reload_ext tensorboard\n",
        "except:\n",
        "    %load_ext tensorboard\n",
        "%tensorboard --logdir=runs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KZ_vbNZMFXTf"
      },
      "source": [
        "overall scores without separating from target or sentiment classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s00-6EVFwEqP"
      },
      "source": [
        "def compute_scores(model:pl.LightningModule, l_dataset:DataLoader, l_label_vocab:Vocab):\n",
        "    model.freeze()\n",
        "    model.cuda()\n",
        "    all_predictions = list()\n",
        "    all_labels = list()\n",
        "    for indexed_elem in l_dataset:\n",
        "        indexed_in = indexed_elem[\"inputs\"]\n",
        "        indexed_labels = indexed_elem[\"outputs\"]\n",
        "        predictions, _ = model(indexed_in)\n",
        "        predictions = torch.argmax(predictions, -1).view(-1)\n",
        "        labels = indexed_labels.view(-1)\n",
        "        valid_indices = labels != 0\n",
        "        \n",
        "        valid_predictions = predictions[valid_indices]\n",
        "        valid_labels = labels[valid_indices]\n",
        "        \n",
        "        all_predictions.extend(valid_predictions.tolist())\n",
        "        all_labels.extend(valid_labels.tolist())\n",
        "\n",
        "    macro_accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    macro_f1 = f1_score(all_labels, all_predictions, average=\"macro\", zero_division=0)\n",
        "    per_class_precision = precision_score(all_labels, all_predictions, labels = list(range(len(l_label_vocab))), average=None, zero_division=0)\n",
        "    model.unfreeze()\n",
        "    return {\"macro_accuracy\":macro_accuracy,\n",
        "            \"f1_macro\":macro_f1, \n",
        "            \"per_class_precision\":per_class_precision}\n",
        "\n",
        "scores = compute_scores(model, data_module.val_dataloader(), label_vocabulary)\n",
        "per_class_precision = scores[\"per_class_precision\"]\n",
        "print(\"Accuracy: {}\\nMacro F1: {}\".format(scores[\"macro_accuracy\"], scores[\"f1_macro\"]))\n",
        "print(\"Per class Precision:\")\n",
        "for idx_class, precision in sorted(enumerate(per_class_precision), key=lambda elem: -elem[1]):\n",
        "    label = label_vocabulary.itos[idx_class]\n",
        "    print(label, precision)\n",
        "\n",
        "if to_be_saved:\n",
        "    torch.save(model.state_dict(), root_folder+'/model/model_b={}_f1_{:0.4f}.pt'.format(str(model_b), scores[\"f1_macro\"])) # save the model state\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ixLrEGBaFjzn"
      },
      "source": [
        "Classes to evaluate like in the implementation.py file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gsk7GU5Z-Xmh"
      },
      "source": [
        "class PreprocessAB():\n",
        "    def __init__(self,sentences_list):\n",
        "        self.window_size = 40\n",
        "        self.sentences = self.load_data(sentences_list)\n",
        "        self.data = self.create_windows(self.sentences)\n",
        "        self.encoded_data = None\n",
        "        self.vocabulary = self.build_vocab()\n",
        "        self.index_dataset(self.vocabulary)\n",
        "\n",
        "    def remove_stopwords(self,sent: str) -> str:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        # remove punkt\n",
        "        others = \"–\" +\"—\" + \"−\" + \"’\" + \"”\" + \"“\" #These chars arent inside the standard punctuation\n",
        "        str_punkt = string.punctuation+ others\n",
        "        translator = str.maketrans(str_punkt, ' '*len(str_punkt)) \n",
        "        word_tokens = word_tokenize(sent.translate(translator)) \n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        return filtered_sentence\n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        sentences = []\n",
        "        for obj in list_of_sentences:\n",
        "            _sentence = []\n",
        "            # lemmatized = [lemmatizer.lemmatize(w)  for w in obj['text'].split(\" \")]\n",
        "            #lemmatized = self.remove_stopwords(\" \".join(lemmatized))\n",
        "            lemmatized = self.remove_stopwords(obj['text'])\n",
        "\n",
        "            for t in lemmatized:\n",
        "                token = {\"token\": t}\n",
        "                _sentence.append(token)\n",
        "            sentences.append(_sentence)\n",
        "        return sentences\n",
        "\n",
        "    def create_windows(self, sentences):\n",
        "\n",
        "        data = []\n",
        "        for sentence in sentences:\n",
        "            for i in range(0, len(sentence), self.window_size):\n",
        "                window = sentence[i:i+self.window_size]\n",
        "                if len(window) < self.window_size:\n",
        "                    window = window + [None]*(self.window_size - len(window))  # to match the same length of sentences\n",
        "                assert len(window) == self.window_size\n",
        "                data.append(window)\n",
        "        return data\n",
        "\n",
        "\n",
        "    def index_dataset(self, l_vocabulary):\n",
        "        self.encoded_data = list()\n",
        "        for i in range(len(self.data)):\n",
        "            # for each window\n",
        "            sentence = self.data[i]\n",
        "            encoded_sentence = torch.LongTensor(self.encode_text(sentence, l_vocabulary)).cpu()\n",
        "            \n",
        "           \n",
        "            self.encoded_data.append({\"inputs\":encoded_sentence})\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def encode_text(sentence:list, l_vocabulary:Vocab):\n",
        "        indices = list()\n",
        "        for w in sentence:\n",
        "            if w is None:\n",
        "                indices.append(l_vocabulary[\"<pad>\"])\n",
        "            elif w[\"token\"] in l_vocabulary.stoi: # vocabulary string to integer (necessary to search faster)\n",
        "                indices.append(l_vocabulary[w[\"token\"]])\n",
        "            else:\n",
        "                indices.append(l_vocabulary[\"<unk>\"])\n",
        "        return indices\n",
        "\n",
        "    \n",
        "    @staticmethod\n",
        "    def decode_output(outputs:torch.Tensor, l_label_vocabulary: Vocab):\n",
        "        max_indices = torch.argmax(outputs, -1).tolist() # shape = (batch_size, max_len)\n",
        "        predictions = list()\n",
        "        for indices in max_indices:\n",
        "            predictions.append([l_label_vocabulary.itos[i] for i in indices])\n",
        "        return predictions\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.encoded_data[idx]\n",
        "    \n",
        "    def get_raw_element(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "    def build_vocab(self, min_freq=1):\n",
        "        counter = Counter()\n",
        "        for i in tqdm(range(len(self.data))):\n",
        "            # for each token in the sentence viewed as a dictionary of items from the line\n",
        "            for token in self.get_raw_element(i):\n",
        "                if token is not None:\n",
        "                    counter[token[\"token\"]]+=1\n",
        "        #Counter({'the': 1046, 'and': 671, 'to': 604, etc....}\n",
        "        # we add special tokens for handling padding and unknown words at testing time.\n",
        "\n",
        "        return Vocab(counter, specials=['<pad>', '<unk>'], min_freq=min_freq)\n",
        "\n",
        "\n",
        "def predict_together_AB(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessAB(samples)\n",
        "    for i,test_elem in tqdm(enumerate(prep.encoded_data)):\n",
        "        json_pred = {\"targets\":[]}\n",
        "        lst,pred = [],[]\n",
        "        test_x = test_elem[\"inputs\"].to(\"cpu\")\n",
        "        logits, predictions = model(test_x.unsqueeze(0))\n",
        "        decoded_labels = prep.decode_output(logits, label_vocabulary)[0]\n",
        "        idxs = test_x.tolist()\n",
        "        for j,word in enumerate(decoded_labels):\n",
        "            if word.startswith(\"B\"):\n",
        "                json_pred[\"targets\"].append((prep.vocabulary.itos[idxs[j]],word.split(\"-\")[1]))\n",
        "            elif (word.startswith(\"I\")) and (decoded_labels[j-1].startswith(\"B\")):\n",
        "                try:\n",
        "                    last_tuple = json_pred['targets'][-1]\n",
        "                    words_tagged = last_tuple[0] + \" \" + prep.vocabulary.itos[idxs[j]]\n",
        "                    sent_tagged = last_tuple[1]\n",
        "                    json_pred['targets'][-1] = (words_tagged, sent_tagged)\n",
        "                except:\n",
        "                    words_tagged = prep.vocabulary.itos[idxs[j]]\n",
        "                    sent_tagged = word.split(\"-\")[1]\n",
        "                    json_pred['targets'].append((words_tagged, sent_tagged))\n",
        "            elif word.startswith(\"I\"):\n",
        "                json_pred[\"targets\"].append((prep.vocabulary.itos[idxs[j]],word.split(\"-\")[1]))\n",
        "\n",
        "        targets.append(json_pred)\n",
        "    #print(targets)\n",
        "    return targets\n",
        "\n",
        "\n",
        "\n",
        "def predict_a_then_b(samples):\n",
        "    targets = []\n",
        "    prep = PreprocessAB(samples)\n",
        "    for i,test_elem in tqdm(enumerate(prep.encoded_data)):\n",
        "        json_pred = {\"targets\":[]}\n",
        "        lst,pred = [],[]\n",
        "        test_x = test_elem[\"inputs\"].to(\"cpu\")\n",
        "        logits, predictions = model(test_x.unsqueeze(0))\n",
        "        decoded_labels = prep.decode_output(logits, label_vocabulary)[0]\n",
        "        idxs = test_x.tolist()\n",
        "        print(prep.sentences[i],test_x.tolist(),decoded_labels)\n",
        "        # for a,b in zip(decoded_labels,idxs):\n",
        "        #     print(a,\"\\t\",prep.vocabulary.itos[b])\n",
        "        for j,word in enumerate(decoded_labels):\n",
        "            if word == \"B\":\n",
        "                json_pred[\"targets\"].append((prep.vocabulary.itos[idxs[j]],\"positive\"))\n",
        "            elif (word == \"I\") and (decoded_labels[j-1] == \"B\"):\n",
        "                try:\n",
        "                    last_tuple = json_pred['targets'][-1]\n",
        "                    words_tagged = last_tuple[0] + \" \" + prep.vocabulary.itos[idxs[j]]\n",
        "                    sent_tagged = last_tuple[1]\n",
        "                    json_pred['targets'][-1] = (words_tagged, sent_tagged)\n",
        "                except:\n",
        "                    words_tagged = prep.vocabulary.itos[idxs[j]]\n",
        "                    sent_tagged = \"positive\"\n",
        "                    json_pred['targets'].append((words_tagged, sent_tagged))\n",
        "            elif word == \"I\":\n",
        "                json_pred[\"targets\"].append((prep.vocabulary.itos[idxs[j]],\"positive\"))\n",
        "\n",
        "        targets.append(json_pred)\n",
        "\n",
        "    return targets\n",
        "def load_data(data_path):\n",
        "    with open(data_path) as json_file:\n",
        "        list_of_sentences = json.load(json_file)\n",
        "    return list_of_sentences\n",
        "\n",
        "\n",
        "a = load_data(dataset_folder+\"/laptops_dev.json\")\n",
        "#a = a + load_data(dataset_folder+\"/restaurants_dev.json\")\n",
        "random.shuffle(a)\n",
        "model.cpu()\n",
        "#t = predictB(a[:30])\n",
        "t = predict_together_AB(a)\n",
        "for gt,pred in zip(a[:10],t[:10]):\n",
        "    print(gt['targets'],\"SEP\",pred['targets'])\n",
        "evaluate_extraction(a,t)\n",
        "evaluate_sentiment(a,t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFT5dm_5NYeP"
      },
      "source": [
        "# TASK B (Bi-LSTM (WiC))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNLb1VSIS3a8"
      },
      "source": [
        "##Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHfB_TUh3KZH"
      },
      "source": [
        "class TaskBDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, dataset_path: str):\n",
        "        self.data_store,self.sentences = self.load_data(dataset_path)\n",
        "        self.vocabulary = self.build_vocab(self.sentences)\n",
        "        self.convert_all_2_indices()\n",
        "        self.mlb = MultiLabelBinarizer()\n",
        "        self.encode_tags()\n",
        "\n",
        "\n",
        "    def encode_tags(self):\n",
        "        self.tags = self.mlb.fit_transform([c for (a,b,c) in self.data_store])\n",
        "        self.data_store = [(a,b, torch.tensor(self.tags[i]) ) for i,(a,b,c) in enumerate(self.data_store)]\n",
        "    \n",
        "    def remove_stopwords(self,sent: str) -> str:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        # remove punkt\n",
        "        others = \"–\" +\"—\" + \"−\" + \"’\" + \"”\" + \"“\" #These chars arent inside the standard punctuation\n",
        "        str_punkt = string.punctuation+ others\n",
        "        translator = str.maketrans(str_punkt, ' '*len(str_punkt)) \n",
        "        word_tokens = word_tokenize(sent.translate(translator)) \n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        return filtered_sentence\n",
        "\n",
        "    def load_data(self,data_path):\n",
        "        data_store,sentences = [],[]\n",
        "        with open(data_path) as json_file:\n",
        "            list_of_sentences = json.load(json_file)\n",
        "            for obj in list_of_sentences:\n",
        "                _sentence = []\n",
        "                #order the targets in order of apperance in the sentence and not alphabetical\n",
        "                obj['targets'] = sorted(obj['targets'], key=lambda x: x[0][0]) \n",
        "\n",
        "                sentiments = [obj['targets'][j][2] for j in range(len(obj['targets']))]\n",
        "                #for each target word construct a sentence putting start and end token inside the sentence\n",
        "                for i,targ_obj in enumerate(obj['targets']):\n",
        "                    #print(targ_obj)\n",
        "                    new_sent = obj['text'][:targ_obj[0][0]-1]+\" <START> \" + obj['text'][targ_obj[0][0]:targ_obj[0][1]] + \" <END>\" + obj['text'][targ_obj[0][1]:]\n",
        "                    new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                    new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))    \n",
        "                    index = self.find_indices(new_sent)\n",
        "                        \n",
        "                    sentences.append(new_sent)\n",
        "                    sentiments_converted = [sentiments[i]]\n",
        "                    data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "                #if no target then construct with a FAKE sentiment classified as NONE so no sentiment\n",
        "                if len(obj['targets'])==0:\n",
        "                    sentiments_converted= [\"NONE\"]\n",
        "                    new_sent = obj['text']\n",
        "                    new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                    new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))\n",
        "                    index = [0,0]\n",
        "                    sentences.append(new_sent)\n",
        "                    data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "            return data_store,sentences\n",
        "\n",
        "\n",
        "    def convert_all_2_indices(self):\n",
        "        self.data_store = [(self.sentence2indices(a),b,c) for (a,b,c) in self.data_store]\n",
        "    \n",
        "    def find_indices(self,new_sent):\n",
        "        splitted = new_sent.split(\" \")\n",
        "        indices = [i+1 for i,w in enumerate(splitted) if (w==\"START\") or (w==\"END\")]\n",
        "        indices[1] = indices[1]-1\n",
        "        return indices\n",
        "    \n",
        "    def build_vocab(self, dataset, min_freq=1):\n",
        "        counter = Counter()\n",
        "        for a in dataset:\n",
        "            for token in a.split(\" \"):\n",
        "                if token is not None:\n",
        "                    counter[token]+=1\n",
        "        #Counter({'the': 1046, 'and': 671, 'to': 604, etc....}\n",
        "        vocabulary = Vocab(counter, specials=['<pad>', '<unk>'], min_freq=min_freq)\n",
        "        vocabulary.load_vectors(\"glove.6B.50d\")\n",
        "        return vocabulary\n",
        "\n",
        "    def sentence2indices(self,sentence: str) -> torch.Tensor:\n",
        "        return torch.tensor([self.vocabulary[word] for word in sentence.split(' ') if word != ''], dtype=torch.long)\n",
        "\n",
        "    def decode_tag(self,tag):\n",
        "        return self.mlb.inverse_transform(tag.reshape(1,-1))\n",
        "    \n",
        "    def __len__(self) -> int:\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
        "        return self.data_store[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pvh938xOBro"
      },
      "source": [
        "class TaskBDataModule(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        data_train_path: str,\n",
        "        data_dev_path: str,\n",
        "        batch_size: int,\n",
        "        collate_fn=None\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.data_train_path = data_train_path\n",
        "        self.data_dev_path = data_dev_path\n",
        "        self.batch_size = batch_size\n",
        "        self.collate_fn = collate_fn\n",
        "\n",
        "        self.train_dataset = None\n",
        "        self.validation_dataset = None\n",
        "\n",
        "    def train_dataloader(self, *args, **kwargs) -> DataLoader:\n",
        "        self.train_dataset = TaskBDataset(self.data_train_path)\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, collate_fn=self.collate_fn)\n",
        "\n",
        "    def val_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
        "        self.validation_dataset = TaskBDataset(self.data_dev_path)\n",
        "        return DataLoader(self.validation_dataset, batch_size=self.batch_size,collate_fn=self.collate_fn)\n",
        "\n",
        "\n",
        "\n",
        "def rnn_collate_fn(data_elements: List[Tuple[torch.Tensor, list]] \n",
        ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    X = [de[0] for de in data_elements]  # list of index tensors\n",
        "    X = torch.nn.utils.rnn.pad_sequence(X, batch_first=True, padding_value=0)  #  shape (batch_size x max_seq_len)\n",
        "    \n",
        "    keyword_position = [de[1] for de in data_elements] # list of tuples indices where keyword is [[start keyword,end_keyword],[...]]\n",
        "\n",
        "    keyword_position = torch.nn.utils.rnn.pad_sequence(keyword_position, batch_first=True, padding_value=0) \n",
        "\n",
        "    y = [de[2] for de in data_elements]\n",
        "    y = torch.nn.utils.rnn.pad_sequence(y, batch_first=True, padding_value=-1) \n",
        "\n",
        "    return X, keyword_position, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KE1BtxsmBNJ"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "my_Ku2SAvnBc"
      },
      "source": [
        "Recurrent classifier definition with a customized forward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI7M_zasi1ol"
      },
      "source": [
        "class TaskBRecurrentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vectors_store: torch.Tensor,\n",
        "        n_hidden: int,\n",
        "        drop_prob: float,\n",
        "        bidir: bool,\n",
        "        n_layer_lstm: int,\n",
        "        vocab_size:int, \n",
        "        embedding_dim: int =100,\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "\n",
        "        # embedding layer\n",
        "        \n",
        "        self.embedding = torch.nn.Embedding.from_pretrained(vectors_store)\n",
        "        #self.embedding = nn.Embedding(vocab_size, embedding_dim) # hparams.vocab_size words in vocab, hparams.embedding_dim dimensional embeddings\n",
        "\n",
        "        self.n_hidden = n_hidden\n",
        "        # recurrent layer\n",
        "        self.lstm = torch.nn.LSTM(input_size=vectors_store.shape[1],\n",
        "                                  hidden_size=n_hidden,\n",
        "                                  num_layers=n_layer_lstm, \n",
        "                                  batch_first=True,\n",
        "                                  bidirectional=bidir)\n",
        "\n",
        "        # classification \n",
        "        if bidir:\n",
        "           n_hidden = n_hidden*2\n",
        "        self.lin1 = torch.nn.Linear(n_hidden, n_hidden)\n",
        "        self.classifier = torch.nn.Linear(n_hidden, 5)\n",
        "\n",
        "        self.loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        X: torch.Tensor, \n",
        "        indices_keyword: torch.Tensor, \n",
        "        y: Optional[torch.Tensor] = None\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "\n",
        "        embedding_out = self.embedding(X)\n",
        "        # recurrent encoding\n",
        "        lstm_output = self.lstm(embedding_out)[0]\n",
        "        \n",
        "        batch_size, seq_len, hidden_size = lstm_output.shape\n",
        "\n",
        "        #sequence of batch x seq_len vectors \n",
        "        flat_output = lstm_output.reshape(-1, hidden_size)\n",
        "        \n",
        "        # start offsets of each element in the batch\n",
        "        sequences_offsets = torch.arange(batch_size, device=self.device) * seq_len\n",
        "        \n",
        "        summary_vectors_indices_sent1 = self.get_indices_keyword(indices_keyword, sequences_offsets,0)\n",
        "        summary_vectors_indices_sent2 = self.get_indices_keyword(indices_keyword, sequences_offsets,1)\n",
        "        \n",
        "        # we retrieve the vector of the corrseponding states for the keyword given for each sentence.\n",
        "          \n",
        "        summary_vectors_sent1 = flat_output[summary_vectors_indices_sent1]\n",
        "        summary_vectors_sent2 = flat_output[summary_vectors_indices_sent2]\n",
        "        \n",
        "        # do the multiplication of these two vectors retrieved\n",
        "        summary_vectors = summary_vectors_sent1 * summary_vectors_sent2\n",
        "        \n",
        "        # feedforward MLP\n",
        "        out = self.lin1(summary_vectors)\n",
        "        out = F.leaky_relu(out)\n",
        "        \n",
        "        logits = self.classifier(out)\n",
        "        \n",
        "        pred = torch.argmax(logits, -1)\n",
        "        \n",
        "        result = {'logits': logits, 'pred': pred} \n",
        "\n",
        "        # compute loss\n",
        "        if y is not None:\n",
        "            #logits = logits.view(-1, logits.shape[-1])\n",
        "            #y = y.view(-1)\n",
        "            try:\n",
        "                loss = self.loss(logits, torch.tensor(y, dtype=torch.float))\n",
        "            except:\n",
        "                print(logits.shape,y.shape)\n",
        "            result['loss'] = loss\n",
        "        return result\n",
        "        \n",
        "       \n",
        "    def loss(self, pred, y):\n",
        "        return self.loss_fn(pred, y)\n",
        "   \n",
        "    '''\n",
        "    return the corresponding position of the indices of the keywords, for the sent_num passed, so the first if 0 is passed and the second if 1 is passed\n",
        "    summary  = [   0,   57,  114,  171,  228, ...] \n",
        "    indices_keywords = [ [ 6, 21],[ 4, 22],[ 6, 21],[ 4, 22], ...]\n",
        "    '''\n",
        "    def get_indices_keyword(self,indices_keywords: Sequence[tuple], summary: Sequence[int] ,sent_num: int) -> torch.Tensor:\n",
        "        tens_idx = torch.tensor([item[sent_num] for item in indices_keywords]).to(self.device)\n",
        "        return tens_idx + summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwunMH6fWNkI"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gyB77pPuAkLs"
      },
      "source": [
        "Trainer class that will handle the training phase for the RNN classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzBUPzpQzic_"
      },
      "source": [
        "class TaskBTrainer():\n",
        "    def __init__(self, model, optimizer, device, exp_details):\n",
        "\n",
        "        self.device = device\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.writer = SummaryWriter(comment=\"_\"+exp_details)\n",
        "        self.model.train()  # we are using this model for training\n",
        "        self.model.to(self.device)  # move model to GPU if available\n",
        "\n",
        "    def train(self, train_dataset, eval_dataset, epochs: int = 1, early_stopping: bool = False, early_stopping_patience:int = 3, to_be_saved: bool =False) -> float:\n",
        "\n",
        "        train_loss = 0.0\n",
        "       \n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            epoch_loss = 0.0\n",
        "            len_train = 0\n",
        "            \n",
        "            self.model.train()\n",
        "\n",
        "            # each element (sample) in train_dataset is a batch\n",
        "            for sample in train_dataset:\n",
        "                # inputs in the batch\n",
        "                inputs = sample[0].to(self.device)\n",
        "                # indices of keywords\n",
        "                idx_start = sample[1].to(self.device)\n",
        "                # outputs in the batch\n",
        "                targets = sample[2].to(self.device)\n",
        "\n",
        "                forward_result = self.model(inputs, idx_start, targets)\n",
        "\n",
        "                loss = forward_result['loss']\n",
        "                \n",
        "                loss.backward()  #  backpropagate the loss\n",
        "                # updates the parameters\n",
        "                #Clips gradient norm of an iterable of parameters.\n",
        "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), CLIP_GRAD)\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "                \n",
        "                epoch_loss += loss.item()\n",
        "                len_train += 1\n",
        "            avg_epoch_loss = epoch_loss / len_train\n",
        "\n",
        "            \n",
        "            train_loss += avg_epoch_loss\n",
        "\n",
        "\n",
        "            print(avg_epoch_loss)\n",
        "            self.writer.flush()\n",
        "    \n",
        "        return train_loss/(epoch+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ysl5lG_pxhY9"
      },
      "source": [
        "Loading of the handler for the dataset and choose of the batch size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeaTHJCvvqCh"
      },
      "source": [
        "BATCH_SIZE = 40 #@param {type:\"slider\", min:8, max:64, step:4}\n",
        "\n",
        "sentences_rnn_dm = TaskBDataModule(\n",
        "    data_train_path=dataset_folder+'/laptops_train.json',\n",
        "    data_dev_path=dataset_folder+'/laptops_dev.json',\n",
        "    batch_size=BATCH_SIZE,\n",
        "    collate_fn = rnn_collate_fn,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o9d52ZOxdiI"
      },
      "source": [
        "Hyperparameter setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j51GSfZSvyTv"
      },
      "source": [
        "#@title Setup of Hyper-parameters{ run: \"auto\" }\n",
        "\n",
        "n_hidden=82 #@param {type:\"slider\", min:50, max:300, step:16}\n",
        "drop_prob=0.15 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "bidir = True #@param [\"True\", \"False\"] {type:\"raw\"}\n",
        "learning_rate = 0.0001 #@param {type:\"slider\", min:0.00001, max:0.001, step:0.00001}\n",
        "epochs = 25 #@param {type:\"slider\", min:10, max:100, step:10}\n",
        "n_layer_lstm = 2 #@param {type:\"slider\", min:1, max:4, step:1}\n",
        "CLIP_GRAD = 2 #@param {type:\"slider\", min:1, max:10, step:1}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YxReoMvS70jb"
      },
      "source": [
        "Start the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmaXIR2DjtCg"
      },
      "source": [
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "#loading of the datasets\n",
        "train_dataloader = sentences_rnn_dm.train_dataloader()\n",
        "val_dataloader = sentences_rnn_dm.val_dataloader()\n",
        "\n",
        "\n",
        "task_b_classifier = TaskBRecurrentClassifier(sentences_rnn_dm.train_dataset.vocabulary.vectors, n_hidden=n_hidden,drop_prob=drop_prob, bidir = bidir, n_layer_lstm = n_layer_lstm, vocab_size=len(sentences_rnn_dm.train_dataset.vocabulary),embedding_dim=100)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "#define the optimizer\n",
        "optimizer = torch.optim.Adam(task_b_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "# string to indetify the model once saved or in the graphs\n",
        "exp_details=\"mul_leakyrelu_\" + str(drop_prob) + \"drop_\"+str(n_hidden) +\"hidden_\"+str(learning_rate) +\"lr_\" + str(BATCH_SIZE) +\"batch_\" + str(n_layer_lstm) +\"lstmLayer_\" + str(CLIP_GRAD) +\"clipGrad\"\n",
        "\n",
        "trainer = TaskBTrainer(task_b_classifier, optimizer, device, exp_details)\n",
        "\n",
        "avg_train_loss= trainer.train(train_dataloader, val_dataloader, epochs=epochs, early_stopping=False, early_stopping_patience=6, to_be_saved = True)\n",
        "print(\" avg_train_loss={}\\n \".format(avg_train_loss))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ICC3g_Wu1kjn"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxP4Xzq_HtLj"
      },
      "source": [
        "general evaluation taking in consideration also the NONE tag and also the fact that there are sentences with multiple tags that now are splitted"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TloazNlkwqxw"
      },
      "source": [
        " def eval_metrics(eval_dataset):\n",
        "    task_b_classifier.eval()\n",
        "    task_b_classifier.cuda()\n",
        "    pred_outs, true_labels = [],[]\n",
        "    for sample in eval_dataset:\n",
        "        # inputs in the batch\n",
        "        inputs = sample[0].to(device)\n",
        "        idx_start = sample[1].to(device)\n",
        "\n",
        "        # outputs in the batch\n",
        "        targets = sample[2].to(device)\n",
        "        with torch.no_grad():\n",
        "\n",
        "            forward_result = task_b_classifier(inputs, idx_start,targets)\n",
        "            loss = forward_result['loss']\n",
        "            pred_out = torch.sigmoid(forward_result['logits'])\n",
        "        \n",
        "            pred_out = pred_out.detach().cpu().numpy()\n",
        "            y_true = targets.cpu().numpy()\n",
        "\n",
        "        pred_outs.append(pred_out)\n",
        "        true_labels.append(y_true)\n",
        "\n",
        "    flat_pred_outs = np.concatenate(pred_outs, axis=0)\n",
        "\n",
        "    # Combine the correct labels for each batch into a single list.\n",
        "    flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "    return flat_pred_outs,flat_true_labels\n",
        "\n",
        "\n",
        "#find the higher probability of the returned logits and set it to 1\n",
        "def classify(pred_prob):\n",
        "    y_pred = []\n",
        "    for tag_label_row in pred_prob:\n",
        "        temp=[]\n",
        "        max_prob = max(tag_label_row)\n",
        "        for tag_label in tag_label_row:\n",
        "            if tag_label == max_prob:\n",
        "                temp.append(1)\n",
        "            else:\n",
        "                temp.append(0) \n",
        "        y_pred.append(temp)\n",
        "    return y_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH6MD17T9Q2L"
      },
      "source": [
        "flat_pred_outs,flat_true_labels= eval_metrics(val_dataloader)\n",
        "y_true = flat_true_labels.ravel()\n",
        "\n",
        "y_pred_labels = classify(flat_pred_outs)\n",
        "\n",
        "y_pred = np.array(y_pred_labels).ravel() # Flatten\n",
        "\n",
        "metr = {}\n",
        "metr['f1'] = f1_score(y_true,y_pred, average=\"macro\")\n",
        "\n",
        "print(\"F1 = \",metr['f1'])\n",
        "\n",
        "y_pred = sentences_rnn_dm.validation_dataset.mlb.inverse_transform(np.array(y_pred_labels))\n",
        "y_act = sentences_rnn_dm.validation_dataset.mlb.inverse_transform(flat_true_labels)\n",
        "\n",
        "df = pd.DataFrame({'Sentence':sentences_rnn_dm.validation_dataset.sentences,'Actual Tags':y_act,'Predicted Tags':y_pred})\n",
        "pd.set_option('display.max_rows', 30)\n",
        "df.head(30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YZoRkeV-WvS"
      },
      "source": [
        "### Evaluation for implementation.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sdak0rlf-Wvc"
      },
      "source": [
        "class PreprocessBWiC():\n",
        "    def __init__(self, sentences):\n",
        "        self.data_store,self.sentences,self.targets = self.load_data(sentences)\n",
        "        self.vocabulary = self.build_vocab(self.sentences)\n",
        "        self.convert_all_2_indices()\n",
        "        # self.tags = [[\"neutral\",\"negative\", \"conflict\", \"positive\", \"NONE\"]]\n",
        "        # self.mlb = MultiLabelBinarizer()\n",
        "        # self.mlb.fit_transform(self.tags)\n",
        "        self.mlb = sentences_rnn_dm.validation_dataset.mlb\n",
        "    def remove_stopwords(self,sent: str) -> str:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        # remove punkt\n",
        "        others = \"–\" +\"—\" + \"−\" + \"’\" + \"”\" + \"“\" #These chars arent inside the standard punctuation\n",
        "        str_punkt = string.punctuation+ others\n",
        "        translator = str.maketrans(str_punkt, ' '*len(str_punkt)) \n",
        "        word_tokens = word_tokenize(sent.translate(translator)) \n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        return filtered_sentence\n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        data_store,sentences,targets = [],[],[]\n",
        "        for obj in list_of_sentences:\n",
        "            _sentence = []\n",
        "            obj['targets'] = sorted(obj['targets'], key=lambda x: x[0][0])\n",
        "            sentiments = [obj['targets'][j][2] for j in range(len(obj['targets']))]\n",
        "\n",
        "            for i,targ_obj in enumerate(obj['targets']):\n",
        "                #print(targ_obj)\n",
        "                new_sent = obj['text'][:targ_obj[0][0]-1]+\" <START> \" + obj['text'][targ_obj[0][0]:targ_obj[0][1]] + \" <END>\" + obj['text'][targ_obj[0][1]:]\n",
        "                new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))    \n",
        "                index = self.find_indices(new_sent)\n",
        "                    \n",
        "                sentences.append(new_sent)\n",
        "                sentiments_converted = [sentiments[i]]\n",
        "                targets.append([(targ[1], \"\") for j,targ in enumerate(obj['targets'])])\n",
        "\n",
        "                data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "\n",
        "            if len(obj['targets'])==0:\n",
        "                sentiments_converted= [\"NONE\"]\n",
        "                targets.append([(targ[1], \"\") for j,targ in enumerate(obj['targets'])])\n",
        "\n",
        "                new_sent = obj['text']\n",
        "                # new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                # new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))\n",
        "                index = [0,0]\n",
        "                sentences.append(new_sent)\n",
        "                data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "        \n",
        "        return data_store,sentences,targets\n",
        "\n",
        "\n",
        "    def convert_all_2_indices(self):\n",
        "        self.data_store = [(self.sentence2indices(a),b,c) for (a,b,c) in self.data_store]\n",
        "    \n",
        "    def find_indices(self,new_sent):\n",
        "        splitted = new_sent.split(\" \")\n",
        "        indices = [i+1 for i,w in enumerate(splitted) if (w==\"START\") or (w==\"END\")]\n",
        "        indices[1] = indices[1]-1\n",
        "        return indices\n",
        "                \n",
        "    \n",
        "    def build_vocab(self, dataset, min_freq=1):\n",
        "        counter = Counter()\n",
        "        for a in dataset:\n",
        "            # for each token in the sentence viewed as a dictionary of items from the line\n",
        "            for token in a.split(\" \"):\n",
        "                if token is not None:\n",
        "                    counter[token]+=1\n",
        "        #Counter({'the': 1046, 'and': 671, 'to': 604, etc....}\n",
        "        # we add special tokens for handling padding and unknown words at testing time.\n",
        "        vocabulary = Vocab(counter, specials=['<pad>', '<unk>'], min_freq=min_freq)\n",
        "        #vocabulary.load_vectors(\"glove.6B.50d\")\n",
        "        return vocabulary\n",
        "\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
        "        return self.data_store[idx]\n",
        "\n",
        "    def sentence2indices(self,sentence: str) -> torch.Tensor:\n",
        "        return torch.tensor([self.vocabulary[word] for word in sentence.split(' ') if word != ''], dtype=torch.long)\n",
        "\n",
        "    def decode_tag(self,tag):\n",
        "        return self.mlb.inverse_transform(tag.reshape(1,-1))\n",
        "    \n",
        "    \n",
        "def rnn_collate_fn(data_elements: List[Tuple[torch.Tensor, list]] # list of (x, y,z) pairs\n",
        ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "    X = [de[0] for de in data_elements]  # list of index tensors\n",
        "    X = torch.nn.utils.rnn.pad_sequence(X, batch_first=True, padding_value=0)  #  shape (batch_size x max_seq_len)\n",
        "    \n",
        "    keyword_position = [de[1] for de in data_elements] # list of tuples indices where keyword is [[1st sent, 2nd sent]]\n",
        "\n",
        "    keyword_position = torch.nn.utils.rnn.pad_sequence(keyword_position, batch_first=True, padding_value=0) \n",
        "\n",
        "\n",
        "\n",
        "    return X, keyword_position\n",
        "\n",
        "def classify(pred_prob):\n",
        "    y_pred = []\n",
        "\n",
        "    for tag_label_row in pred_prob:\n",
        "        temp=[]\n",
        "        max_prob = max(tag_label_row)\n",
        "        for tag_label in tag_label_row:\n",
        "            if tag_label == max_prob:\n",
        "                temp.append(1) \n",
        "            else:\n",
        "                temp.append(0) \n",
        "        y_pred.append(temp)\n",
        "\n",
        "    return y_pred\n",
        "    \n",
        "def predictBBNEW(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessBWiC(samples)\n",
        "    task_b_classifier.eval()\n",
        "    i = 0\n",
        "    task_b_classifier.cpu()\n",
        "    print(len(prep.data_store))\n",
        "    while i < len(prep.data_store):\n",
        "        cont = len(prep.targets[i])\n",
        "        json_pred = {\"targets\":prep.targets[i]}\n",
        "        if cont==0:\n",
        "            i+=1\n",
        "        sentiments = []\n",
        "        while cont > 0:\n",
        "            inputs,idx_start = rnn_collate_fn([prep.data_store[i]]) # inputs in the batch\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                forward_result = task_b_classifier(inputs.cpu(), idx_start.cpu())\n",
        "                pred_out = torch.sigmoid(forward_result['logits'])\n",
        "                pred_out = pred_out.detach().cpu().numpy()\n",
        "\n",
        "            y_pred_labels = classify(pred_out)\n",
        "            y_pred = prep.mlb.inverse_transform(np.array(y_pred_labels))\n",
        "            for pred in y_pred:\n",
        "                sentiments += list(pred)\n",
        "            cont-=1\n",
        "            i+=1\n",
        "        for k,targ in enumerate(json_pred['targets']):\n",
        "            try:\n",
        "                if sentiments[k] != \"NONE\":\n",
        "                    json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],sentiments[k])\n",
        "            except:\n",
        "                json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],\"conflict\")\n",
        "        targets.append(json_pred)\n",
        "    return targets\n",
        "\n",
        "a = load_data(dataset_folder+\"/laptops_dev.json\")\n",
        "random.shuffle(a)\n",
        "t = predictBBNEW(a)\n",
        "for x,y in zip(a[:30],t[:30]):\n",
        "    print(x['targets'],\"SEP\",y['targets'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGPgX7edIMpb"
      },
      "source": [
        "evaluate_sentiment(a,t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7cdZZOGT-3y"
      },
      "source": [
        "# TASK A-B (BERT for token classification fine tuning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzeLLprlNkYo"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qga1F6PWMAJ7"
      },
      "source": [
        "Define of the transfomers dataset class, this class will load raw data and then encode the labels into tag and using the Bert tokenizer, tokenize the sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_Uhysd9XzAS"
      },
      "source": [
        "class TaskABDataset(Dataset):\n",
        "    def __init__(self, path,path2, model_b):\n",
        "        self.model_b = model_b\n",
        "        self.texts, self.tags = self.load_data(path)\n",
        "        texts2,tags2 = self.load_data(path2)\n",
        "        self.texts = self.texts + texts2\n",
        "        self.tags = self.tags + tags2\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(bert_model)\n",
        "        self.encodings = self.tokenizer(self.texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "        self.tag2id = {'O': 0, 'neutral': 1, 'positive': 2, 'negative': 3, 'conflict': 4}\n",
        "        self.id2tag = {0: 'O', 1: 'neutral', 2: 'positive', 3: 'negative', 4: 'conflict'}\n",
        "        if model_AB:\n",
        "            self.tag2id = {'B-conflict': 1, 'B-negative': 5, 'B-neutral': 2, 'B-positive': 4, 'I-conflict': 6, 'I-negative': 7, 'I-neutral': 8, 'I-positive': 3, 'O': 0}\n",
        "            self.id2tag = {0: 'O', 1: 'B-conflict', 2: 'B-neutral', 3: 'I-positive', 4: 'B-positive', 5: 'B-negative', 6: 'I-conflict', 7: 'I-negative', 8: 'I-neutral'}\n",
        "        if not model_b:\n",
        "            self.tag2id = {'O': 0, 'B': 1, 'I': 2}\n",
        "            self.id2tag = {0: 'O', 1: 'B', 2: 'I'}\n",
        "        self.labels = self.encode_tags(self.tags, self.encodings)\n",
        "        \n",
        "\n",
        "    def load_data(self,data_path):\n",
        "        sentences,texts,tags = [], [], []\n",
        "        with open(data_path) as json_file:\n",
        "            list_of_sentences = json.load(json_file)\n",
        "            for obj in list_of_sentences:\n",
        "                _sentence = []\n",
        "                sent = obj['text']\n",
        "                if LOWERED:\n",
        "                    sent = obj['text'].lower()\n",
        "                for t in tokenizer.tokenize(sent):\n",
        "                    ne_label = \"O\"\n",
        "                    sentiment = \"\"\n",
        "                    for i in range(len(obj['targets'])):\n",
        "                        targ = obj['targets'][i][1]\n",
        "                        if LOWERED:\n",
        "                            targ = obj['targets'][i][1].lower()\n",
        "                        if t in targ and len(t)>2:\n",
        "                            #if its first word i.e. \"battery life\" (battery)\n",
        "                            ne_label = \"B\" if t == targ.split(\" \")[0] else \"I\"\n",
        "                            #if for any reason the I tag is assigned but the word before its not a B\n",
        "                            try:\n",
        "                                if ne_label == \"I\" and _sentence[-1][\"ne_label\"] == \"O\":\n",
        "                                    ne_label = \"O\"\n",
        "                            except:\n",
        "                                pass\n",
        "                            sentiment = obj['targets'][i][2]\n",
        "                            if self.model_b and ne_label != \"O\":\n",
        "                                ne_label = sentiment #ne_label +\"-\"+sentiment\n",
        "                    token = {\"token\": t, \"ne_label\": ne_label , \"sentiment\" :sentiment}\n",
        "                    _sentence.append(token)\n",
        "                sentences.append(_sentence)\n",
        "\n",
        "            for elem in sentences:\n",
        "                texts.append([tok['token'] for tok in elem])\n",
        "                tags.append([tag['ne_label'] for tag in elem])\n",
        "            return texts, tags\n",
        "    \n",
        "    def encode_tags(self,tags, encodings):\n",
        "        labels = [[self.tag2id[tag] for tag in doc] for doc in tags]\n",
        "        encoded_labels = []\n",
        "        for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
        "            # create an empty array of -100\n",
        "            doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
        "            arr_offset = np.array(doc_offset)\n",
        "\n",
        "            try:\n",
        "                # set labels whose first offset position is 0 and the second is not 0\n",
        "                doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
        "                encoded_labels.append(doc_enc_labels.tolist())\n",
        "            except:\n",
        "                print(doc_labels, doc_offset)\n",
        "\n",
        "        return encoded_labels\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        #item['text'] = self.texts[idx] + [\"<end>\"] *(100-len(self.texts[idx]))\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztFb0FZYHAYl"
      },
      "source": [
        "class DataModuleTaskAB(pl.LightningDataModule):\n",
        "    def __init__(self, training_file, training_file2, dev_file, dev_file2, model_b=None):\n",
        "        super().__init__()\n",
        "        self.training_file = training_file\n",
        "        self.dev_file = dev_file\n",
        "        self.training_file2 = training_file2\n",
        "        self.dev_file2 = dev_file2\n",
        "        self.model_b = model_b\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "      self.trainingset = TaskABDataset(self.training_file, self.training_file2, self.model_b)\n",
        "      self.devset = TaskABDataset(self.dev_file, self.dev_file2, self.model_b)\n",
        "          \n",
        "    def train_dataloader(self):\n",
        "      return DataLoader(self.trainingset, batch_size=64)\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.devset, batch_size=64)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKX4GS2GIJxL"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG9yN61dIqjo"
      },
      "source": [
        "Lightning module wrapping around pretrained bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD8kBRsdII4_"
      },
      "source": [
        "class TaskABModel(pl.LightningModule):\n",
        "    def __init__(self, device,  comments=\"\",*args, **kwargs):\n",
        "        super(TaskABModel, self).__init__(*args, **kwargs)      \n",
        "        self.model = BertForTokenClassification.from_pretrained(bert_model, num_labels=5 if model_b else 3, output_hidden_states = True)\n",
        "        \n",
        "        self.writer = SummaryWriter(comment=comments+\"_modelb=\"+str(model_b))\n",
        "        self.epoch_t, self.epoch_ev = -1,-1\n",
        "        self.model.to(device)\n",
        "        self.save_hyperparameters()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, labels=None):\n",
        "        outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)        \n",
        "        return outputs\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        self.model.train()\n",
        "        input_ids = batch['input_ids'].to(self.device)\n",
        "        attention_mask = batch['attention_mask'].to(self.device)\n",
        "        labels = batch['labels'].to(self.device)\n",
        "\n",
        "        outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "\n",
        "        # Log it:\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        if self.epoch_t != self.current_epoch:\n",
        "            self.epoch_t = self.current_epoch\n",
        "            self.writer.add_scalar(\"train/loss\", loss, self.current_epoch)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            input_ids = batch['input_ids'].to(self.device)\n",
        "            attention_mask = batch['attention_mask'].to(self.device)\n",
        "            labels = batch['labels'].to(self.device)\n",
        "            outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            sample_loss = outputs[0]\n",
        "        self.log('valid_loss', sample_loss, prog_bar=True)\n",
        "        \n",
        "        if self.epoch_ev != self.current_epoch:\n",
        "            self.epoch_ev = self.current_epoch\n",
        "            self.writer.add_scalar(\"eval/loss\", sample_loss, self.current_epoch)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.parameters(), lr=2e-5)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkoCFfmtNajs"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SspVee8DX7NC"
      },
      "source": [
        "Declaration of the datasets, dataloaders and start of the training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLksR0GPL37w"
      },
      "source": [
        "data_module = DataModuleTaskAB(dataset_folder+\"/laptops_train.json\",dataset_folder+\"/restaurants_train.json\",dataset_folder+\"/laptops_dev.json\",dataset_folder+\"/restaurants_dev.json\",model_b)\n",
        "trainer = pl.Trainer(gpus=1, val_check_interval=1.0, max_epochs=5)\n",
        "model = TaskABModel(device,\"testAB_distilbert\")\n",
        "trainer.fit(model, datamodule=data_module)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GDlN5HvNz5o"
      },
      "source": [
        "Save the model and the id2tag correspondant\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAOR0KOb4ZKG"
      },
      "source": [
        "scores = {\"f1_macro\": 71.4}\n",
        "#torch.save(model.state_dict(), root_folder+'/model/model_A={}_f1_{:0.4f}.pt'.format(str(model_b), scores[\"f1_macro\"])) # save the model state\n",
        "# with open(root_folder+'/model/model_AB_together={}_f1_{:0.4f}.json'.format(str(model_b), scores[\"f1_macro\"]), 'w') as outfile:\n",
        "#     json.dump(val_dataset.id2tag, outfile)\n",
        "trainer.save_checkpoint(root_folder+\"/model/taskA_\"+str(scores[\"f1_macro\"])+\".ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCwLdySOM9it"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VN2i1zyOlX03"
      },
      "source": [
        "def reconstruct_original_logits(text,logits,tokenizer):\n",
        "    offset = tokenizer(text, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)['offset_mapping']\n",
        "    new_logits = list()\n",
        "    for i, tup in enumerate(offset):\n",
        "        if tup[0] == 0:\n",
        "            new_logits.append(logits[i])\n",
        "    return new_logits\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1ja43QlEEt_"
      },
      "source": [
        "# modelB = TaskBModel.load_from_checkpoint(root_folder+\"/model/taskB.ckpt\",device=device)\n",
        "# modelB.eval()\n",
        "\n",
        "# modelA = TaskABModel.load_from_checkpoint(root_folder+\"/model/taskA_71.4.ckpt\",device = device)\n",
        "# modelA.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kiGlYlt9DiaM"
      },
      "source": [
        "#### Model B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "896ZmUjE6GPh"
      },
      "source": [
        "class PreprocessB():\n",
        "    def __init__(self, sentences):\n",
        "        self.texts, self.tags = self.load_data(sentences)\n",
        "        self.tokenizer = DistilBertTokenizerFast.from_pretrained(bert_model)\n",
        "        self.encodings = self.tokenizer(self.texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "        self.tag2id = {'O': 0, 'neutral': 1, 'positive': 2, 'negative': 3, 'conflict': 4}\n",
        "        self.id2tag = {0: 'O', 1: 'neutral', 2: 'positive', 3: 'negative', 4: 'conflict'}\n",
        "                \n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        sentences,texts,tags = [], [], []\n",
        "        for obj in list_of_sentences:\n",
        "            _sentence = []\n",
        "            for t in tokenizer.tokenize(obj['text']):\n",
        "                ne_label =\"O\"\n",
        "                for i in range(len(obj['targets'])):\n",
        "                    if t in obj['targets'][i][1]: #if target word\n",
        "                        ne_label = obj['targets'][i][1]\n",
        "                        break\n",
        "                        \n",
        "                token = {\"token\": t, \"ne_label\": ne_label}\n",
        "                _sentence.append(token)\n",
        "\n",
        "            sentences.append(_sentence)\n",
        "\n",
        "        for i,elem in enumerate(sentences):\n",
        "            texts.append([tok['token'] for tok in elem])\n",
        "            #new_lst = list()\n",
        "            tags.append([(targ[1], \"\") for j,targ in enumerate(list_of_sentences[i]['targets'])])\n",
        "            #print(tags)\n",
        "            # for tag in elem:\n",
        "            #     if tag['ne_label'] != \"O\" and tag['ne_label'] not in new_lst:\n",
        "            #         new_lst.append(tag['ne_label'])\n",
        "            # tags.append(new_lst)\n",
        "        return texts, tags\n",
        "    \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "def predictB(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessB(samples)\n",
        "    for i,encode in enumerate(prep.encodings['input_ids']):\n",
        "        json_pred = {\"targets\":prep.tags[i]}\n",
        "        lst,pred = [],[]\n",
        "        ids = torch.unsqueeze(torch.tensor(encode),0)\n",
        "        attention_mask = torch.unsqueeze(torch.tensor(prep.encodings['attention_mask'][i]),0)\n",
        "\n",
        "        logits = model(torch.tensor(ids).to(\"cuda\"), torch.tensor(attention_mask).cuda())[\"logits\"]\n",
        "        for id in logits[0].argmax(1):\n",
        "            lst.append(id.item())\n",
        "        p = reconstruct_original_logits(prep.texts[i], lst,prep.tokenizer)[1:-1]\n",
        "        idtotag = [prep.id2tag[raw_pred] for raw_pred in p]\n",
        "        sentiments = []\n",
        "        # for j,sentiment in enumerate(idtotag):\n",
        "        #     if (sentiment != \"O\"):\n",
        "        #         try:\n",
        "        #             if (idtotag[j+1] == \"O\"):\n",
        "        #                 sentiments.append(sentiment)\n",
        "        #                 #print(prep.texts[i][j],sentiment)\n",
        "        #         except:\n",
        "        #             sentiments.append(sentiment)\n",
        "        #             #print(prep.texts[i][j],sentiment)\n",
        "\n",
        "                \n",
        "        # for k,targ in enumerate(json_pred['targets']):\n",
        "        #     try:\n",
        "        #         json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],sentiments[k])\n",
        "        #     except:\n",
        "        #         print(prep.texts[i],idtotag)\n",
        "        #         json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],\"conflict\")\n",
        "        idd = 0\n",
        "        if (len(json_pred['targets'])>0):\n",
        "            for word, sentiment in zip(prep.texts[i],idtotag):\n",
        "                if word in json_pred[\"targets\"][idd][0]:\n",
        "                    if sentiment !=\"O\": \n",
        "                        json_pred[\"targets\"][idd] = (json_pred[\"targets\"][idd][0],sentiment)\n",
        "                    else:\n",
        "                        json_pred[\"targets\"][idd] = (json_pred[\"targets\"][idd][0],\"positive\") \n",
        "                    idd+=1\n",
        "                    if idd==len(json_pred[\"targets\"]):\n",
        "                        break\n",
        "        targets.append(json_pred)\n",
        "    return targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABh7UkQBDlKt"
      },
      "source": [
        "####Model A-->B"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dn0Gw3f1zf_"
      },
      "source": [
        "class PreprocessAB():\n",
        "    def __init__(self, sentences):\n",
        "        self.texts = self.load_data(sentences)\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(bert_model)\n",
        "        self.encodings = self.tokenizer(self.texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "        \n",
        "        self.tag2id = {'O': 0, 'B': 1, 'I': 2}\n",
        "        self.id2tag = {0: 'O', 1: 'B', 2: 'I'}\n",
        "       \n",
        "                \n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        sentences,texts = [], []\n",
        "        for obj in list_of_sentences:\n",
        "            _sentence = []\n",
        "            for t in tokenizer.tokenize(obj['text']):\n",
        "                token = {\"token\": t}\n",
        "                _sentence.append(token)\n",
        "            sentences.append(_sentence)\n",
        "\n",
        "        for elem in sentences:\n",
        "            texts.append([tok['token'] for tok in elem])\n",
        "        return texts\n",
        "    \n",
        "    \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "def predict_A_then_B(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessAB(samples)\n",
        "    bt_tokenizer = DistilBertTokenizerFast.from_pretrained(bert_model)\n",
        "\n",
        "    for i,encode in tqdm(enumerate(prep.encodings['input_ids'])):\n",
        "        json_pred = {\"targets\":[]}\n",
        "        lst,pred = [],[]\n",
        "\n",
        "        ids = torch.unsqueeze(torch.tensor(encode),0)\n",
        "        attention_mask = torch.unsqueeze(torch.tensor(prep.encodings['attention_mask'][i]),0)\n",
        "        with torch.no_grad():\n",
        "            try:\n",
        "                logits = modelA(torch.tensor(ids).to(device), torch.tensor(attention_mask).to(device))[\"logits\"]\n",
        "            except Exception as e:\n",
        "                #print(encode,prep.texts[i])\n",
        "                print(e)\n",
        "                targets.append(json_pred)\n",
        "                continue\n",
        "            for id in logits[0].argmax(1):\n",
        "                lst.append(id.item())\n",
        "            p = reconstruct_original_logits(prep.texts[i], lst,prep.tokenizer)[1:-1]\n",
        "            idtotag = [prep.id2tag[raw_pred] for raw_pred in p]\n",
        "            idx_tgt_list = []\n",
        "        for j,word in enumerate(idtotag):\n",
        "            if word == \"B\":\n",
        "                json_pred[\"targets\"].append((prep.texts[i][j],\"positive\"))\n",
        "                start = return_indices(prep.texts[i],j)\n",
        "                idx_tgt_list.append([start, start + len(prep.texts[i][j])])\n",
        "            elif (word == \"I\") and (idtotag[j-1] == \"B\"):\n",
        "                try:\n",
        "                    last_tuple = json_pred['targets'][-1]\n",
        "                    words_tagged = last_tuple[0] + \" \" + prep.texts[i][j]\n",
        "                    sent_tagged = last_tuple[1]\n",
        "                    json_pred['targets'][-1] = (words_tagged, sent_tagged)\n",
        "                    \n",
        "                    idx_tgt_list[-1][1] = idx_tgt_list[-1][1] + len(prep.texts[i][j]) +1\n",
        "                except:\n",
        "                    words_tagged = prep.texts[i][j]\n",
        "                    sent_tagged = \"positive\"\n",
        "                    json_pred['targets'].append((words_tagged, sent_tagged))\n",
        "                    start = return_indices(prep.texts[i],j)\n",
        "                    idx_tgt_list.append([start, start + len(prep.texts[i][j])])\n",
        "\n",
        "            elif word == \"I\":\n",
        "                json_pred[\"targets\"].append((prep.texts[i][j],\"positive\"))\n",
        "                start = return_indices(prep.texts[i],j)\n",
        "                idx_tgt_list.append([start, start + len(prep.texts[i][j])])\n",
        "        batches = create_B_batches(prep.texts[i],json_pred,idx_tgt_list,bt_tokenizer)\n",
        "        json_pred_sent = predict_B_after_A_2(json_pred,batches)\n",
        "        targets.append(json_pred_sent)\n",
        "    return targets\n",
        "\n",
        "\n",
        "\n",
        "def predict_B_after_A_2(json_pred,batches):\n",
        "    cont = len(json_pred['targets'])\n",
        "\n",
        "    id2tag = {0: 'NONE', 1: 'conflict', 2: 'negative', 3: 'neutral', 4: 'positive'}\n",
        "\n",
        "    sentiments = []\n",
        "    i = 0\n",
        "    while cont > 0:\n",
        "        #inputs,idx_start = rnn_collate_fn([prep.data_store[i]]) # inputs in the batch\n",
        "        batch = batches[i]\n",
        "        input_ids = torch.unsqueeze(batch['input_ids'],0).to(device)\n",
        "        attention_mask = torch.unsqueeze(batch['attention_mask'],0).to(device)\n",
        "        indices_keyword = torch.unsqueeze(batch['indices'],0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = modelB.forward(input_ids, attention_mask=attention_mask, indices_keyword=indices_keyword)\n",
        "            logits = out['logits']\n",
        "\n",
        "        y_pred_labels = torch.argmax(logits, axis=-1)\n",
        "        pred_label = y_pred_labels.tolist()[0]\n",
        "        y_pred = id2tag[pred_label]\n",
        "        sentiments.append(y_pred)\n",
        "        cont-=1\n",
        "        i+=1\n",
        "    for k,targ in enumerate(json_pred['targets']):\n",
        "        try:\n",
        "            if sentiments[k] != \"NONE\":\n",
        "                json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],sentiments[k])\n",
        "        except:\n",
        "            json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],\"conflict\")\n",
        "\n",
        "    return json_pred\n",
        "\n",
        "\n",
        "def return_indices(frase_splitt,word_stop):\n",
        "    c = 0\n",
        "    for i,w in enumerate(frase_splitt):\n",
        "        if word_stop == i:\n",
        "            return c\n",
        "        c+=len(\" \"+w)\n",
        "\n",
        "def create_B_batches(text,targ_list,idx_list,bt_tokenizer):\n",
        "    #id2tag = {0: 'NONE', 1: 'conflict', 2: 'negative', 3: 'neutral', 4: 'positive'}\n",
        "    #tokenizer = BertTokenizerFast.from_pretrained(bert_model)\n",
        "    #encodings = self.tokenizer(self.sentences, is_split_into_words=False, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "    data_store = []\n",
        "    text =  \" \".join(text)\n",
        "    sentences = []\n",
        "    lst = []\n",
        "    for i,(targ,_) in enumerate(targ_list['targets']):\n",
        "        new_sent = text[:idx_list[i][0]]+\" <START> \" + text[idx_list[i][0]:idx_list[i][1]] + \" <END>\" + text[idx_list[i][1]:]\n",
        "        new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "        new_sent = \" \".join(remove_stopwords(\" \".join(new_sent)))    \n",
        "        index = find_indices(new_sent)\n",
        "            \n",
        "        sentences.append(new_sent)\n",
        "        data_store.append((new_sent,torch.tensor(index,dtype=torch.long)))\n",
        "\n",
        "    if len(targ_list['targets']) == 0:\n",
        "        new_sent = \" \".join(text)\n",
        "        # new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "        # new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))\n",
        "        index = [0,0]\n",
        "        sentences.append(new_sent)\n",
        "    \n",
        "        data_store.append((new_sent,torch.tensor(index,dtype=torch.long)))\n",
        "    \n",
        "    encodings = bt_tokenizer(sentences, is_split_into_words=False, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "    for idx,batch in enumerate(data_store):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in encodings.items()}\n",
        "        item['indices'] = batch[1]\n",
        "        lst.append(item)\n",
        "    \n",
        "    return lst\n",
        "\n",
        "def find_indices(new_sent):\n",
        "    splitted = new_sent.split(\" \")\n",
        "    indices = [i+1 for i,w in enumerate(splitted) if (w==\"START\") or (w==\"END\")]\n",
        "    indices[1] = indices[1]-1\n",
        "    return indices\n",
        "\n",
        "\n",
        "def get_batch(idx):\n",
        "    item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    item['indices'] = self.data_store[idx][1]\n",
        "    return item\n",
        "\n",
        "def remove_stopwords(sent: str) -> str:\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "\n",
        "    # remove punkt\n",
        "    others = \"–\" +\"—\" + \"−\" + \"’\" + \"”\" + \"“\" #These chars arent inside the standard punctuation\n",
        "    str_punkt = string.punctuation+ others\n",
        "    translator = str.maketrans(str_punkt, ' '*len(str_punkt)) \n",
        "    word_tokens = word_tokenize(sent.translate(translator)) \n",
        "    \n",
        "    filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "    return filtered_sentence"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcwzOXhlZDQY"
      },
      "source": [
        "#### Model AB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NsPpB06eZDnh"
      },
      "source": [
        "class PreprocessAB():\n",
        "    def __init__(self, sentences):\n",
        "        self.texts = self.load_data(sentences)\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(bert_model)\n",
        "        self.encodings = self.tokenizer(self.texts, is_split_into_words=True, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "        \n",
        "\n",
        "        self.tag2id = {'B-conflict': 1, 'B-negative': 5, 'B-neutral': 2, 'B-positive': 4, 'I-conflict': 6, 'I-negative': 7, 'I-neutral': 8, 'I-positive': 3, 'O': 0}\n",
        "        self.id2tag = {0: 'O', 1: 'B-conflict', 2: 'B-neutral', 3: 'I-positive', 4: 'B-positive', 5: 'B-negative', 6: 'I-conflict', 7: 'I-negative', 8: 'I-neutral'}\n",
        "       \n",
        "                \n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        sentences,texts = [], []\n",
        "        for obj in list_of_sentences:\n",
        "            _sentence = []\n",
        "            for t in tokenizer.tokenize(obj['text']):\n",
        "                token = {\"token\": t}\n",
        "                _sentence.append(token)\n",
        "            sentences.append(_sentence)\n",
        "\n",
        "        for elem in sentences:\n",
        "            texts.append([tok['token'] for tok in elem])\n",
        "        return texts\n",
        "    \n",
        "    \n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "def predict_together_AB(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessAB(samples)\n",
        "    for i,encode in tqdm(enumerate(prep.encodings['input_ids'])):\n",
        "        json_pred = {\"targets\":[]}\n",
        "        lst,pred = [],[]\n",
        "        ids = torch.unsqueeze(torch.tensor(encode),0)\n",
        "        attention_mask = torch.unsqueeze(torch.tensor(prep.encodings['attention_mask'][i]),0)\n",
        "        logits = model(torch.tensor(ids).to(\"cuda\"), torch.tensor(attention_mask).cuda())[\"logits\"]\n",
        "        \n",
        "        for id in logits[0].argmax(1):\n",
        "            lst.append(id.item())\n",
        "        p = reconstruct_original_logits(prep.texts[i], lst,prep.tokenizer)[1:-1]\n",
        "        idtotag = [val_dataset.id2tag[raw_pred] for raw_pred in p]\n",
        "        #idtotag = [label_vocabulary.itos[raw_pred] for raw_pred in p]\n",
        "\n",
        "        for j,word in enumerate(idtotag):\n",
        "            if word.startswith(\"B\"):\n",
        "                json_pred[\"targets\"].append((prep.texts[i][j],word.split(\"-\")[1]))\n",
        "            elif (word.startswith(\"I\")) and (idtotag[j-1].startswith(\"B\")):\n",
        "                try:\n",
        "                    last_tuple = json_pred['targets'][-1]\n",
        "                    words_tagged = last_tuple[0] + \" \" + prep.texts[i][j]\n",
        "                    sent_tagged = last_tuple[1]\n",
        "                    json_pred['targets'][-1] = (words_tagged, sent_tagged)\n",
        "                except:\n",
        "                    words_tagged = prep.texts[i][j]\n",
        "                    sent_tagged = word.split(\"-\")[1]\n",
        "                    json_pred['targets'].append((words_tagged, sent_tagged))\n",
        "            elif word.startswith(\"I\"):\n",
        "                json_pred[\"targets\"].append((prep.texts[i][j],word.split(\"-\")[1]))\n",
        "\n",
        "        targets.append(json_pred)\n",
        "    return targets\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKpRzNWqTcXO"
      },
      "source": [
        "#### Actual evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpyu8rGA2BQw"
      },
      "source": [
        "a = load_data(dataset_folder+\"/laptops_dev.json\")\n",
        "a = a + load_data(dataset_folder+\"/restaurants_dev.json\")\n",
        "random.shuffle(a)\n",
        "#t = predictB(a)\n",
        "# modelA.to(device)\n",
        "# modelB.to(device)\n",
        "model.cuda()\n",
        "modelB = model\n",
        "t = predict_A_then_B(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2gUCA9zb0eo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f45f974-5724-4a40-a837-9c7c64286542"
      },
      "source": [
        "evaluate_sentiment(a,t)\n",
        "evaluate_extraction(a,t)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aspect Sentiment Evaluation\n",
            "\n",
            "\tALL\t TP: 527;\tFP: 554;\tFN: 559\n",
            "\t\t(m avg): precision: 48.75;\trecall: 48.53;\tf1: 48.64 (micro)\n",
            "\t\t(M avg): precision: 33.10;\trecall: 33.61;\tf1: 33.35 (Macro)\n",
            "\n",
            "\tpositive: \tTP: 321;\tFP: 248;\tFN: 222;\tprecision: 56.41;\trecall: 59.12;\tf1: 57.73;\t569\n",
            "\tnegative: \tTP: 152;\tFP: 151;\tFN: 150;\tprecision: 50.17;\trecall: 50.33;\tf1: 50.25;\t303\n",
            "\tneutral: \tTP: 54;\tFP: 155;\tFN: 162;\tprecision: 25.84;\trecall: 25.00;\tf1: 25.41;\t209\n",
            "\tconflict: \tTP: 0;\tFP: 0;\tFN: 25;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n",
            "Aspect Extraction Evaluation\n",
            "\tAspects\t TP: 771;\tFP: 303;\tFN: 311\n",
            "\t\tprecision: 71.79;\trecall: 71.26;\tf1: 71.52\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH0tCcPim6ZQ"
      },
      "source": [
        "for gt,pred in zip(a[:50],t[:50]):\n",
        "    print(gt['targets'],\"SEP\",pred['targets'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMclicKXGZ9C"
      },
      "source": [
        "# TASK B (BERT (WiC))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KzdRK6LlpV1r"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DydnhZNfq_5k"
      },
      "source": [
        "class TaskBDataset(Dataset):\n",
        "    def __init__(self, path,path2, model_b):\n",
        "        self.model_b = model_b\n",
        "        self.texts, self.tags,self.data_store = self.load_data(path)\n",
        "        texts2,tags2,data_store2 = self.load_data(path2)\n",
        "        self.texts = self.texts + texts2\n",
        "        self.tags = self.tags + tags2\n",
        "        self.data_store = self.data_store + data_store2\n",
        "\n",
        "\n",
        "        self.tokenizer = BertTokenizerFast.from_pretrained(bert_model)\n",
        "        self.encodings = self.tokenizer(self.texts, is_split_into_words=False, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "        self.tag2id = {'NONE': 0, 'conflict': 1, 'negative': 2, 'neutral': 3, 'positive': 4}\n",
        "        self.id2tag = {0: 'NONE', 1: 'conflict', 2: 'negative', 3: 'neutral', 4: 'positive'}\n",
        "        self.labels = self.encode_tags(self.tags, self.encodings)\n",
        "        \n",
        "\n",
        "    def encode_tags(self,tags, encodings):\n",
        "        labels = [[self.tag2id[tag] for tag in doc] for doc in tags]\n",
        "        encoded_labels = []\n",
        "        for doc_labels, doc_offset in zip(labels, encodings.offset_mapping):\n",
        "            # create an empty array of -100\n",
        "            doc_enc_labels = np.ones(len(doc_offset),dtype=int) * -100\n",
        "            arr_offset = np.array(doc_offset)\n",
        "\n",
        "            try:\n",
        "                # set labels whose first offset position is 0 and the second is not 0\n",
        "                doc_enc_labels[(arr_offset[:,0] == 0) & (arr_offset[:,1] != 0)] = doc_labels\n",
        "                encoded_labels.append(doc_enc_labels.tolist())\n",
        "            except:\n",
        "                print(doc_labels, doc_offset)\n",
        "\n",
        "        return encoded_labels\n",
        "\n",
        "    def remove_stopwords(self,sent: str) -> str:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        # remove punkt\n",
        "        others = \"–\" +\"—\" + \"−\" + \"’\" + \"”\" + \"“\" #These chars arent inside the standard punctuation\n",
        "        str_punkt = string.punctuation+ others\n",
        "        translator = str.maketrans(str_punkt, ' '*len(str_punkt)) \n",
        "        word_tokens = word_tokenize(sent.translate(translator)) \n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        return filtered_sentence\n",
        "\n",
        "    def load_data(self,data_path):\n",
        "        data_store,sentences = [],[]\n",
        "        with open(data_path) as json_file:\n",
        "            list_of_sentences = json.load(json_file)\n",
        "            for obj in list_of_sentences:\n",
        "                _sentence = []\n",
        "                obj['targets'] = sorted(obj['targets'], key=lambda x: x[0][0])\n",
        "                sentiments = [obj['targets'][j][2] for j in range(len(obj['targets']))]\n",
        "                if LOWERED:\n",
        "                    obj['text'] = obj['text'].lower()\n",
        "                for i,targ_obj in enumerate(obj['targets']):\n",
        "                    #print(targ_obj)\n",
        "                    new_sent = obj['text'][:targ_obj[0][0]-1]+\" <START> \" + obj['text'][targ_obj[0][0]:targ_obj[0][1]] + \" <END>\" + obj['text'][targ_obj[0][1]:]\n",
        "                    if LEMMATIZATION:\n",
        "                        new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                    if REMOVE_STOPWORDS:\n",
        "                        new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))    \n",
        "                    index = self.find_indices(new_sent)\n",
        "                    if LOWERED:\n",
        "                        new_sent = new_sent.lower()    \n",
        "                    sentences.append(new_sent)\n",
        "                    sentiments_converted = [sentiments[i]]\n",
        "                    data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "\n",
        "                if len(obj['targets'])==0:\n",
        "                    sentiments_converted= [\"NONE\"]\n",
        "                    new_sent = obj['text']\n",
        "                    if LEMMATIZATION:\n",
        "                        new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                    if REMOVE_STOPWORDS:\n",
        "                        new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))\n",
        "                    index = [0,0]\n",
        "                    sentences.append(new_sent)\n",
        "                    data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "            tags = []\n",
        "            for tupl in data_store:\n",
        "                tags.append(tupl[2])\n",
        "        return sentences, tags, data_store\n",
        "\n",
        "\n",
        "    \n",
        "    def find_indices(self,new_sent):\n",
        "        splitted = new_sent.split(\" \")\n",
        "        indices = [i+1 for i,w in enumerate(splitted) if (w==\"START\") or (w==\"END\")]\n",
        "        indices[1] = indices[1]-1\n",
        "        return indices\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        #item['text'] = self.texts[idx] + [\"<end>\"] *(100-len(self.texts[idx]))\n",
        "        item['indices'] = self.data_store[idx][1]\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2O-z1kLpZl6"
      },
      "source": [
        "data module"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTiEEnqSpYrL"
      },
      "source": [
        "class DataModuleTaskB(pl.LightningDataModule):\n",
        "    def __init__(self, training_file,training_file2,dev_file, dev_file2, model_b=None):\n",
        "        super().__init__()\n",
        "        self.training_file = training_file\n",
        "        self.dev_file = dev_file\n",
        "        self.training_file2 = training_file2\n",
        "        self.dev_file2 = dev_file2\n",
        "        self.model_b = model_b\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "      self.trainingset = TaskBDataset(self.training_file, self.training_file2, self.model_b)\n",
        "      self.devset = TaskBDataset(self.dev_file, self.dev_file2, self.model_b)\n",
        "          \n",
        "    def train_dataloader(self):\n",
        "      return DataLoader(self.trainingset, batch_size=64)\n",
        "    \n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.devset, batch_size=64)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwCMfEutpccP"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3CEyH_0VyDrz"
      },
      "source": [
        "class TaskBModel(pl.LightningModule):\n",
        "    def __init__(self, device,  comments=\"\",*args, **kwargs):\n",
        "        super(TaskBModel, self).__init__(*args, **kwargs)      \n",
        "        self.model = BertModel.from_pretrained(bert_model, num_labels=5 if model_b else 3, output_hidden_states = True)\n",
        "        \n",
        "        self.writer = SummaryWriter(comment=comments+\"_modelb=\"+str(model_b))\n",
        "        self.epoch_t, self.epoch_ev = -1,-1\n",
        "        self.lin1 = torch.nn.Linear(768, 768)\n",
        "        self.classifier = torch.nn.Linear(768, 5)\n",
        "        self.loss_fn = torch.nn.CrossEntropyLoss()\n",
        "        self.model.to(device)\n",
        "        self.save_hyperparameters()\n",
        "    \n",
        "    def forward(self, input_ids, attention_mask, indices_keyword, labels=None):\n",
        "        outputs = self.model(input_ids, attention_mask=attention_mask)# labels=labels)\n",
        "        # hidden_states = outputs['hidden_states']\n",
        "        # hidden_states = self.tuple_of_tensors_to_tensor(hidden_states)\n",
        "        hidden_states = outputs['last_hidden_state']\n",
        "        batch_size, seq_len, hidden_size = hidden_states.shape\n",
        "\n",
        "        #sequence of batch x seq_len vectors \n",
        "        flat_output = hidden_states.reshape(-1, hidden_size)\n",
        "        \n",
        "        # start offsets of each element in the batch\n",
        "        sequences_offsets = torch.arange(batch_size, device=self.device) * seq_len\n",
        "        \n",
        "        summary_vectors_indices_sent1 = self.get_indices_keyword(indices_keyword, sequences_offsets,0)\n",
        "        summary_vectors_indices_sent2 = self.get_indices_keyword(indices_keyword, sequences_offsets,1)\n",
        "        \n",
        "        # we retrieve the vector of the corrseponding states for the keyword given for each sentence.\n",
        "        \n",
        "        summary_vectors_sent1 = flat_output[summary_vectors_indices_sent1]\n",
        "        summary_vectors_sent2 = flat_output[summary_vectors_indices_sent2]\n",
        "        \n",
        "        # do the multiplication of these two vectors retrieved\n",
        "        summary_vectors = summary_vectors_sent1 * summary_vectors_sent2\n",
        "        out = self.lin1(summary_vectors)\n",
        "        out = F.leaky_relu(out)\n",
        "        \n",
        "        logits = self.classifier(out)\n",
        "        res = {}\n",
        "        res['logits'] = logits\n",
        "        if labels is not None:\n",
        "            labels = torch.stack([labels[i][1] for i in range(labels.shape[0])])\n",
        "            pred = torch.argmax(logits, -1)\n",
        "            loss = self.loss_fn(logits, torch.tensor(labels) )\n",
        "            res['loss'] = loss\n",
        "        return res\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "        self.model.train()\n",
        "        input_ids = batch['input_ids'].to(self.device)\n",
        "        attention_mask = batch['attention_mask'].to(self.device)\n",
        "        labels = batch['labels'].to(self.device)\n",
        "        indices_keyword = batch['indices'].to(self.device)\n",
        "\n",
        "        out = self.forward(input_ids, attention_mask=attention_mask, indices_keyword=indices_keyword, labels=labels)\n",
        "        logits = out['logits']\n",
        "        loss = out['loss']\n",
        "        # Log it:\n",
        "        self.log('train_loss', loss, prog_bar=True)\n",
        "        if self.epoch_t != self.current_epoch:\n",
        "            self.epoch_t = self.current_epoch\n",
        "            res = self.compute_F1(logits,labels)\n",
        "            self.log('train_f1', res['f1'], prog_bar = True)\n",
        "            self.writer.add_scalar(\"train/loss\", loss, self.current_epoch)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            input_ids = batch['input_ids'].to(self.device)\n",
        "            attention_mask = batch['attention_mask'].to(self.device)\n",
        "            labels = batch['labels'].to(self.device)\n",
        "            indices_keyword = batch['indices'].to(self.device)\n",
        "\n",
        "            out = self.forward(input_ids, attention_mask=attention_mask, indices_keyword=indices_keyword,labels=labels)\n",
        "            logits = out['logits']\n",
        "            sample_loss = out['loss']\n",
        "\n",
        "        self.log('valid_loss', sample_loss, prog_bar=True)\n",
        "        \n",
        "        if self.epoch_ev != self.current_epoch:\n",
        "            self.epoch_ev = self.current_epoch\n",
        "            self.writer.add_scalar(\"eval/loss\", sample_loss, self.current_epoch)\n",
        "            res = self.compute_F1(logits,labels)\n",
        "            self.log('val_f1', res['f1'], prog_bar = True)\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.parameters(), lr=5e-5)\n",
        "    \n",
        "    def tuple_of_tensors_to_tensor(self, tuple_of_tensors):\n",
        "        return torch.stack(list(tuple_of_tensors[6]), dim=0).to(self.device)\n",
        "        # vec = torch.stack(list(tuple_of_tensors),dim=0)\n",
        "        # vec = torch.mean(vec,dim=0)\n",
        "        # return vec.to(self.device)\n",
        "    '''\n",
        "    return the corresponding position of the indices of the keywords, for the sent_num passed, so the first if 0 is passed and the second if 1 is passed\n",
        "    summary  = [   0,   57,  114,  171,  228, ...] \n",
        "    indices_keywords = [ [ 6, 21],[ 4, 22],[ 6, 21],[ 4, 22], ...]\n",
        "    '''\n",
        "    def get_indices_keyword(self,indices_keywords: Sequence[tuple], summary: Sequence[int] ,sent_num: int) -> torch.Tensor:\n",
        "        tens_idx = torch.tensor([item[sent_num] for item in indices_keywords]).to(self.device)\n",
        "        return tens_idx + summary\n",
        "\n",
        "    def compute_F1(self, logits, labels):\n",
        "\n",
        "        valid_predictions = torch.argmax(logits, axis=-1)\n",
        "        valid_labels = torch.stack([labels[i][1] for i in range(labels.shape[0])])\n",
        "\n",
        "        all_predictions = valid_predictions.tolist()\n",
        "        all_labels = valid_labels.tolist() \n",
        "\n",
        "        precision = precision_score(all_labels, all_predictions, average=\"macro\", zero_division=0)\n",
        "        recall = recall_score(all_labels, all_predictions, average=\"macro\", zero_division=0)\n",
        "        f1 = f1_score(all_labels, all_predictions, average=\"macro\", zero_division=0)\n",
        "        return {\"precision\": precision, \"recall\": recall, \"f1\": f1}"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8RbNRU6pft_"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7wDbWhZOTEr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605,
          "referenced_widgets": [
            "961f7b94248e4b2cbbf3a9f8745e9dfe",
            "a8aa9d851f584c64b168c185099e81ca",
            "fb21a7aab56847b1bf6ec5fe09951858",
            "c928c7509c7246378ee1b2a36ef56eea",
            "3b0b50dc1bb04f1187ffd399d52793bc",
            "84af3a64efa249af985b8e3411fb2215",
            "67c8cab8bcea4dd89ec37b46c8b053c2",
            "8a5356aadc26425aa6bf12b1acb7d66d",
            "2d5de18b4e0743039fa1de698214637d",
            "cc6c8ba264d641998d26ff383cabf602",
            "b89d9b2b53d44b8ebec4d9d97b9440bf",
            "b183d0dc380f4a83a441cb475900d845",
            "b8e092aa942b4350b5b2173676f49245",
            "4feafb44e306435c886f545a4d2b1177",
            "a97790d345674a01ad1658e3f4d3ffe4",
            "64a4fd85b7394c388f35fd07c5afb3cf",
            "fe333864048e4d85abc13b594b21f559",
            "92f69ef8429e4d7cb4dfee43bd916637",
            "d21b5c985ad440529c5d4913fd7d391a",
            "4b94d3d2a71542819da584d007f7932f",
            "f80c0f3b1d1d4c699c00dea61c93f1b8",
            "b2ab44c2c29345e595ddd86340e2793c",
            "c682a18c95504b15a97979d9347d11c6",
            "9b40b5433814450da884878511f6ae73",
            "ec5d2ee121f2445f86e7db9a62d4b9ee",
            "3cfd9d12fcbd407baab948ce5f338d61",
            "f31769e55b1c419887f7ac95ea95aee9",
            "ef67b8f242a4421f8b27f98a3f1d9f6a",
            "8917e5fdad8f4fc1a0628a4dac2c2587",
            "271cfc12a9d149fda8a2585ee7cacd04",
            "be287613e58a477f962fc047298f442f",
            "977795e642e74750a0c1a1bc6de8abf6",
            "767dc8a4397c46eea32c81bc15410feb",
            "1983c7d04653475f9dba7386da821d36",
            "c631e18f453e45bea09a72f9d835280e",
            "508e06b71c85492d9a41cf0fe6471fde",
            "d97e892804e941c0aa6958a714a0fc26",
            "24c418beb59b45b486e59af1215bdb26",
            "fda0a2e978c84e898cd6d99a959fcb6a",
            "630879492b6e49828bb85cac79d50ccf",
            "7597c039d01d4132a80c2fb07776df1a",
            "9572759a16fa4ca9863e77e2c63a9f07",
            "ae6205a662e2430d84a42d9acd29d083",
            "9646f325afe34e4c929f061738600392",
            "b9308f2d6fbe487a82798bdafbafc7b3",
            "a4b2c130c7094968a6129d49e87a2825",
            "5542f48537054c1f8b1569ca19df1a16",
            "6b59b085570f4a3a9a30677567c69f8f",
            "d4f4392d922f4790ba5fb551a3739c9c",
            "7dbc1371b5e946869f739d20263bb36e",
            "93cad05753a2406199a740bbc7dc01e4",
            "ec561e23321749b48d5cc21cdd408e67",
            "f59d5510c64747d4ab1af44e3e900aa4",
            "3c307732fd9647b3891406b1d8f85d03",
            "5a164b87d2dd437daccbe28ef0255ae6",
            "59f1151bba71484c9c447a53b99ace7a",
            "157c2e45b14b4a649cb32dda44dbbf41",
            "3bf0cef774c340f5ab0718373134814a",
            "bd25333d0c724917aba696c583fc6971",
            "8d7cb264d5c3429b884ebd75754635f9",
            "fba21f42944449d984838fba5d491c4a",
            "a5d158fd48314602ad6159008f719c69",
            "448a40b6473d4a03ab7d7f62843b7357",
            "dbea96771fa548d4acd5307f2b7299cc",
            "87047ec3a20b433ca2b829ed51bc5c91",
            "68d52d8d0f7240019700009f590f40f9",
            "d90a11c16f744ecdafb3ea9e238b5d7d",
            "75ad54de64674bc38faabb0abdf991ed",
            "3e1883e7ab7e47c8b380515630cec588",
            "2a6a1bbf180b4cf4b42b0b467e0d4a8d",
            "21dc18fedd824b549e53af35823e111f",
            "57aed45a7c93405aa64f5ccbf5c6cdbb",
            "f1229eb30c104b64bb0c7771745a870a",
            "67d0de59949e47fe926a6af32945ba95",
            "2a3c1437cb4740719af950b640c0f872",
            "6dd70528342d4433a612624c146afbd5",
            "aed852bc135b42f38e810eb33559d931",
            "674ae67a3fa042a8881f0026443ba05c",
            "87577ef68222471490f4b679263ce09b",
            "4fda82fd1a1947838e94953db9989d9b"
          ]
        },
        "outputId": "91f7a68f-6264-4719-c311-61b28d496f95"
      },
      "source": [
        "data_module = DataModuleTaskB(dataset_folder+\"/laptops_train.json\",dataset_folder+\"/restaurants_train.json\",dataset_folder+\"/laptops_dev.json\",dataset_folder+\"/restaurants_dev.json\",model_b)\n",
        "trainer = pl.Trainer(gpus=1, val_check_interval=1.0, max_epochs=5)\n",
        "model = TaskBModel(device,\"test_bert\")\n",
        "trainer.fit(model, datamodule=data_module)\n",
        "#trainer.save_checkpoint(root_folder+\"/model/taskB.ckpt\")"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "961f7b94248e4b2cbbf3a9f8745e9dfe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d5de18b4e0743039fa1de698214637d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe333864048e4d85abc13b594b21f559",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=28.0, style=ProgressStyle(description_w…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name       | Type             | Params\n",
            "------------------------------------------------\n",
            "0 | model      | BertModel        | 109 M \n",
            "1 | lin1       | Linear           | 590 K \n",
            "2 | classifier | Linear           | 3.8 K \n",
            "3 | loss_fn    | CrossEntropyLoss | 0     \n",
            "------------------------------------------------\n",
            "110 M     Trainable params\n",
            "0         Non-trainable params\n",
            "110 M     Total params\n",
            "440.307   Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ec5d2ee121f2445f86e7db9a62d4b9ee",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "767dc8a4397c46eea32c81bc15410feb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7597c039d01d4132a80c2fb07776df1a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d4f4392d922f4790ba5fb551a3739c9c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "157c2e45b14b4a649cb32dda44dbbf41",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87047ec3a20b433ca2b829ed51bc5c91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1229eb30c104b64bb0c7771745a870a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "au-5s3YWTPiF"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipBdBfhol3uB"
      },
      "source": [
        "metr = {\"f1\":48.7}\n",
        "#torch.save(model.state_dict(), root_folder+'/model/TASKB_model_b={}_f1_{:0.4f}.pt'.format(str(model_b), metr[\"f1\"])) # save the model state"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbiZGGWRTPig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b092417-2dcf-4cdc-f013-7aff924959b2"
      },
      "source": [
        "class PreprocessBWiC():\n",
        "    def __init__(self, sentences):\n",
        "        self.data_store,self.sentences,self.targets = self.load_data(sentences)\n",
        "        #self.texts, self.tags,self.data_store = self.load_data(sentences)\n",
        "\n",
        "        self.id2tag = {0: 'NONE', 1: 'conflict', 2: 'negative', 3: 'neutral', 4: 'positive'}\n",
        "\n",
        "\n",
        "        self.tokenizer = DistilBertTokenizerFast.from_pretrained(bert_model)\n",
        "        self.encodings = self.tokenizer(self.sentences, is_split_into_words=False, return_offsets_mapping=True, padding=True, truncation=True)\n",
        "        \n",
        "    \n",
        "    def remove_stopwords(self,sent: str) -> str:\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "\n",
        "        # remove punkt\n",
        "        others = \"–\" +\"—\" + \"−\" + \"’\" + \"”\" + \"“\" #These chars arent inside the standard punctuation\n",
        "        str_punkt = string.punctuation+ others\n",
        "        translator = str.maketrans(str_punkt, ' '*len(str_punkt)) \n",
        "        word_tokens = word_tokenize(sent.translate(translator)) \n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        return filtered_sentence\n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        data_store,sentences,targets = [],[],[]\n",
        "        for obj in list_of_sentences:\n",
        "            _sentence = []\n",
        "            obj['targets'] = sorted(obj['targets'], key=lambda x: x[0][0])\n",
        "            sentiments = [obj['targets'][j][2] for j in range(len(obj['targets']))]\n",
        "\n",
        "            for i,targ_obj in enumerate(obj['targets']):\n",
        "                #print(targ_obj)\n",
        "                new_sent = obj['text'][:targ_obj[0][0]-1]+\" <START> \" + obj['text'][targ_obj[0][0]:targ_obj[0][1]] + \" <END>\" + obj['text'][targ_obj[0][1]:]\n",
        "                new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))    \n",
        "                index = self.find_indices(new_sent)\n",
        "                    \n",
        "                sentences.append(new_sent)\n",
        "                sentiments_converted = [sentiments[i]]\n",
        "                targets.append([(targ[1], \"\") for j,targ in enumerate(obj['targets'])])\n",
        "\n",
        "                data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "\n",
        "            if len(obj['targets'])==0:\n",
        "                sentiments_converted= [\"NONE\"]\n",
        "                targets.append([(targ[1], \"\") for j,targ in enumerate(obj['targets'])])\n",
        "\n",
        "                new_sent = obj['text']\n",
        "                # new_sent = [lemmatizer.lemmatize(w)  for w in new_sent.split(\" \")]\n",
        "                # new_sent = \" \".join(self.remove_stopwords(\" \".join(new_sent)))\n",
        "                index = [0,0]\n",
        "                sentences.append(new_sent)\n",
        "                data_store.append((new_sent,torch.tensor(index,dtype=torch.long), sentiments_converted))\n",
        "        \n",
        "        return data_store,sentences,targets\n",
        "\n",
        "    \n",
        "    def find_indices(self,new_sent):\n",
        "        splitted = new_sent.split(\" \")\n",
        "        indices = [i+1 for i,w in enumerate(splitted) if (w==\"START\") or (w==\"END\")]\n",
        "        indices[1] = indices[1]-1\n",
        "        return indices\n",
        "\n",
        "\n",
        "    def get_batch(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['indices'] = self.data_store[idx][1]\n",
        "        return item\n",
        "    \n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self.sentences)\n",
        "\n",
        "    \n",
        "def predictBBNEW(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessBWiC(samples)\n",
        "    model.eval()\n",
        "    model.cuda()\n",
        "    i = 0\n",
        "    print(len(prep.data_store))\n",
        "    while i < len(prep.data_store):\n",
        "        cont = len(prep.targets[i])\n",
        "        json_pred = {\"targets\":prep.targets[i]}\n",
        "        if cont==0:\n",
        "            i+=1\n",
        "        sentiments = []\n",
        "        while cont > 0:\n",
        "            #inputs,idx_start = rnn_collate_fn([prep.data_store[i]]) # inputs in the batch\n",
        "            batch = prep.get_batch(i)\n",
        "            input_ids = torch.unsqueeze(batch['input_ids'],0).to(device)\n",
        "            attention_mask = torch.unsqueeze(batch['attention_mask'],0).to(device)\n",
        "            indices_keyword = torch.unsqueeze(batch['indices'],0).to(device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                out = model.forward(input_ids, attention_mask=attention_mask, indices_keyword=indices_keyword)\n",
        "                logits = out['logits']\n",
        "                #forward_result = task_b_classifier(inputs.cpu(), idx_start.cpu())\n",
        "\n",
        "            y_pred_labels = torch.argmax(logits, axis=-1)\n",
        "            y_pred_labels.tolist()[0]\n",
        "            y_pred = prep.id2tag[y_pred_labels.tolist()[0]]\n",
        "            sentiments += [y_pred]\n",
        "            cont-=1\n",
        "            i+=1\n",
        "        for k,targ in enumerate(json_pred['targets']):\n",
        "            try:\n",
        "                if sentiments[k] != \"NONE\":\n",
        "                    json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],sentiments[k])\n",
        "            except:\n",
        "                json_pred[\"targets\"][k] = (json_pred[\"targets\"][k][0],\"conflict\")\n",
        "        targets.append(json_pred)\n",
        "    return targets\n",
        "\n",
        "a = load_data(dataset_folder+\"/laptops_dev.json\")\n",
        "a = a + load_data(dataset_folder+\"/restaurants_dev.json\")\n",
        "random.shuffle(a)\n",
        "t = predictBBNEW(a)\n",
        "for x,y in zip(a[:30],t[:30]):\n",
        "    print(x['targets'],\"SEP\",y['targets'])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1546\n",
            "[[[74, 77], 'use', 'positive']] SEP [('use', 'positive')]\n",
            "[[[30, 34], 'cost', 'positive']] SEP [('cost', 'negative')]\n",
            "[[[89, 94], 'staff', 'conflict']] SEP [('staff', 'positive')]\n",
            "[] SEP []\n",
            "[] SEP []\n",
            "[] SEP []\n",
            "[[[0, 7], 'Service', 'positive'], [[18, 25], 'takeout', 'positive']] SEP [('Service', 'positive'), ('takeout', 'positive')]\n",
            "[[[13, 30], 'pastrami sandwich', 'positive']] SEP [('pastrami sandwich', 'positive')]\n",
            "[[[87, 97], 'hard drive', 'negative']] SEP [('hard drive', 'negative')]\n",
            "[[[54, 58], 'meal', 'positive']] SEP [('meal', 'positive')]\n",
            "[[[21, 35], 'standard os cd', 'negative'], [[47, 75], 'proprietary hardware drivers', 'negative']] SEP [('standard os cd', 'neutral'), ('proprietary hardware drivers', 'neutral')]\n",
            "[] SEP []\n",
            "[[[4, 9], 'staff', 'positive']] SEP [('staff', 'positive')]\n",
            "[[[4, 10], 'people', 'positive']] SEP [('people', 'positive')]\n",
            "[] SEP []\n",
            "[[[12, 29], 'seltzer with lime', 'neutral']] SEP [('seltzer with lime', 'neutral')]\n",
            "[[[2, 25], 'glass of Leaping Lizard', 'positive'], [[29, 46], 'glass of prosecco', 'positive'], [[56, 63], 'mussels', 'positive']] SEP [('glass of Leaping Lizard', 'positive'), ('glass of prosecco', 'positive'), ('mussels', 'positive')]\n",
            "[] SEP []\n",
            "[] SEP []\n",
            "[[[26, 51], 'Microsoft Student Edition', 'negative']] SEP [('Microsoft Student Edition', 'neutral')]\n",
            "[[[85, 94], 'Pentium 4', 'neutral'], [[103, 111], '1 GB ram', 'neutral']] SEP [('Pentium 4', 'negative'), ('1 GB ram', 'negative')]\n",
            "[[[0, 14], 'Veal Parmigana', 'positive']] SEP [('Veal Parmigana', 'positive')]\n",
            "[[[9, 20], 'RMA service', 'positive']] SEP [('RMA service', 'positive')]\n",
            "[[[95, 101], 'Gnochi', 'positive']] SEP [('Gnochi', 'positive')]\n",
            "[] SEP []\n",
            "[[[58, 64], 'waiter', 'positive']] SEP [('waiter', 'positive')]\n",
            "[[[4, 8], 'food', 'negative']] SEP [('food', 'negative')]\n",
            "[[[31, 39], 'features', 'positive']] SEP [('features', 'positive')]\n",
            "[] SEP []\n",
            "[[[31, 35], 'food', 'negative']] SEP [('food', 'neutral')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3s3Qj8A6TPit",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3beec20-e2e9-4a95-fa22-9f1909ccdd2f"
      },
      "source": [
        "evaluate_sentiment(a,t)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Aspect Sentiment Evaluation\n",
            "\n",
            "\tALL\t TP: 730;\tFP: 356;\tFN: 356\n",
            "\t\t(m avg): precision: 67.22;\trecall: 67.22;\tf1: 67.22 (micro)\n",
            "\t\t(M avg): precision: 46.61;\trecall: 47.84;\tf1: 47.20 (Macro)\n",
            "\n",
            "\tpositive: \tTP: 427;\tFP: 122;\tFN: 116;\tprecision: 77.78;\trecall: 78.64;\tf1: 78.21;\t549\n",
            "\tnegative: \tTP: 209;\tFP: 117;\tFN: 93;\tprecision: 64.11;\trecall: 69.21;\tf1: 66.56;\t326\n",
            "\tneutral: \tTP: 94;\tFP: 117;\tFN: 122;\tprecision: 44.55;\trecall: 43.52;\tf1: 44.03;\t211\n",
            "\tconflict: \tTP: 0;\tFP: 0;\tFN: 25;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFGbrVy9YX7R"
      },
      "source": [
        "# TASK C-D (DistilBERT for sequence classification fine tuning)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pW7JmyGUXmJu"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wr9hcu_PbOSF"
      },
      "source": [
        "class TaskCDDataset (Dataset):\n",
        "    def __init__(self,path, tokenizer, max_len,model_b):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model_b = model_b\n",
        "        self.texts, self.tags = self.load_data(path)\n",
        "        self.mlb = MultiLabelBinarizer()\n",
        "        self.mlb.fit_transform([['ambience-conflict', 'ambience-negative', 'ambience-neutral',\n",
        "       'ambience-positive', 'anecdotes/miscellaneous-conflict',\n",
        "       'anecdotes/miscellaneous-negative',\n",
        "       'anecdotes/miscellaneous-neutral',\n",
        "       'anecdotes/miscellaneous-positive', 'food-conflict',\n",
        "       'food-negative', 'food-neutral', 'food-positive', 'price-conflict',\n",
        "       'price-negative', 'price-neutral', 'price-positive',\n",
        "       'service-conflict', 'service-negative', 'service-neutral',\n",
        "       'service-positive']])\n",
        "        self.encode_tags()\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def encode_tags(self):\n",
        "        self.tags = self.mlb.fit_transform(self.tags)\n",
        "\n",
        "    def decode_tag(self,tag):\n",
        "        return self.mlb.inverse_transform(tag.reshape(1,-1))\n",
        "\n",
        "    def load_data(self,datapath):\n",
        "        sentences = []     \n",
        "        texts = []\n",
        "        tags = []\n",
        "        with open(datapath) as json_file:\n",
        "            list_of_sentences = json.load(json_file)\n",
        "            for obj in list_of_sentences:\n",
        "                texts.append(obj['text'])\n",
        "                tags.append([cat[0]+\"-\"+cat[1] for cat in obj['categories']])\n",
        "\n",
        "        return texts, tags  \n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, item_idx):\n",
        "        text = self.texts[item_idx]\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True, # Add [CLS] [SEP]\n",
        "            max_length= self.max_len,\n",
        "            padding = 'max_length',\n",
        "            return_token_type_ids= False,\n",
        "            return_attention_mask= True, \n",
        "            truncation=True,\n",
        "            return_tensors = 'pt'\n",
        "          )\n",
        "        \n",
        "        input_ids = inputs['input_ids'].flatten()\n",
        "        attn_mask = inputs['attention_mask'].flatten()\n",
        "        \n",
        "        return {\n",
        "            'input_ids': input_ids ,\n",
        "            'attention_mask': attn_mask,\n",
        "            'label': torch.tensor(self.tags[item_idx], dtype=torch.float)\n",
        "        }\n",
        "        "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLM-mkSobQwc"
      },
      "source": [
        "class TaskCDDataModule (pl.LightningDataModule):\n",
        "    \n",
        "    def __init__(self,training_file, dev_file, tokenizer,batch_size=16,max_token_len=200):\n",
        "        super().__init__()\n",
        "        self.training_file = training_file\n",
        "        self.dev_file = dev_file\n",
        "        \n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "        self.max_token_len = max_token_len\n",
        "\n",
        "    def setup(self):\n",
        "        self.train_dataset = TaskCDDataset(self.training_file, tokenizer=self.tokenizer,max_len = self.max_token_len,model_b=model_b)\n",
        "        self.val_dataset  = TaskCDDataset(self.dev_file, tokenizer=self.tokenizer,max_len = self.max_token_len,model_b=model_b)\n",
        "           \n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.train_dataset,batch_size = self.batch_size,shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.val_dataset,batch_size= 16)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilD0LTOxXp1x"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkTK8rJocqxC"
      },
      "source": [
        "class TaskCDClassifier(pl.LightningModule):\n",
        "    def __init__(self, n_classes=5, steps_per_epoch=None, n_epochs=3, lr=2e-5,device=\"cuda\" ):\n",
        "        super().__init__()\n",
        "        self.bert = DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased',num_labels=n_classes)\n",
        "        self.steps_per_epoch = steps_per_epoch\n",
        "        self.n_epochs = n_epochs\n",
        "        self.lr = lr\n",
        "        self.criterion = nn.BCEWithLogitsLoss()\n",
        "        self.to(device)\n",
        "    \n",
        "    def forward(self,input_ids, attn_mask):\n",
        "        output = self.bert(input_ids = input_ids ,attention_mask = attn_mask)\n",
        "        output = output['logits']        \n",
        "        return output\n",
        "    \n",
        "    \n",
        "    def training_step(self,batch,batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['label']\n",
        "        \n",
        "        outputs = self(input_ids,attention_mask)\n",
        "        loss = self.criterion(outputs,labels)\n",
        "        self.log('train_loss',loss , prog_bar=True,logger=True)\n",
        "        \n",
        "        return {\"loss\" :loss, \"predictions\":outputs, \"labels\": labels }\n",
        "\n",
        "\n",
        "    def validation_step(self,batch,batch_idx):\n",
        "        input_ids = batch['input_ids']\n",
        "        attention_mask = batch['attention_mask']\n",
        "        labels = batch['label']\n",
        "        \n",
        "        outputs = self(input_ids,attention_mask)\n",
        "        loss = self.criterion(outputs,labels)\n",
        "        self.log('val_loss',loss , prog_bar=True,logger=True)\n",
        "        \n",
        "        return loss\n",
        "    \n",
        "    \n",
        "    def configure_optimizers(self):\n",
        "        optimizer = AdamW(self.parameters() , lr=self.lr)\n",
        "        return optimizer\n",
        "    "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjiaWac8X1rL"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3FpYR3RNf_L"
      },
      "source": [
        "Set up hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fXn-TfKcdNo"
      },
      "source": [
        "bert_tokenizer=DistilBertTokenizerFast.from_pretrained('distilbert-base-cased') \n",
        "N_EPOCHS = 5 #@param {type:\"slider\", min:1, max:10, step:1}\n",
        "BATCH_SIZE = 32 #@param {type:\"slider\", min:8, max:64, step:2}\n",
        "MAX_LEN = 20 #@param {type:\"slider\", min:20, max:50, step:1}\n",
        "LR = 0.00002 #@param {type:\"slider\", min:0.00002, max:0.002, step:0.00001}"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HRpWKBYVkuz"
      },
      "source": [
        "Set up the data module and instantiate the classifier model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lvv6Au-icsVm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "f78cb654444440e68205a5cdfbaa9c40",
            "c8b4683ca42a406a8b4f827485065d47",
            "13813d43539c46afb32fbd18a9ce9418",
            "4cdafb3516944813bbb55d91cc519779",
            "6d05b1682b8640bb8c204305147a93ce",
            "9e5ec14b12734b69892d10893132470e",
            "fb653e39201d4a87a9309c22866aa585",
            "b287e412b7ee43f5affd7056362482fd",
            "f47dcd371bca4130a116954c02ebe7a5",
            "87fcf59c8b01446b96a3a666b17c0a7e",
            "4900b010d1f24ca7832a65b65fffde1e",
            "4e361a3f640a4982820bdc6d9010db99",
            "d1fec17d6f524a7986a7712060d3d8b6",
            "83e46cce8ed44ddc88dd7e71213692d4",
            "aa39c854f7cd44cfacba68f3345b4a56",
            "4514b493168d4587ba62d13b71665f51"
          ]
        },
        "outputId": "c645d837-95f0-47a7-b204-a5c2d14726bc"
      },
      "source": [
        "TaskCD_data_module = TaskCDDataModule(\n",
        "    dataset_folder+\"/restaurants_train.json\",\n",
        "    dataset_folder+\"/restaurants_dev.json\",\n",
        "    bert_tokenizer,\n",
        "    BATCH_SIZE,\n",
        "    MAX_LEN\n",
        "    )\n",
        "TaskCD_data_module.setup()\n",
        "\n",
        "train_d = TaskCD_data_module.train_dataset\n",
        "steps_per_epoch = len(train_d.texts)//BATCH_SIZE\n",
        "model = TaskCDClassifier(n_classes=20, steps_per_epoch=steps_per_epoch,n_epochs=N_EPOCHS,lr=LR)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f78cb654444440e68205a5cdfbaa9c40",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=411.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f47dcd371bca4130a116954c02ebe7a5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=263273408.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'classifier.weight', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WurD2_IQXFU9"
      },
      "source": [
        "Instantiate the Model Trainer\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EpY53knvdGoA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330,
          "referenced_widgets": [
            "3dc5f9dfeabf423ba0c0fa9960f12347",
            "95252eefb12a44418b77f1ae6bb416f1",
            "9105d6b5b0164b72814ba9ec4a600d1c",
            "d4398e50c6a643c2976b3019e44c227d",
            "11f8eb13292b44a3b4277181bf382a82",
            "da0aa675e64e48fbb1aaa57778c93198",
            "ddc70421593d4d02920a5b8d5e79d4a5",
            "62a224f9f97f4a45b780fd566f367adb",
            "430968a2dc804c5e86f7a8bcf1e858c6",
            "6afc79977fcf46c193b2d408d83f8b51",
            "5b6244fe03cd45f1ae61843f5848d8c8",
            "85b0af61eacd4e75975c66a183d66ca8",
            "7cac26539d7a4e7fa0f79b79898ff04c",
            "740f7ca5b0e64b738fefb6b4d3bed8db",
            "69600d43d29048c4a36ff06875b7df2f",
            "741a5400490348f6b27a6b77a25c97f0",
            "4169416293b24a688adfe216d9f70c1f",
            "f80bb77861f7457a8d9fa588a10f950c",
            "ea5c18dc4c5a41bebf5a7fd12ba04e54",
            "8889aeee02e2414591815ced3a0bf3fb",
            "96f0fcdc54af4a36a6a31a5758b4ec7f",
            "55acc995971444a9b5365f6a23a340b3",
            "c79f28ea040841f491d729bf37f3c5f7",
            "1ce5d18c7be14b3898ba630a7f94af2b",
            "a695e7339ce14af995ca0704793749cc",
            "6061d0ab824c419a8cf4b74114c947d8",
            "92eb8a0627f245d2ace7fc9821d6ccc6",
            "4df02b18266c4c38908879283f2ec274",
            "e6224f3b491d4a799dcfa26fc246c6b2",
            "e46be26d39e943b8b6ef9f150f09cf22",
            "3c2c9b4a59a649e1806034c2138d0c0f",
            "466afbdd755542589a6179d8aab1c242",
            "e7c295bdf4464de0ac565eb509fcb312",
            "662354f27bc94e818bbc53b14294773e",
            "e854c194b0d5446ca3f5493b7a961498",
            "87885b44690744a2952cd14cfbdb9a6f",
            "0f78a31aa741420aa23fc7f0342fed22",
            "2cf07cf2f19a4b9280a2a6fc9a8c0ca2",
            "f69848b564e74b55a42ada63f864276b",
            "a8a307bfc1bf41a0911b283dc5cd1b07",
            "b3c02e1231134c8bae34ea0bc146d6bf",
            "d66ce2c7b82c430489a51ede8e681a5c",
            "96c1f1ebf2d64ef2b91c971043c49097",
            "851614ab0b5b4417a647ef1428358a9b",
            "503a5d96684e48efa2fe69736ebe8587",
            "f06f3b0f52b047babd74bc9caad416f8",
            "dcabf24fcfbe489b9a99b0149ab66497",
            "6901287d42ef4e1d8c86341d1a577a96",
            "99eabc2aa9a5417a84117b2c78e128d2",
            "e1c5a0a6cc1a40658928ca3e5c8d9e17",
            "e8218bac3c524760aeeb601904d7a61b",
            "3d448834ee5843be8d3d1e0e9591941f",
            "8f2c1439cf9c48bca413cbef242dace4",
            "42292eab50524a59881af600d5f91be7",
            "c8ceb563081d492aa4dd4f20cd8d3a05",
            "23aa81e3c5924a6fb0eb5be7cdaea76e"
          ]
        },
        "outputId": "9d065645-aae4-4afc-d53b-49b532047016"
      },
      "source": [
        "trainer = pl.Trainer(max_epochs = N_EPOCHS , gpus = 1,progress_bar_refresh_rate = 10)\n",
        "trainer.fit(model, TaskCD_data_module)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type                                | Params\n",
            "------------------------------------------------------------------\n",
            "0 | bert      | DistilBertForSequenceClassification | 65.8 M\n",
            "1 | criterion | BCEWithLogitsLoss                   | 0     \n",
            "------------------------------------------------------------------\n",
            "65.8 M    Trainable params\n",
            "0         Non-trainable params\n",
            "65.8 M    Total params\n",
            "263.188   Total estimated model params size (MB)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3dc5f9dfeabf423ba0c0fa9960f12347",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validation sanity check', layout=Layout…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\r"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "430968a2dc804c5e86f7a8bcf1e858c6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4169416293b24a688adfe216d9f70c1f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a695e7339ce14af995ca0704793749cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e7c295bdf4464de0ac565eb509fcb312",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3c02e1231134c8bae34ea0bc146d6bf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "99eabc2aa9a5417a84117b2c78e128d2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m6ogQkj3RDeK"
      },
      "source": [
        "trainer.save_checkpoint(root_folder+\"/model/taskCD.ckpt\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNOOSb92X31J"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gvffKboBbJ2E"
      },
      "source": [
        "def evaluate_CD():\n",
        "    pred_outs, true_labels = [], []\n",
        "    model.to(device)\n",
        "    for batch in TaskCD_data_module.val_dataloader():\n",
        "        b_input_ids = batch[\"input_ids\"].to(device)\n",
        "        b_attn_mask = batch[\"attention_mask\"].to(device)\n",
        "        b_labels = batch[\"label\"].to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            pred_out = model(b_input_ids,b_attn_mask)\n",
        "            pred_out = torch.sigmoid(pred_out)        \n",
        "            pred_out = pred_out.detach().cpu().numpy()\n",
        "            label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        pred_outs.append(pred_out)\n",
        "        true_labels.append(label_ids)\n",
        "    return pred_outs,true_labels\n",
        "\n",
        "def classify(pred_prob,thresh):\n",
        "    y_pred = []\n",
        "\n",
        "    for tag_label_row in pred_prob:\n",
        "        temp=[]\n",
        "        for tag_label in tag_label_row:\n",
        "            if tag_label >= thresh:\n",
        "                temp.append(1) \n",
        "            else:\n",
        "                temp.append(0)\n",
        "        y_pred.append(temp)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "\n",
        "def find_best_threshold(flat_pred_outs,y_true):\n",
        "    scores=[]\n",
        "    threshold  = np.arange(0.2,0.51,0.01)\n",
        "\n",
        "    for thresh in threshold:\n",
        "        #classes for each threshold\n",
        "        pred_bin_label = classify(flat_pred_outs,thresh) \n",
        "        #convert to 1D array\n",
        "        y_pred = np.array(pred_bin_label).ravel()\n",
        "\n",
        "        scores.append(f1_score(y_true,y_pred))\n",
        "\n",
        "    return threshold[scores.index(max(scores))]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEr_WIiyIzNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e56536d-df09-4e8f-8217-f27d22310984"
      },
      "source": [
        "pred_outs,true_labels = evaluate_CD()\n",
        "\n",
        "flat_pred_outs = np.concatenate(pred_outs, axis=0)\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0).ravel()\n",
        "y_true = np.concatenate(true_labels, axis=0)\n",
        "opt_thresh = find_best_threshold(flat_pred_outs,flat_true_labels)\n",
        "print(opt_thresh)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnGxMSO2KzeH"
      },
      "source": [
        "Convert probabilities into 0 or 1 based on a threshold value, then calculate the F1 score. I decided the range between 0.2 and 0.51 to find the threshold that maximize the F1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrC_H3DVfU0N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccb50ebf-7d39-4c4a-9466-11954fd6aaf0"
      },
      "source": [
        "y_pred_labels = classify(flat_pred_outs,opt_thresh)\n",
        "y_pred = np.array(y_pred_labels).ravel() \n",
        "\n",
        "f1_macro = f1_score(flat_true_labels,y_pred, average=\"macro\")\n",
        "\n",
        "print(\"F1 =\",f1_macro)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 = 0.752859207010842\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L1FuPFeK39d"
      },
      "source": [
        "See some prediction example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9UdQso0-TOwW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 968
        },
        "outputId": "927adc8a-2c2c-4048-f203-529d796d46c2"
      },
      "source": [
        "y_pred = TaskCD_data_module.val_dataset.mlb.inverse_transform(np.array(y_pred_labels))\n",
        "y_act = TaskCD_data_module.val_dataset.mlb.inverse_transform(y_true)\n",
        "df = pd.DataFrame({'Sentence':TaskCD_data_module.val_dataset.texts,'Actual Tags':y_act,'Predicted Tags':y_pred})\n",
        "\n",
        "pd.set_option('display.max_rows', 30)\n",
        "df.sample(30)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Actual Tags</th>\n",
              "      <th>Predicted Tags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>I asked for seltzer with lime, no ice.</td>\n",
              "      <td>(food-neutral,)</td>\n",
              "      <td>(food-negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>Won't or Can't is not in the service directory.</td>\n",
              "      <td>(service-positive,)</td>\n",
              "      <td>()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>While the ambiance and atmosphere were great, ...</td>\n",
              "      <td>(ambience-positive, food-negative, service-neg...</td>\n",
              "      <td>(ambience-positive, food-positive, service-pos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>They're rude at times, and not very friendly.</td>\n",
              "      <td>(service-negative,)</td>\n",
              "      <td>(service-negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>Both times we waited well over a half hour for...</td>\n",
              "      <td>(service-negative,)</td>\n",
              "      <td>(service-negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Frites were delicious if a bit on the thick side.</td>\n",
              "      <td>(food-positive,)</td>\n",
              "      <td>(food-positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>If your visiting, you'll enjoy the ambiance an...</td>\n",
              "      <td>(ambience-positive,)</td>\n",
              "      <td>(ambience-positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>I have never eaten in the restaurant, however,...</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral,)</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>Much more reasonably priced too!</td>\n",
              "      <td>(price-positive,)</td>\n",
              "      <td>(food-positive, price-negative, price-positive)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>I highly recommend the Sophia pizza.</td>\n",
              "      <td>(anecdotes/miscellaneous-positive,)</td>\n",
              "      <td>(anecdotes/miscellaneous-positive, food-positive)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Why make a reservation if you aren't going to ...</td>\n",
              "      <td>(service-negative,)</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>Prices too high for this cramped and unappeali...</td>\n",
              "      <td>(ambience-negative, price-negative)</td>\n",
              "      <td>(price-negative,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>I am completely hooked on this place, it is ri...</td>\n",
              "      <td>(anecdotes/miscellaneous-positive,)</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral, anecdotes/mi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>The prices were CHEAP compared to the quality ...</td>\n",
              "      <td>(food-positive, price-positive, service-positive)</td>\n",
              "      <td>(food-positive, price-positive)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>not only does make the best pizza in NY , mayb...</td>\n",
              "      <td>(food-positive,)</td>\n",
              "      <td>(food-positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>I do suggest to ask to be seated upstairs if y...</td>\n",
              "      <td>(ambience-positive, anecdotes/miscellaneous-ne...</td>\n",
              "      <td>(service-positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>Our teenage kids love it, too.</td>\n",
              "      <td>(anecdotes/miscellaneous-positive,)</td>\n",
              "      <td>(anecdotes/miscellaneous-positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>Better than the bagel shop on the corner, but ...</td>\n",
              "      <td>(anecdotes/miscellaneous-negative,)</td>\n",
              "      <td>()</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>They treated us well and the food was extremel...</td>\n",
              "      <td>(food-positive, service-positive)</td>\n",
              "      <td>(food-positive, service-positive)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>wont come back again for sure!</td>\n",
              "      <td>(anecdotes/miscellaneous-negative,)</td>\n",
              "      <td>(anecdotes/miscellaneous-positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>After complaining about the chicken dish, the ...</td>\n",
              "      <td>(food-negative, service-negative)</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral, service-nega...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>They were served warm and had a soft fluffy in...</td>\n",
              "      <td>(food-positive,)</td>\n",
              "      <td>(ambience-positive, food-positive, service-pos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>Is just the way it was in days gone by.</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral,)</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>In an area sadly lacking in decent Thai food, ...</td>\n",
              "      <td>(food-positive,)</td>\n",
              "      <td>(food-positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>The takeout menu says to keep an eye out for a...</td>\n",
              "      <td>(food-positive,)</td>\n",
              "      <td>(food-positive,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My wife and I always enjoy the young, not alwa...</td>\n",
              "      <td>(service-conflict,)</td>\n",
              "      <td>(food-positive, service-positive)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>The staff is excellent, specjal: that girl beh...</td>\n",
              "      <td>(service-positive,)</td>\n",
              "      <td>(ambience-positive, food-positive, service-pos...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>The service was friendly and the atmosphere wa...</td>\n",
              "      <td>(ambience-positive, service-positive)</td>\n",
              "      <td>(ambience-positive, service-positive)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>If you want to save some money, don't go here.</td>\n",
              "      <td>(price-negative,)</td>\n",
              "      <td>(anecdotes/miscellaneous-neutral,)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>But after last night, Spice Grill is the only ...</td>\n",
              "      <td>(food-positive,)</td>\n",
              "      <td>(food-positive,)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Sentence  ...                                     Predicted Tags\n",
              "229             I asked for seltzer with lime, no ice.  ...                                   (food-negative,)\n",
              "73     Won't or Can't is not in the service directory.  ...                                                 ()\n",
              "352  While the ambiance and atmosphere were great, ...  ...  (ambience-positive, food-positive, service-pos...\n",
              "86       They're rude at times, and not very friendly.  ...                                (service-negative,)\n",
              "470  Both times we waited well over a half hour for...  ...                                (service-negative,)\n",
              "77   Frites were delicious if a bit on the thick side.  ...                                   (food-positive,)\n",
              "297  If your visiting, you'll enjoy the ambiance an...  ...                               (ambience-positive,)\n",
              "468  I have never eaten in the restaurant, however,...  ...                 (anecdotes/miscellaneous-neutral,)\n",
              "342                   Much more reasonably priced too!  ...    (food-positive, price-negative, price-positive)\n",
              "384               I highly recommend the Sophia pizza.  ...  (anecdotes/miscellaneous-positive, food-positive)\n",
              "6    Why make a reservation if you aren't going to ...  ...                 (anecdotes/miscellaneous-neutral,)\n",
              "117  Prices too high for this cramped and unappeali...  ...                                  (price-negative,)\n",
              "411  I am completely hooked on this place, it is ri...  ...  (anecdotes/miscellaneous-neutral, anecdotes/mi...\n",
              "75   The prices were CHEAP compared to the quality ...  ...                    (food-positive, price-positive)\n",
              "272  not only does make the best pizza in NY , mayb...  ...                                   (food-positive,)\n",
              "195  I do suggest to ask to be seated upstairs if y...  ...                                (service-positive,)\n",
              "485                     Our teenage kids love it, too.  ...                (anecdotes/miscellaneous-positive,)\n",
              "101  Better than the bagel shop on the corner, but ...  ...                                                 ()\n",
              "527  They treated us well and the food was extremel...  ...                  (food-positive, service-positive)\n",
              "55                      wont come back again for sure!  ...                (anecdotes/miscellaneous-positive,)\n",
              "374  After complaining about the chicken dish, the ...  ...  (anecdotes/miscellaneous-neutral, service-nega...\n",
              "185  They were served warm and had a soft fluffy in...  ...  (ambience-positive, food-positive, service-pos...\n",
              "298            Is just the way it was in days gone by.  ...                 (anecdotes/miscellaneous-neutral,)\n",
              "167  In an area sadly lacking in decent Thai food, ...  ...                                   (food-positive,)\n",
              "386  The takeout menu says to keep an eye out for a...  ...                                   (food-positive,)\n",
              "2    My wife and I always enjoy the young, not alwa...  ...                  (food-positive, service-positive)\n",
              "180  The staff is excellent, specjal: that girl beh...  ...  (ambience-positive, food-positive, service-pos...\n",
              "388  The service was friendly and the atmosphere wa...  ...              (ambience-positive, service-positive)\n",
              "10      If you want to save some money, don't go here.  ...                 (anecdotes/miscellaneous-neutral,)\n",
              "311  But after last night, Spice Grill is the only ...  ...                                   (food-positive,)\n",
              "\n",
              "[30 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIZcJMYGAibp"
      },
      "source": [
        "#torch.save(model.state_dict(), root_folder+'/model/TASKCD_model_b={}_f1_{:0.4f}.pt'.format(str(model_b), metr[\"f1\"])) # save the model state"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOQl4xWw9kU9"
      },
      "source": [
        "### Code for implementation.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIf9100usmW9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "217909ff-84c1-49fb-d668-8ed4df6e691b"
      },
      "source": [
        "class PreprocessCD():\n",
        "    def __init__(self, sentences):\n",
        "        self.texts, self.tags = self.load_data(sentences)\n",
        "        self.tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
        "        self.max_len = 20\n",
        "        self.mlb = MultiLabelBinarizer()\n",
        "        self.mlb.fit_transform([['ambience-conflict', 'ambience-negative', 'ambience-neutral',\n",
        "       'ambience-positive', 'anecdotes/miscellaneous-conflict',\n",
        "       'anecdotes/miscellaneous-negative',\n",
        "       'anecdotes/miscellaneous-neutral',\n",
        "       'anecdotes/miscellaneous-positive', 'food-conflict',\n",
        "       'food-negative', 'food-neutral', 'food-positive', 'price-conflict',\n",
        "       'price-negative', 'price-neutral', 'price-positive',\n",
        "       'service-conflict', 'service-negative', 'service-neutral',\n",
        "       'service-positive']])\n",
        "        self.encodings = self.encode_texts()\n",
        "        \n",
        "    def encode_texts(self):\n",
        "        encodings = []\n",
        "        for item_idx,text in enumerate(self.texts):\n",
        "            inputs = self.tokenizer.encode_plus(\n",
        "                text,\n",
        "                None,\n",
        "                add_special_tokens=True, # Add [CLS] [SEP]\n",
        "                max_length= self.max_len,\n",
        "                padding = 'max_length',\n",
        "                return_token_type_ids= False,\n",
        "                return_attention_mask= True, # Differentiates padded vs normal token\n",
        "                truncation=True, # Truncate data beyond max length\n",
        "                return_tensors = 'pt' # PyTorch Tensor format\n",
        "            )\n",
        "            \n",
        "            input_ids = inputs['input_ids'].flatten()\n",
        "            attn_mask = inputs['attention_mask'].flatten()\n",
        "            \n",
        "            encodings.append({\n",
        "                'input_ids': input_ids ,\n",
        "                'attention_mask': attn_mask,\n",
        "            })\n",
        "        return encodings\n",
        "        \n",
        "\n",
        "    def load_data(self,list_of_sentences):\n",
        "        texts = []\n",
        "        tags = []\n",
        "\n",
        "        for obj in list_of_sentences:\n",
        "            texts.append(obj['text'])            \n",
        "        return texts, tags  \n",
        "    \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "\n",
        "def classify(pred_prob,thresh):\n",
        "    y_pred = []\n",
        "\n",
        "    for tag_label_row in pred_prob:\n",
        "        temp=[]\n",
        "        for tag_label in tag_label_row:\n",
        "            if tag_label >= thresh:\n",
        "                temp.append(1) # Infer tag value as 1 (present)\n",
        "            else:\n",
        "                temp.append(0) # Infer tag value as 0 (absent)\n",
        "        y_pred.append(temp)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "def predictCD(samples: List[Dict]) -> List[Dict]:\n",
        "    targets = []\n",
        "    prep = PreprocessCD(samples)\n",
        "    model.eval()\n",
        "    model.cpu()\n",
        "    for i,batch in enumerate(prep.encodings):\n",
        "        with torch.no_grad():\n",
        "            json_pred = {\"targets\":[], \"categories\": []}\n",
        "            b_input_ids = batch[\"input_ids\"]\n",
        "            b_attn_mask = batch[\"attention_mask\"]\n",
        "            \n",
        "            ids = torch.unsqueeze(torch.tensor(b_input_ids),0).cpu()\n",
        "            attmasks = torch.unsqueeze(torch.tensor(b_attn_mask),0).cpu()\n",
        "            # Forward pass, calculate logit predictions\n",
        "            pred_out = model(ids,attmasks)\n",
        "            pred_out = torch.sigmoid(pred_out)\n",
        "            \n",
        "            pred_out = pred_out.detach().cpu().numpy()\n",
        "\n",
        "            y_pred_labels = classify(pred_out,0.2)\n",
        "            \n",
        "            y_pred = prep.mlb.inverse_transform(np.array(y_pred_labels))\n",
        "        for pred in y_pred:\n",
        "            try:\n",
        "                asd = pred[0].split(\"-\")\n",
        "                json_pred[\"categories\"].append((asd[0],asd[1]))\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        targets.append(json_pred)\n",
        "    \n",
        "    return targets\n",
        "\n",
        "            \n",
        "a = load_data(dataset_folder+\"/restaurants_dev.json\")\n",
        "random.shuffle(a)\n",
        "t = predictCD(a)\n",
        "\n",
        "for obj,o in zip(a[:30],t):\n",
        "    print(obj[\"categories\"],\"SEP\",o[\"categories\"])\n",
        "# print(t['categories'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:81: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[['food', 'positive']] SEP [('food', 'positive')]\n",
            "[['food', 'positive']] SEP [('food', 'positive')]\n",
            "[['service', 'positive']] SEP [('service', 'positive')]\n",
            "[['food', 'neutral']] SEP [('food', 'negative')]\n",
            "[['food', 'positive'], ['service', 'positive'], ['ambience', 'positive']] SEP [('ambience', 'positive')]\n",
            "[['food', 'positive']] SEP [('ambience', 'positive')]\n",
            "[['ambience', 'negative']] SEP [('anecdotes/miscellaneous', 'neutral')]\n",
            "[['food', 'positive']] SEP [('food', 'positive')]\n",
            "[['food', 'positive'], ['service', 'positive']] SEP [('service', 'negative')]\n",
            "[['food', 'negative']] SEP [('food', 'negative')]\n",
            "[['price', 'negative'], ['ambience', 'negative']] SEP []\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP []\n",
            "[['food', 'positive'], ['service', 'positive']] SEP [('ambience', 'positive')]\n",
            "[['service', 'positive'], ['anecdotes/miscellaneous', 'positive']] SEP [('food', 'positive')]\n",
            "[['food', 'positive'], ['anecdotes/miscellaneous', 'positive']] SEP [('anecdotes/miscellaneous', 'neutral')]\n",
            "[['anecdotes/miscellaneous', 'neutral']] SEP [('service', 'negative')]\n",
            "[['anecdotes/miscellaneous', 'negative']] SEP [('anecdotes/miscellaneous', 'neutral')]\n",
            "[['anecdotes/miscellaneous', 'negative'], ['price', 'negative']] SEP [('anecdotes/miscellaneous', 'neutral')]\n",
            "[['anecdotes/miscellaneous', 'neutral'], ['service', 'positive']] SEP [('anecdotes/miscellaneous', 'neutral')]\n",
            "[['food', 'negative']] SEP []\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP [('ambience', 'positive')]\n",
            "[['price', 'negative'], ['food', 'neutral']] SEP [('food', 'positive')]\n",
            "[['anecdotes/miscellaneous', 'negative']] SEP [('anecdotes/miscellaneous', 'neutral')]\n",
            "[['ambience', 'negative']] SEP []\n",
            "[['food', 'positive']] SEP [('food', 'positive')]\n",
            "[['food', 'neutral']] SEP [('food', 'positive')]\n",
            "[['food', 'positive']] SEP [('food', 'positive')]\n",
            "[['anecdotes/miscellaneous', 'neutral']] SEP [('anecdotes/miscellaneous', 'neutral')]\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP [('anecdotes/miscellaneous', 'neutral')]\n",
            "[['anecdotes/miscellaneous', 'positive']] SEP []\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JTrvz4d_yZD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7c2030f-cd09-4727-f07f-3cf1a5a95c5a"
      },
      "source": [
        "evaluate_sentiment(a,t,mode=\"Category Extraction\")\n",
        "evaluate_sentiment(a,t,mode=\"Category Sentiment\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Category Extraction Evaluation\n",
            "\n",
            "\tALL\t TP: 357;\tFP: 79;\tFN: 187\n",
            "\t\t(m avg): precision: 81.88;\trecall: 65.62;\tf1: 72.86 (micro)\n",
            "\t\t(M avg): precision: 82.31;\trecall: 53.39;\tf1: 60.13 (Macro)\n",
            "\n",
            "\tanecdotes/miscellaneous: \tTP: 140;\tFP: 27;\tFN: 51;\tprecision: 83.83;\trecall: 73.30;\tf1: 78.21;\t167\n",
            "\tprice: \tTP: 9;\tFP: 0;\tFN: 44;\tprecision: 100.00;\trecall: 16.98;\tf1: 29.03;\t9\n",
            "\tfood: \tTP: 173;\tFP: 28;\tFN: 51;\tprecision: 86.07;\trecall: 77.23;\tf1: 81.41;\t201\n",
            "\tambience: \tTP: 35;\tFP: 24;\tFN: 41;\tprecision: 59.32;\trecall: 46.05;\tf1: 51.85;\t59\n",
            "Category Sentiment Evaluation\n",
            "\n",
            "\tALL\t TP: 268;\tFP: 203;\tFN: 395\n",
            "\t\t(m avg): precision: 56.90;\trecall: 40.42;\tf1: 47.27 (micro)\n",
            "\t\t(M avg): precision: 39.25;\trecall: 30.02;\tf1: 32.69 (Macro)\n",
            "\n",
            "\tpositive: \tTP: 186;\tFP: 96;\tFN: 190;\tprecision: 65.96;\trecall: 49.47;\tf1: 56.53;\t282\n",
            "\tnegative: \tTP: 41;\tFP: 33;\tFN: 126;\tprecision: 55.41;\trecall: 24.55;\tf1: 34.02;\t74\n",
            "\tneutral: \tTP: 41;\tFP: 74;\tFN: 48;\tprecision: 35.65;\trecall: 46.07;\tf1: 40.20;\t115\n",
            "\tconflict: \tTP: 0;\tFP: 0;\tFN: 31;\tprecision: 0.00;\trecall: 0.00;\tf1: 0.00;\t0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}