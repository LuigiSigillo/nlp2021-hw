{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_hw1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "0y_g6ETA_lf3",
        "mkMP7JR-DGfB",
        "8b45LYx6FZiD",
        "QNNOBdXhWKNJ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d8facf6954eb46cfae39704f6a23d20c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e511ca1f310648949fcb498a7b9a6784",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_34bfae961153476eb5acd4a379e34e87",
              "IPY_MODEL_bf47c35ce7d24c4493c372d2c749a233"
            ]
          }
        },
        "e511ca1f310648949fcb498a7b9a6784": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "34bfae961153476eb5acd4a379e34e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf5475a3680f45598c3037507ae698f9",
            "_dom_classes": [],
            "description": " 99%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 140000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 138478,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a0675969e9c4909947096beae5b9a26"
          }
        },
        "bf47c35ce7d24c4493c372d2c749a233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9404fa5d4fde465f9d25cf3950b5447b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 138478/140000 [00:20&lt;00:00, 18961.60it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bcf71f20d0e9440d8d89d9f496e24d4b"
          }
        },
        "cf5475a3680f45598c3037507ae698f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a0675969e9c4909947096beae5b9a26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9404fa5d4fde465f9d25cf3950b5447b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bcf71f20d0e9440d8d89d9f496e24d4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuigiSigillo/nlp2021-hw/blob/master/nlp_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyM39Hb89WdF"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2n5xn1F5kvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63726f3-6d83-4492-892e-d3d288579523"
      },
      "source": [
        "from google.colab import drive\n",
        "# general\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "from collections import Counter, defaultdict\n",
        "from tqdm.notebook import tqdm\n",
        "from typing import *\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import string\n",
        "\n",
        "# torch\n",
        "import torch\n",
        "import json\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim import SGD\n",
        "\n",
        "# NLTK\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "\n",
        "# SKLEARN\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "root_folder = '/content/drive/My Drive/NLP/nlp2021-hw1'\n",
        "dataset_folder = os.path.join(root_folder,'data')\n",
        "\n",
        "''' code to download and move the glove embeddings in the right folder '''\n",
        "#! wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
        "#! unzip -d data/glove.6B\n",
        "#! cd '/content/drive/My Drive/NLP/nlp2021-hw1'\n",
        "#!unzip '/content/drive/My Drive/NLP/nlp2021-hw1/glove.6B.zip'\n",
        "# !mv glove.6B.200d.txt '/content/drive/My Drive/NLP/nlp2021-hw1/model'\n",
        "# !ls \"{root_folder}/model/\"\n",
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Mounted at /content/drive\n",
            "Thu Apr 22 16:03:54 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqmOAYIa_elL"
      },
      "source": [
        "#@title Setup of parameters{ run: \"auto\" }\n",
        "WE_LENGTH = \"100\" #@param [50,100,200,300]\n",
        "METHOD = \"avg\" #@param [\"avg\",\"sum\",\"weigthed_avg\"]\n",
        "USE_SEP = \"True\" #@param [\"True\", \"False\"]\n",
        "WORDS_LIMIT = 140000 #@param {type:\"slider\", min:20000, max:200000, step:20000}\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y_g6ETA_lf3"
      },
      "source": [
        "# First approach (word-level)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anwpXc08XRKf"
      },
      "source": [
        "### Loading of GloVe word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pgljP56n-Wgm"
      },
      "source": [
        "Added to the dictionary also the \"UNK\" and \"SEP\" words using a random vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te3_zheKQQDe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "d8facf6954eb46cfae39704f6a23d20c",
            "e511ca1f310648949fcb498a7b9a6784",
            "34bfae961153476eb5acd4a379e34e87",
            "bf47c35ce7d24c4493c372d2c749a233",
            "cf5475a3680f45598c3037507ae698f9",
            "2a0675969e9c4909947096beae5b9a26",
            "9404fa5d4fde465f9d25cf3950b5447b",
            "bcf71f20d0e9440d8d89d9f496e24d4b"
          ]
        },
        "outputId": "c473f1c5-dd47-4b54-efdf-746425cc5d14"
      },
      "source": [
        "word_vectors = dict()\n",
        "with open(root_folder+'/model/glove.6B.'+WE_LENGTH+'d.txt') as f:\n",
        "\n",
        "    next(f)  # skip header\n",
        "\n",
        "    for i, line in tqdm(enumerate(f), total=WORDS_LIMIT):\n",
        "\n",
        "        if i == WORDS_LIMIT:\n",
        "            break\n",
        "\n",
        "        word, *vector = line.strip().split(' ')\n",
        "        vector = torch.tensor([float(c) for c in vector])\n",
        "        \n",
        "        word_vectors[word] = vector\n",
        "# word_vectors[\"UNK\"] = np.mean(np.array(list(word_vectors.values()), dtype=np.float64), axis=0)\n",
        "word_vectors[\"UNK\"] = torch.tensor(np.random.random(int(WE_LENGTH)),dtype=torch.float)\n",
        "if USE_SEP == \"true\":\n",
        "    word_vectors[\"SEP\"] = torch.tensor(np.random.random(int(WE_LENGTH)),dtype=torch.float)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d8facf6954eb46cfae39704f6a23d20c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=140000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wKed-2p_XsMH"
      },
      "source": [
        "Word-embedding-powered function $\\phi$. Converts sentences to a vector by averaging the embeddings corresponding to each word in it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpsIPHyUV6Lt"
      },
      "source": [
        "def phrase2vector(phrase: str, method: str, keyword: str) -> Optional[torch.Tensor]:\n",
        "    phrases_word_vector = []\n",
        "    if method == \"avg\":\n",
        "        phrases_word_vector = [word_vectors[w] if w in word_vectors else word_vectors['UNK'] for w in phrase.split(' ')]\n",
        "    elif method ==\"weigthed_avg\":\n",
        "        for w in phrase.split(' '):\n",
        "            coeff = 1\n",
        "            if w in word_vectors:\n",
        "                if w == keyword:\n",
        "                    coeff = 1.5\n",
        "                phrases_word_vector.append(word_vectors[w]*coeff)\n",
        "            else:\n",
        "                phrases_word_vector.append(word_vectors['UNK'])\n",
        "\n",
        "    if len(phrases_word_vector) == 0:\n",
        "        return None\n",
        "\n",
        "    phrases_word_vector = torch.stack(phrases_word_vector)  # tensor shape: (#words X #features)\n",
        "    if method==\"sum\":\n",
        "        return torch.sum(phrases_word_vector, dim=0)\n",
        "    else:\n",
        "        return torch.mean(phrases_word_vector, dim=0)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkMP7JR-DGfB"
      },
      "source": [
        "### Dataset class and interfaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti80ryeyXUXT"
      },
      "source": [
        "class SentencesDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, dataset_path: str, phrase2vector):\n",
        "        self.data_store = []\n",
        "        self.init_structures(dataset_path, phrase2vector)\n",
        "\n",
        "    def init_structures(self, dataset_path: str, phrase2vector) -> None:\n",
        "\n",
        "        with open(dataset_path) as f:\n",
        "            for json_string in f:\n",
        "                single_json = json.loads(json_string)\n",
        "\n",
        "                keyword = single_json['sentence1'][int(single_json['start1']):int(single_json['end1'])]\n",
        "                keyword2 = single_json['sentence2'][int(single_json['start2']):int(single_json['end2'])]\n",
        "                lemma = single_json['lemma']\n",
        "\n",
        "                sep = \" \" if USE_SEP == \"false\" else \" SEP \"\n",
        "                lemmatized1 = self.use_only_lemma(single_json['sentence1'],lemma,keyword)\n",
        "                lemmatized2 = self.use_only_lemma(single_json['sentence2'],lemma,keyword2)\n",
        "\n",
        "                sentence =  self.remove_stopwords(lemmatized1) + sep + self.remove_stopwords(lemmatized2)\n",
        "                \n",
        "                indices = self.only_context_target(sentence,[keyword,keyword2,lemma])\n",
        "                ground_t = np.float32(1) if single_json['label'] =='True' else np.float32(0)\n",
        "\n",
        "                vector,idx = phrase2vector(sentence,METHOD,keyword)\n",
        "                \n",
        "                if vector is None or len(indices)!=2:\n",
        "                    continue\n",
        "                    \n",
        "                self.data_store.append((vector,ground_t,indices))\n",
        "\n",
        "    def remove_stopwords(self,sent):\n",
        "        stop_words = set(stopwords.words('english'))\n",
        "        # remove punkt\n",
        "        translator = str.maketrans(string.punctuation, ' '*len(string.punctuation)) \n",
        "        word_tokens = word_tokenize(sent.translate(translator)) \n",
        "        \n",
        "        filtered_sentence = [w for w in word_tokens if not w.lower() in stop_words]\n",
        "        return \" \".join(filtered_sentence)\n",
        "\n",
        "    def use_only_lemma(self,sent,lemma, keyword):\n",
        "        filtered_sentence = [w if not w == keyword else lemma for w in sent.split(\" \") ]\n",
        "        return \" \".join(filtered_sentence)\n",
        "\n",
        "    \n",
        "    def only_context_target(self,sentence,keywords):\n",
        "        i = 0\n",
        "        j = []\n",
        "        sec = False\n",
        "        sentence_list = sentence.split(\" \")\n",
        "        while i < len(sentence_list):\n",
        "            if sentence_list[i] == \"SEP\":\n",
        "                sec = True\n",
        "            if sentence_list[i] in keywords:\n",
        "                if j == []:\n",
        "                    j.append(i)\n",
        "                elif sec:\n",
        "                    j.append(i)\n",
        "                    return j\n",
        "            i += 1\n",
        "        return j\n",
        "            \n",
        "    def __len__(self) -> int:\n",
        "        return len(self.data_store)\n",
        "\n",
        "    def __getitem__(self, idx: int) -> torch.Tensor:\n",
        "        return self.data_store[idx]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8K2TtSOXY13"
      },
      "source": [
        "class SentencesDataModule(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        data_train_path: str,\n",
        "        data_dev_path: str,\n",
        "        batch_size: int,\n",
        "        collate_fn=None\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.data_train_path = data_train_path\n",
        "        self.data_dev_path = data_dev_path\n",
        "        self.batch_size = batch_size\n",
        "        self.collate_fn = collate_fn\n",
        "\n",
        "        self.train_dataset = None\n",
        "        self.validation_dataset = None\n",
        "\n",
        "    def train_dataloader(self, *args, **kwargs) -> DataLoader:\n",
        "        self.train_dataset = SentencesDataset(self.data_train_path, phrase2vector)\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
        "        self.validation_dataset = SentencesDataset(self.data_dev_path, phrase2vector)\n",
        "        return DataLoader(self.validation_dataset, batch_size=self.batch_size)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELkIYmAwDTft"
      },
      "source": [
        "Loading and testing of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwuHz1kdXryl"
      },
      "source": [
        "BATCH_SIZE = 16 #@param {type:\"slider\", min:8, max:64, step:8}\n",
        "sentences_dm = SentencesDataModule(\n",
        "    data_train_path=dataset_folder+'/train.jsonl',\n",
        "    data_dev_path=dataset_folder+'/dev.jsonl',\n",
        "    batch_size=BATCH_SIZE,\n",
        ")\n",
        "val_dataloader = sentences_dm.val_dataloader()\n",
        "# print(word_vectors['test'])\n",
        "\n",
        "for batch in val_dataloader:\n",
        "    X, y = batch\n",
        "    print(batch)\n",
        "    print(f\"batch X shape: {X.shape}\")\n",
        "    print(f\"batch z shape: {y.shape}\")\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b45LYx6FZiD"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0P4wyI__EYdu"
      },
      "source": [
        "Create the classifier class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmfsdUysWYNl"
      },
      "source": [
        "class SentencesClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, n_features: int, n_hidden: int):\n",
        "        super().__init__()\n",
        "        # classification function\n",
        "        self.lin1 = torch.nn.Linear(n_features, n_hidden)\n",
        "        self.output_layer = torch.nn.Linear(n_hidden, 1)\n",
        "        \n",
        "        # criterion\n",
        "        self.loss_fn = torch.nn.BCELoss()\n",
        "        \n",
        "\n",
        "    def forward(self, x: torch.Tensor, y: Optional[torch.Tensor] = None) -> Dict[str, torch.Tensor]:\n",
        "        # actual forward\n",
        "        out = self.lin1(x)\n",
        "        out = torch.relu(out)\n",
        "        # compute logits (which are simply the out variable) and the actual probability distribution (pred, as it is the predicted distribution)\n",
        "    \n",
        "        logits = self.output_layer(out).squeeze(1)\n",
        "\n",
        "        out = torch.sigmoid(logits)\n",
        "\n",
        "        result = {'logits': logits, 'pred': out}\n",
        "\n",
        "        # compute loss\n",
        "        if y is not None:\n",
        "            # torch optimizes its computation internally and takes as input the logits instead\n",
        "            loss = self.loss(out, y)\n",
        "            result['loss'] = loss\n",
        "\n",
        "        return result\n",
        "\n",
        "    def loss(self, pred, y):\n",
        "        return self.loss_fn(pred, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPmotA39E0Ds"
      },
      "source": [
        "Defining a trainer class to better separate our work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-D3B5zgbcKy"
      },
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, optimizer, device):\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.writer = SummaryWriter()\n",
        "        # starts requires_grad for all layers\n",
        "        self.model.train()  # we are using this model for training (some layers have different behaviours in train and eval mode)\n",
        "        self.model.to(self.device)  # move model to GPU if available\n",
        "\n",
        "    def train(self, train_dataset, eval_dataset, epochs=1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            epoch_loss = 0.0\n",
        "            len_train = 0\n",
        "            epoch_val_loss = 0.0\n",
        "            len_val_train = 0\n",
        "            accuracy = 0\n",
        "            f1 = 0\n",
        "            self.model.train()\n",
        "            # each element (sample) in train_dataset is a batch\n",
        "            for step, sample in enumerate(train_dataset):\n",
        "                # inputs in the batch\n",
        "                inputs = sample[0].to(self.device)\n",
        "                # outputs in the batch\n",
        "                targets = sample[1].to(self.device)\n",
        "                output_distribution = self.model(inputs)\n",
        "                loss = self.model.loss(output_distribution['pred'], targets)  # compute loss\n",
        "                # calculates the gradient and accumulates\n",
        "                loss.backward()  # we backpropagate the loss\n",
        "                # updates the parameters\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                len_train += 1\n",
        "\n",
        "            self.model.eval()\n",
        "            for step, sample in enumerate(eval_dataset):\n",
        "                # inputs in the batch\n",
        "                inputs = sample[0].to(self.device)\n",
        "                # outputs in the batch\n",
        "                targets = sample[1].to(self.device)\n",
        "                output_distribution = self.model(inputs)\n",
        "                loss = self.model.loss(output_distribution['pred'], targets)  # compute loss    \n",
        "                y_pred = (output_distribution['pred']>0.5).float().cpu()\n",
        "                y_true = targets.cpu()\n",
        "                accuracy += accuracy_score(y_true, y_pred)\n",
        "                f1 += f1_score(y_true,y_pred)\n",
        "                #accuracy += ((output_distribution['pred'] > 0.5) == targets).float().mean().item() #TODO\n",
        "                epoch_val_loss += loss.item()\n",
        "                len_val_train += 1\n",
        "            \n",
        "            avg_epoch_loss = epoch_loss / len_train\n",
        "            avg_eval_loss = epoch_val_loss / len_val_train\n",
        "            avg_accuracy_loss = accuracy / len_val_train\n",
        "            avg_f1_score = f1/len_val_train\n",
        "            self.writer.add_scalar(\"Train/loss\", avg_epoch_loss, epoch)\n",
        "            self.writer.add_scalar(\"Eval/loss\", avg_eval_loss, epoch)\n",
        "            self.writer.add_scalar(\"Eval/accuracy\", avg_accuracy_loss, epoch)\n",
        "            self.writer.add_scalar(\"Eval/F1_score\", avg_f1_score, epoch)\n",
        "\n",
        "            print('Epoch: {} avg loss = {:0.4f} avg_eval_loss = {:0.4f} avg_eval_acc = {:0.4f} avg_eval_f1 = {:0.4f}'.format(epoch, avg_epoch_loss, avg_eval_loss, avg_accuracy_loss, avg_f1_score))\n",
        "\n",
        "            train_loss += avg_epoch_loss\n",
        "            \n",
        "        torch.save(self.model.state_dict(),os.path.join(root_folder +\"/model\", 'state_{}.pt'.format(epoch)))  # save the model state\n",
        "        self.writer.flush()\n",
        "        avg_epoch_loss = train_loss / epochs\n",
        "        return avg_epoch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkHNJ3n7JShv"
      },
      "source": [
        "Instanciating the classifier and tune some hyperparameters such as the number of hidden layers learning rate and number of epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbqT_pCjKUJE"
      },
      "source": [
        "sent_classifier = SentencesClassifier(\n",
        "    n_features=int(WE_LENGTH), \n",
        "    n_hidden=200 #@param {type:\"slider\", min:50, max:300, step:50}\n",
        ")\n",
        "learning_rate = 0.0391 #@param {type:\"slider\", min:0.0001, max:0.1, step:0.001}\n",
        "epochs = 100 #@param {type:\"slider\", min:50, max:300, step:10}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9BoAWaXJsR4"
      },
      "source": [
        "Defining the optimizer, we will use Stochastic gradient descent and instanciating the trainer to start the train."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsbMs2tYbxTv"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "optimizer = torch.optim.SGD(sent_classifier.parameters(), lr=learning_rate)\n",
        "\n",
        "trainer = Trainer(sent_classifier, optimizer, device)\n",
        "\n",
        "train_dataloader = sentences_dm.train_dataloader()\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs\n",
        "#avg_loss = trainer.train(train_dataloader,val_dataloader, epochs=epochs)\n",
        "print(avg_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cijah8M5QXXN"
      },
      "source": [
        "Method to run a prediction on a personal test phrase and see the prob of beeing of the same context"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxGcNR-cQXjP"
      },
      "source": [
        "def predict(model, phrase2vector, phrase: str, keyword: str):\n",
        "    phrase_vector = phrase2vector(phrase,METHOD,keyword).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    forward_out = model(phrase_vector.unsqueeze(0))  # add a dimension to create a one-item batch\n",
        "    print(f\"# Sentences: {phrase}\")\n",
        "    for i,prob in enumerate(forward_out[\"pred\"]):\n",
        "        print(\"\\n {}\".format( prob) )\n",
        "predict(sent_classifier, phrase2vector, \"The cat eats the mouse SEP Use the mouse to click on the button\", \"mouse\")\n",
        "predict(sent_classifier, phrase2vector, \"The cat eats the mouse SEP The mouse escaped from the predator\", \"mouse\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRni2aJ-O_VY"
      },
      "source": [
        "#Second approach (sequence encoding with RNN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fL_KGqd_MkuA"
      },
      "source": [
        "Let's start by indexing each word in our vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqI-K3a5PBGA"
      },
      "source": [
        "word_index = dict()\n",
        "vectors_store = []\n",
        "\n",
        "# pad token, index = 0\n",
        "vectors_store.append(torch.rand(int(WE_LENGTH)))\n",
        "\n",
        "# unk token, index = 1\n",
        "vectors_store.append(torch.rand(int(WE_LENGTH)))\n",
        "\n",
        "for word, vector in word_vectors.items():\n",
        "    word_index[word] = len(vectors_store)\n",
        "    vectors_store.append(vector)\n",
        "\n",
        "word_index = defaultdict(lambda: 1, word_index)  # default dict returns 1 (unk token) when unknown word\n",
        "vectors_store = torch.stack(vectors_store)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ6jMUGwfg-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe3c7e84-d3be-4faf-9ff9-4f57118faf5d"
      },
      "source": [
        "vocabulary_size, hidden_features = vectors_store.shape\n",
        "print(f\"Vocabulary size: {vocabulary_size}\")\n",
        "print(f\"Hidden features: {hidden_features}\")\n",
        "word_index['pens']  # let's see if the word_index gives to us the unk index (1)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 140003\n",
            "Hidden features: 100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JOKnbTicgFxH"
      },
      "source": [
        "def sentence2indices(review: str,method: str,keyword: str) -> torch.Tensor:\n",
        "    return torch.tensor([word_index[word] for word in review.split(' ')], dtype=torch.long), word_index[keyword]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDx2QWAhhYsp"
      },
      "source": [
        "def rnn_collate_fn(\n",
        "    data_elements: List[Tuple[torch.Tensor, torch.Tensor]] # list of (x, y) pairs\n",
        ") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "\n",
        "    X = [de[0] for de in data_elements]  # list of index tensors\n",
        "    # to implement the many-to-one strategy\n",
        "    X_lengths = torch.tensor([x.size(0) for x in X], dtype=torch.long)\n",
        "    \n",
        "\n",
        "    X = torch.nn.utils.rnn.pad_sequence(X, batch_first=True, padding_value=0)  #  shape (batch_size x max_seq_len)\n",
        "\n",
        "    y = [de[1] for de in data_elements]\n",
        "    y = torch.tensor(y)\n",
        "    keyword_position = [de[2] for de in data_elements] # list of tuples indices where keyword is [[1st sent, 2nd sent]]\n",
        "    \n",
        "    #print(keyword_position)\n",
        "\n",
        "    keyword_position = torch.tensor(keyword_position)\n",
        "\n",
        "    return X, X_lengths, y, keyword_position"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NJyDXpahn7P"
      },
      "source": [
        "class SentencesRNNDataModule(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self, \n",
        "        data_train_path: str,\n",
        "        data_dev_path: str,\n",
        "        batch_size: int,\n",
        "        collate_fn=None\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "        self.data_train_path = data_train_path\n",
        "        self.data_dev_path = data_dev_path\n",
        "        self.batch_size = batch_size\n",
        "        self.collate_fn = collate_fn\n",
        "\n",
        "        self.train_dataset = None\n",
        "        self.validation_dataset = None\n",
        "\n",
        "    def train_dataloader(self, *args, **kwargs) -> DataLoader:\n",
        "        self.train_dataset = SentencesDataset(self.data_train_path, sentence2indices)\n",
        "        return DataLoader(self.train_dataset, batch_size=self.batch_size, collate_fn=rnn_collate_fn)\n",
        "\n",
        "    def val_dataloader(self, *args, **kwargs) -> Union[DataLoader, List[DataLoader]]:\n",
        "        self.validation_dataset = SentencesDataset(self.data_dev_path, sentence2indices)\n",
        "        return DataLoader(self.validation_dataset, batch_size=self.batch_size, collate_fn=rnn_collate_fn)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ejkjswCVhtpz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef60738-c34c-4a6f-c076-69a06adae24f"
      },
      "source": [
        "with open(dataset_folder+'/train.jsonl') as f:\n",
        "    for json_string in f:\n",
        "        single_json = json.loads(json_string)\n",
        "        keyword = single_json['sentence1'][int(single_json['start1']):int(single_json['end1'])]\n",
        "        sep = \" \" if USE_SEP == \"false\" else \" SEP \"\n",
        "        sentence =  single_json['sentence1'] + sep + single_json['sentence2']\n",
        "        ground_t = np.float32(1) if single_json['label'] =='True' else np.float32(0)\n",
        "        vector = sentence2indices(sentence,METHOD,keyword)\n",
        "        if vector is None:\n",
        "            continue\n",
        "        else:\n",
        "            print((sentence,vector, ground_t))\n",
        "        break\n",
        "sentences_rnn_dm = SentencesRNNDataModule(\n",
        "    data_train_path=dataset_folder+'/train.jsonl',\n",
        "    data_dev_path=dataset_folder+'/dev.jsonl',\n",
        "    batch_size=32\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('In that context of coordination and integration, Bolivia holds a key play in any process of infrastructure development. SEP A musical play on the same subject was also staged in Kathmandu for three days.', (tensor([   1,   13, 4711,    4, 6410,    6,    1,    1, 2041,    8,  639,  283,\n",
            "           7,  131,  547,    4, 2952,    1,    1,    1, 2149,  283,   14,    1,\n",
            "         216, 1699,   16,   53, 4425,    7,    1,   11,   88,    1]), 283), 0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7ODza0Zh4oH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "324cb3f2-a552-4f26-8caa-27784cdc329e"
      },
      "source": [
        "for batch in sentences_rnn_dm.val_dataloader():\n",
        "    batch_X, batch_X_lengths, batch_y, batch_kws = batch\n",
        "    print(batch_X)\n",
        "    print(batch_X.shape)\n",
        "    print(batch_y.shape)\n",
        "    break"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 8195,   954,  5285,  ...,     1,  9580,     1],\n",
            "        [ 8195,   954,  5285,  ...,     0,     0,     0],\n",
            "        [19372,   249,  7727,  ...,     0,     0,     0],\n",
            "        ...,\n",
            "        [  360,  2604,   608,  ...,     0,     0,     0],\n",
            "        [  750,  5518,  1237,  ...,     0,     0,     0],\n",
            "        [  750,  5518,  1237,  ...,     0,     0,     0]])\n",
            "torch.Size([32, 38])\n",
            "torch.Size([32])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xI7M_zasi1ol"
      },
      "source": [
        "class SentencesRecurrentClassifier(nn.Module):\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vectors_store: torch.Tensor,\n",
        "        n_hidden: int,\n",
        "        drop_prob: float\n",
        "    ) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        # embedding layer\n",
        "        self.embedding = torch.nn.Embedding.from_pretrained(vectors_store)\n",
        "        self.n_hidden = n_hidden\n",
        "        # recurrent layer\n",
        "        self.rnn = torch.nn.LSTM(input_size=vectors_store.size(1), hidden_size=n_hidden, num_layers=1, batch_first=True, bidirectional=True)\n",
        "        self.dropout = nn.Dropout(drop_prob)\n",
        "\n",
        "        # classification \n",
        "        self.lin1 = torch.nn.Linear(n_hidden*2, n_hidden*2)\n",
        "        self.lin2 = torch.nn.Linear(n_hidden*2, 1)\n",
        "\n",
        "        # criterion\n",
        "        self.loss_fn = torch.nn.BCELoss()\n",
        "        self.device = 'cuda'\n",
        "\n",
        "    def forward(\n",
        "        self, \n",
        "        X: torch.Tensor, \n",
        "        X_length: torch.Tensor,\n",
        "        indices_keyword: torch.Tensor, \n",
        "        y: Optional[torch.Tensor] = None\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "\n",
        "        \n",
        "        embedding_out = self.embedding(X)\n",
        "        # recurrent encoding\n",
        "        recurrent_out = self.rnn(embedding_out)[0]\n",
        "        # here we utilize the sequences length to retrieve the last token \n",
        "        # output for each sequence\n",
        "        \n",
        "        batch_size, seq_len, hidden_size = recurrent_out.shape\n",
        "\n",
        "        # we flatten the recurrent output now I have a long sequence of batch x seq_len vectors \n",
        "        flattened_out = recurrent_out.reshape(-1, hidden_size)\n",
        "        \n",
        "        # and we use a simple trick to compute a tensor of the indices of the last token in each batch element\n",
        "        last_word_relative_indices = X_length - 1\n",
        "        # tensor of the start offsets of each element in the batch\n",
        "        sequences_offsets = torch.arange(batch_size, device=self.device) * seq_len\n",
        "        # e.g. (0, 5, 10, 15, ) + ( 3, 2, 1, 4 ) = ( 3, 7, 11, 19 )\n",
        "        summary_vectors_indices = sequences_offsets + last_word_relative_indices\n",
        "        \n",
        "        \n",
        "        summary_vectors_indices_sent1 = self.testing(indices_keyword, sequences_offsets,0)\n",
        "        #print(sequences_offsets,indices_keyword, summary_vectors_indices)\n",
        "        summary_vectors_indices_sent2 = self.testing(indices_keyword, sequences_offsets,1)\n",
        "        \n",
        "\n",
        "        # finaly we retrieve the vectors that should summarize every sentence.\n",
        "        # (i.e. the last token in the sequence)\n",
        "        #summary_vectors = flattened_out[summary_vectors_indices]\n",
        "        \n",
        "        summary_vectors_sent1 = flattened_out[summary_vectors_indices_sent1]\n",
        "        summary_vectors_sent2 = flattened_out[summary_vectors_indices_sent2]\n",
        "        \n",
        "        #summary_vectors = torch.mean(torch.stack((summary_vectors_sent1,summary_vectors_sent2)), dim = 0)\n",
        "        summary_vectors = summary_vectors_sent1 - summary_vectors_sent2\n",
        "        #print(summary_vectors)\n",
        "        \n",
        "        # now we can classify the reviews with a feedforward pass on the summary\n",
        "        # vectors\n",
        "        out = self.lin1(summary_vectors)\n",
        "        #print(\"shape \",out.shape)\n",
        "        #out = self.lin1(out)\n",
        "        out = torch.relu(out)\n",
        "        # compute logits (which are simply the out variable) and the actual probability distribution (pred, as it is the predicted distribution)\n",
        "        logits = self.lin2(out).squeeze(1)\n",
        "        \n",
        "        pred = torch.sigmoid(logits)\n",
        "\n",
        "        #pred = pred.view(batch_size,-1)\n",
        "        #pred = pred[:,-1]\n",
        "\n",
        "        result = {'logits': logits, 'pred': pred} #'hidden':hidden}\n",
        "        \n",
        "        # compute loss\n",
        "        if y is not None:\n",
        "            loss = self.loss(pred, y)\n",
        "            result['loss'] = loss\n",
        "        \n",
        "        return result\n",
        "        \n",
        "       \n",
        "    def loss(self, pred, y):\n",
        "        return self.loss_fn(pred, y)\n",
        "\n",
        "    def testing(self,indices_keywords,summary,sent_num):\n",
        "        #[   0,   57,  114,  171,  228] = summary\n",
        "        #[ [ 6, 21],[ 4, 22],[ 6, 21],[ 4, 22] ] = indices_keywords\n",
        "        tens_idx = torch.tensor([item[sent_num] for item in indices_keywords]).to(self.device)\n",
        "        return tens_idx + summary\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "        weight = next(self.parameters()).data\n",
        "        hidden = (weight.new(2, batch_size, self.n_hidden).zero_().to(device),\n",
        "                      weight.new(2, batch_size, self.n_hidden).zero_().to(device))\n",
        "        return hidden"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNNOBdXhWKNJ"
      },
      "source": [
        "####  Other NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v-8XowxylF7b"
      },
      "source": [
        "LSTM_UNITS = 128\n",
        "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class SpatialDropout(nn.Dropout2d):\n",
        "    def forward(self, x):\n",
        "        x = x.unsqueeze(2)    # (N, T, 1, K)\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, K, 1, T)\n",
        "        x = super(SpatialDropout, self).forward(x)  # (N, K, 1, T), some features are masked\n",
        "        x = x.permute(0, 3, 2, 1)  # (N, T, 1, K)\n",
        "        x = x.squeeze(2)  # (N, T, K)\n",
        "        return x\n",
        "    \n",
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, embedding_matrix):\n",
        "        super(NeuralNet, self).__init__()\n",
        "        embed_size = embedding_matrix.shape[1]\n",
        "        \n",
        "        self.embedding = nn.Embedding(int(WE_LENGTH), embed_size)\n",
        "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
        "        self.embedding.weight.requires_grad = False\n",
        "        self.embedding_dropout = SpatialDropout(0.3)\n",
        "        \n",
        "        self.lstm1 = nn.LSTM(embed_size, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
        "        self.lstm2 = nn.LSTM(LSTM_UNITS * 2, LSTM_UNITS, bidirectional=True, batch_first=True)\n",
        "    \n",
        "        self.linear1 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
        "        self.linear2 = nn.Linear(DENSE_HIDDEN_UNITS, DENSE_HIDDEN_UNITS)\n",
        "        \n",
        "        self.linear_out = nn.Linear(DENSE_HIDDEN_UNITS, 1)\n",
        "        self.loss_fn = torch.nn.BCELoss()\n",
        "\n",
        "    def forward(self, x, xl, y):\n",
        "        h_embedding = self.embedding(x)\n",
        "        h_embedding = self.embedding_dropout(h_embedding)\n",
        "        \n",
        "        h_lstm1, _ = self.lstm1(h_embedding)\n",
        "        h_lstm2, _ = self.lstm2(h_lstm1)\n",
        "        \n",
        "        # global average pooling\n",
        "        avg_pool = torch.mean(h_lstm2, 1)\n",
        "        # global max pooling\n",
        "        max_pool, _ = torch.max(h_lstm2, 1)\n",
        "        \n",
        "        h_conc = torch.cat((max_pool, avg_pool), 1)\n",
        "        h_conc_linear1  = F.relu(self.linear1(h_conc))\n",
        "        h_conc_linear2  = F.relu(self.linear2(h_conc))\n",
        "        \n",
        "        hidden = h_conc + h_conc_linear1 + h_conc_linear2\n",
        "        \n",
        "        logits = self.linear_out(hidden).squeeze(1)\n",
        "        \n",
        "        pred = torch.sigmoid(logits)\n",
        "\n",
        "        result = {'logits': logits, 'pred': pred}\n",
        "\n",
        "        # compute loss\n",
        "        if y is not None:\n",
        "            loss = self.loss(pred, y)\n",
        "            result['loss'] = loss\n",
        "\n",
        "        return result\n",
        "    def loss(self, pred, y):\n",
        "        return self.loss_fn(pred, y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwunMH6fWNkI"
      },
      "source": [
        "#### Continuos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzBUPzpQzic_"
      },
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, optimizer, device):\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "\n",
        "        # starts requires_grad for all layers\n",
        "        self.model.train()  # we are using this model for training (some layers have different behaviours in train and eval mode)\n",
        "        self.model.to(self.device)  # move model to GPU if available\n",
        "\n",
        "    def train(self, train_dataset, eval_dataset, epochs=1):\n",
        "\n",
        "        train_loss = 0.0\n",
        "        for epoch in tqdm(range(epochs)):\n",
        "            epoch_loss = 0.0\n",
        "            len_train = 0\n",
        "            epoch_val_loss = 0.0\n",
        "            len_val_train = 0\n",
        "            accuracy = 0\n",
        "            self.model.train()\n",
        "\n",
        "            # each element (sample) in train_dataset is a batch\n",
        "            for step, sample in enumerate(train_dataset):\n",
        "                # inputs in the batch\n",
        "                inputs = sample[0].to(self.device)\n",
        "                x_lenghts = sample[1].to(self.device)\n",
        "                # outputs in the batch\n",
        "                targets = sample[2].to(self.device)\n",
        "                \n",
        "                idx_start = torch.tensor(sample[3]).to(self.device)\n",
        "\n",
        "                #output_distribution = self.model(inputs, x_lengths, targets)\n",
        "\n",
        "                output_distribution = self.model(inputs, x_lenghts, idx_start, targets)\n",
        "\n",
        "                loss = output_distribution['loss']#self.model.loss(output_distribution['pred'], targets)  # compute loss\n",
        "\n",
        "                # calculates the gradient and accumulates\n",
        "                loss.backward()  # we backpropagate the loss\n",
        "                # updates the parameters\n",
        "                self.optimizer.step()\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                epoch_loss += loss.item()\n",
        "                len_train += 1\n",
        "                \n",
        "            self.model.eval()\n",
        "            \n",
        "            for step, sample in enumerate(eval_dataset):\n",
        "                # inputs in the batch\n",
        "                inputs = sample[0].to(self.device)\n",
        "                x_lenghts = sample[1].to(self.device)\n",
        "                # outputs in the batch\n",
        "                targets = sample[2].to(self.device)\n",
        "                #h = tuple([e.data for e in h])\n",
        "\n",
        "                idx_start = torch.tensor(sample[3]).to(self.device)\n",
        "\n",
        "                #output_distribution = self.model(inputs, h)\n",
        "                #h = output_distribution['hidden']\n",
        "\n",
        "                output_distribution = self.model(inputs, x_lenghts, idx_start)\n",
        "                loss = self.model.loss(output_distribution['pred'], targets)  # compute loss  \n",
        "                #print(output_distribution['pred'], targets)  \n",
        "                y_pred = (output_distribution['pred']>0.5).float().cpu()\n",
        "                y_true = targets.cpu()\n",
        "                accuracy += accuracy_score(y_true, y_pred)\n",
        "                epoch_val_loss += loss.item()\n",
        "                len_val_train += 1\n",
        "            \n",
        "            avg_epoch_loss = epoch_loss / len_train\n",
        "            avg_eval_loss = epoch_val_loss / len_val_train\n",
        "            avg_accuracy_loss = accuracy / len_val_train\n",
        "            print('Epoch: {} avg loss = {:0.4f} eval loss = {:0.4f} ACC = {:0.4f}'.format(epoch, avg_epoch_loss, avg_eval_loss, avg_accuracy_loss))\n",
        "            train_loss += avg_epoch_loss\n",
        "            # torch.save(self.model.state_dict(),\n",
        "            #            os.path.join(output_folder, 'state_{}.pt'.format(epoch)))  # save the model state\n",
        "            \n",
        "        avg_epoch_loss = train_loss / epochs\n",
        "        return avg_epoch_loss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmaXIR2DjtCg"
      },
      "source": [
        "sentences_recurrent_classifier = SentencesRecurrentClassifier(vectors_store, n_hidden=128,drop_prob=0.2)\n",
        "#sentences_recurrent_classifier = NeuralNet(vectors_store)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "optimizer = torch.optim.Adam(sentences_recurrent_classifier.parameters(), lr=0.0001)\n",
        "trainer = Trainer(sentences_recurrent_classifier, optimizer, device)\n",
        "\n",
        "\n",
        "train_dataloader = sentences_rnn_dm.train_dataloader()\n",
        "avg_loss = trainer.train(train_dataloader,sentences_rnn_dm.val_dataloader(), epochs=50)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFKYSAHv7DKl"
      },
      "source": [
        "a = torch.tensor([ [ 6, 21],[ 4, 22],[ 6, 21],[ 4, 22] ], dtype=float)\n",
        "b = torch.tensor([ [ 1, 1],[ 4, 2],[ 1, 21],[ 2, 2] ], dtype=float)\n",
        "c = torch.mean(torch.stack((a,b)), dim = 0)\n",
        "print(c)\n",
        "print(torch.stack((a,b)), c.shape)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}